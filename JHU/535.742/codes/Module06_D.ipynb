{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module06_D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeFca_h2NgVz",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# Upload\n",
        "# synthetic_control_data.csv\n",
        "# airline_passengers.csv\n",
        "# concrete_compressive_strength.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PtslZ2_P51N"
      },
      "source": [
        "# 6.6. K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJMMjrVizKD2",
        "cellView": "form"
      },
      "source": [
        "#@title 6.6.1. Import some necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.preprocessing as pg\n",
        "import keras.utils           as ku \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier as knnc\n",
        "from sklearn.neighbors import KNeighborsRegressor  as knnr\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrNKPAK4upBJ",
        "cellView": "form"
      },
      "source": [
        "#@title 6.6.2. Classification example: data preprocessing\n",
        "data = pd.read_csv('/content/synthetic_control_data.csv')\n",
        "\n",
        "datain = data.iloc[:,0:-1]\n",
        "dataou = data.iloc[:,-1:]\n",
        "\n",
        "datain_tr, datain_te, dataou_tr, dataou_te = train_test_split(datain, dataou, test_size = 0.2, random_state = 42)\n",
        "\n",
        "print(\"training inputs: \\n\\n {} \\n\\n\".format(datain_tr))\n",
        "print(\"testing  inputs: \\n\\n {} \\n\\n\".format(datain_te))\n",
        "\n",
        "# get the values\n",
        "datain_tr = datain_tr.values\n",
        "dataou_tr = dataou_tr.values\n",
        "\n",
        "datain_te = datain_te.values\n",
        "dataou_te = dataou_te.values\n",
        "\n",
        "# output calibration (inputs are calibrated row-wised between 0 and 1)\n",
        "\n",
        "fun_calibration_in = pg.MinMaxScaler(feature_range=(0,1))\n",
        "fun_calibration_in.fit(datain_tr)\n",
        "\n",
        "datain_tr_calibrated = fun_calibration_in.transform(datain_tr)\n",
        "datain_te_calibrated = fun_calibration_in.transform(datain_te)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBguBX85UDxO",
        "cellView": "form"
      },
      "source": [
        "#@title 6.6.3. Classification example: train and test the KNN model\n",
        "\n",
        "model = knnc(n_neighbors=3)\n",
        "model.fit(datain_tr_calibrated, dataou_tr)\n",
        "\n",
        "dataes_tr = model.predict(datain_tr_calibrated)\n",
        "dataes_te = model.predict(datain_te_calibrated)\n",
        "\n",
        "dataes_tr = np.expand_dims(dataes_tr, axis = 1)\n",
        "dataes_te = np.expand_dims(dataes_te, axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6JsO7ZeWBke",
        "cellView": "form"
      },
      "source": [
        "#@title 6.6.4. Classification example: compute accuracy\n",
        "def fun_accuracy(dataes, dataou):\n",
        "  num_err = np.count_nonzero( dataes - dataou )\n",
        "  accuracy = 1 - num_err/dataou.shape[0]\n",
        "  return accuracy \n",
        "\n",
        "print('training accuracy: {} %'.format( fun_accuracy(dataes_tr,dataou_tr)*100) )\n",
        "print('testing  accuracy: {} %'.format( fun_accuracy(dataes_te,dataou_te)*100) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix75yGsDVKb1",
        "cellView": "form"
      },
      "source": [
        "#@title 6.6.5. Regression example: data preprocessing\n",
        "data = pd.read_csv('/content/concrete_compressive_strength.csv')\n",
        "\n",
        "datain = data.iloc[:,:-1]\n",
        "dataou = data.iloc[:,-1:]\n",
        "\n",
        "datain = datain.values\n",
        "dataou = dataou.values\n",
        "\n",
        "datain_tr, datain_te, dataou_tr, dataou_te = train_test_split(datain, dataou, test_size = 0.1, random_state = 42)\n",
        "\n",
        "scalerin = pg.MinMaxScaler(feature_range=(0,1))\n",
        "scalerin.fit(datain_tr)\n",
        "\n",
        "scalerou = pg.MinMaxScaler(feature_range=(0,1))\n",
        "scalerou.fit(dataou_tr)\n",
        "\n",
        "datain_tr_calibrated = scalerin.transform(datain_tr)\n",
        "datain_te_calibrated = scalerin.transform(datain_te)\n",
        "\n",
        "dataou_tr_calibrated = scalerou.transform(dataou_tr)\n",
        "dataou_te_calibrated = scalerou.transform(dataou_te)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYCbFvR-XFzm",
        "cellView": "form"
      },
      "source": [
        "#@title 6.6.6. Regression example: train and test the KNN\n",
        "model = knnr(n_neighbors=3)\n",
        "model.fit(datain_tr_calibrated, dataou_tr_calibrated)\n",
        "\n",
        "dataes_tr_calibrated = model.predict(datain_tr_calibrated)\n",
        "dataes_te_calibrated = model.predict(datain_te_calibrated)\n",
        "\n",
        "# plot training real vs estimation\n",
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(dataou_tr_calibrated, dataes_tr_calibrated, '.', markersize = 1)\n",
        "plt.plot([0,1],[0,1], '-r', linewidth = 2)\n",
        "plt.xlabel('Real', fontsize = 20)\n",
        "plt.ylabel('Estimated', fontsize = 20)\n",
        "plt.title('Training Results | KNN', fontsize = 20)\n",
        "plt.legend(['datapoint','bi-sector'], fontsize = 20)\n",
        "matplotlib.rc('xtick', labelsize = 20)\n",
        "matplotlib.rc('ytick', labelsize = 20)\n",
        "\n",
        "# plot testing real vs estimation\n",
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(dataou_te_calibrated, dataes_te_calibrated, '.', markersize = 1)\n",
        "plt.plot([0,1],[0,1], '-r', linewidth = 2)\n",
        "plt.xlabel('Real', fontsize = 20)\n",
        "plt.ylabel('Estimated', fontsize = 20)\n",
        "plt.title('Testing Results | KNN', fontsize = 20)\n",
        "plt.legend(['datapoint','bi-sector'], fontsize = 20)\n",
        "matplotlib.rc('xtick', labelsize = 20)\n",
        "matplotlib.rc('ytick', labelsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoijoskeN9zl"
      },
      "source": [
        "# 6.7. Long Short-Term Memory (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihaL6_aY79av",
        "cellView": "form"
      },
      "source": [
        "#@title 6.7.1. Data preprocessing\n",
        "data = pd.read_csv('/content/airline_passengers.csv')\n",
        "data = data.iloc[:,-1].values\n",
        "\n",
        "plt.figure(figsize = [8,8])\n",
        "plt.plot(data, 'k-')\n",
        "plt.xlabel('records over time'    , fontsize = 20)\n",
        "plt.ylabel('number of passengers' , fontsize = 20)\n",
        "\n",
        "size_tr = int(len(data) * 0.8)\n",
        "\n",
        "data_tr = np.expand_dims(data[:size_tr], axis = 1)\n",
        "data_te = np.expand_dims(data[size_tr:], axis = 1)\n",
        "\n",
        "# one way of data processing \n",
        "fun_calibration = pg.MinMaxScaler(feature_range=(0,1))\n",
        "fun_calibration.fit(data_tr)\n",
        "\n",
        "data_tr_calibrated = fun_calibration.transform(data_tr)\n",
        "data_te_calibrated = fun_calibration.transform(data_te)\n",
        "\n",
        "# LSTM data preparation function \n",
        "def fun_dataprocessing_lstm(data, lag = 1, size_in = 5, size_ou = 1):\n",
        "  datain = []\n",
        "  dataou = []\n",
        "\n",
        "  for i0 in range(0, data.shape[0] - size_in - size_ou, lag):\n",
        "\n",
        "    datain.append(np.ndarray.tolist(data[i0           : i0 + size_in, 0]))\n",
        "    dataou.append(np.ndarray.tolist(data[i0 + size_in : i0 + size_in + size_ou, 0]))\n",
        "\n",
        "  datain = np.asarray(datain)\n",
        "  dataou = np.asarray(dataou)\n",
        "\n",
        "  return datain, dataou\n",
        "\n",
        "size_in = 10\n",
        "datain_tr_calibrated, dataou_tr_calibrated = fun_dataprocessing_lstm(data_tr_calibrated, lag = 1, size_in = size_in, size_ou = 1)\n",
        "datain_te_calibrated, dataou_te_calibrated = fun_dataprocessing_lstm(data_te_calibrated, lag = 1, size_in = size_in, size_ou = 1)\n",
        "\n",
        "# expand dimension to be [datapoints or samples, time steps, features (here is number of passengers)]\n",
        "datain_tr_calibrated = np.expand_dims(datain_tr_calibrated, axis = 2)\n",
        "datain_te_calibrated = np.expand_dims(datain_te_calibrated, axis = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZCHGLldrF69",
        "cellView": "form"
      },
      "source": [
        "#@title 6.7.2. Create and compile an LSTM model\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.LSTM(units = 8, input_shape=(size_in, 1))) \n",
        "model.add(layers.Dense(25, activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(10 , activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(5 , activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(1  , activation='linear'))\n",
        "\n",
        "model.compile(optimizer='adam', loss = \"mean_squared_error\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Some good points from https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
        "# The LSTM input layer must be 3D.\n",
        "# The meaning of the 3 input dimensions are: samples, time steps, and features.\n",
        "# The LSTM input layer is defined by the input_shape argument on the first hidden layer.\n",
        "# The input_shape argument takes a tuple of two values that define the number of time steps and features.\n",
        "# The number of samples is assumed to be 1 or more.\n",
        "# The reshape() function on NumPy arrays can be used to reshape your 1D or 2D data to be 3D.\n",
        "# The reshape() function takes a tuple as an argument that defines the new shape.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnVfgz-2reHf",
        "cellView": "form"
      },
      "source": [
        "#@title 6.7.3. Train and test the LSTM model\n",
        "history = model.fit(datain_tr_calibrated, dataou_tr_calibrated[:,0], epochs = 100, batch_size = 1, verbose = 1, shuffle=True, validation_split=0.1)\n",
        "\n",
        "dataes_tr_calibrated = model.predict(datain_tr_calibrated)\n",
        "dataes_te_calibrated = model.predict(datain_te_calibrated)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Be6XYhcOtgw",
        "cellView": "form"
      },
      "source": [
        "#@title 6.7.4. Plots\n",
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(dataou_tr_calibrated[:,0], dataes_tr_calibrated[:,0], '*', markersize = 3)\n",
        "plt.plot([0,1],[0,1], '-r', linewidth = 2)\n",
        "plt.xlabel('Real', fontsize = 20)\n",
        "plt.ylabel('Estimated', fontsize = 20)\n",
        "plt.title('Training Results | LSTM', fontsize = 20)\n",
        "plt.legend(['datapoint','bi-sector'], fontsize = 20)\n",
        "matplotlib.rc('xtick', labelsize = 20)\n",
        "matplotlib.rc('ytick', labelsize = 20)\n",
        "\n",
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(dataou_te_calibrated[:,0], dataes_te_calibrated[:,0], '*', markersize = 3)\n",
        "plt.plot([0,1.5],[0,1.5], '-r', linewidth = 2)\n",
        "plt.xlabel('Real', fontsize = 20)\n",
        "plt.ylabel('Estimated', fontsize = 20)\n",
        "plt.title('Testing Results | LSTM', fontsize = 20)\n",
        "plt.legend(['datapoint','bi-sector'], fontsize = 20)\n",
        "matplotlib.rc('xtick', labelsize = 20)\n",
        "matplotlib.rc('ytick', labelsize = 20)\n",
        "\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(history.history['loss'],'--')\n",
        "plt.plot(history.history['val_loss'],'-')\n",
        "plt.title('model loss', fontsize = 20)\n",
        "plt.ylabel('loss', fontsize = 20)\n",
        "plt.xlabel('epoch', fontsize = 20)\n",
        "plt.legend(['training loss','validation loss'], fontsize = 20)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(np.concatenate((dataou_tr_calibrated, dataou_te_calibrated), axis = 0),'k-')\n",
        "plt.plot(dataes_tr_calibrated,'b--')\n",
        "plt.plot(list(range(dataou_tr_calibrated.shape[0],dataou_tr_calibrated.shape[0] + dataou_te_calibrated.shape[0])), dataes_te_calibrated,'r:')\n",
        "plt.title('model loss', fontsize = 20)\n",
        "plt.ylabel('calibrated number of passengers', fontsize = 20)\n",
        "plt.xlabel('records over time', fontsize = 20)\n",
        "plt.legend(['real', 'training estimation','testing estimation'], fontsize = 20)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}