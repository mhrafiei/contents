{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module06_C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeAaLYaQNKqM",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# Upload: \n",
        "# mnist_train_regression.csv\n",
        "# mnist_test_regression.csv\n",
        "# mnist_train_classification.csv\n",
        "# mnist_test_classification.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PtslZ2_P51N"
      },
      "source": [
        "# 6.5. Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJMMjrVizKD2",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.1. GPU runtime and importing some necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.preprocessing as pg\n",
        "import keras.utils           as ku \n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "#from tensorflow.keras.layers import Dense\n",
        "#from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrNKPAK4upBJ",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.2. Regression example: data preprocessing\n",
        "data_tr   = pd.read_csv('/content/mnist_train_regression.csv')\n",
        "data_te   = pd.read_csv('/content/mnist_test_regression.csv')\n",
        "\n",
        "datain_tr = data_tr.iloc[:,:-1]\n",
        "dataou_tr = data_tr.iloc[:,-1:]\n",
        "\n",
        "datain_te = data_te.iloc[:,:-1]\n",
        "dataou_te = data_te.iloc[:,-1:]\n",
        "\n",
        "print(\"training inputs: \\n\\n {} \\n\\n\".format(datain_tr))\n",
        "print(\"testing  inputs: \\n\\n {} \\n\\n\".format(datain_te))\n",
        "\n",
        "# get the values\n",
        "datain_tr = datain_tr.values\n",
        "dataou_tr = dataou_tr.values\n",
        "\n",
        "datain_te = datain_te.values\n",
        "dataou_te = dataou_te.values\n",
        "\n",
        "# output calibration (inputs are calibrated row-wised between 0 and 1)\n",
        "\n",
        "fun_calibration_ou = pg.MinMaxScaler(feature_range=(0,1))\n",
        "fun_calibration_ou.fit(dataou_tr)\n",
        "\n",
        "dataou_tr_calibrated = fun_calibration_ou.transform(dataou_tr)\n",
        "dataou_te_calibrated = fun_calibration_ou.transform(dataou_te)\n",
        "\n",
        "# reshape for CNN layers\n",
        "\n",
        "shape0 = datain_tr.shape[0]\n",
        "shape1 = int(np.sqrt(datain_tr.shape[1]))\n",
        "shape2 = int(np.sqrt(datain_tr.shape[1]))\n",
        "shape3 = 1\n",
        "\n",
        "datain_tr = datain_tr.reshape((shape0, shape1, shape2, shape3))\n",
        "datain_te = datain_te.reshape((shape0, shape1, shape2, shape3))\n",
        "\n",
        "# observe some training data\n",
        "plt.figure(figsize=[10,10])\n",
        "fig, axs = plt.subplots(3, 3)\n",
        "counter = 0\n",
        "for i0 in range(3):\n",
        "  for i1 in range(3):\n",
        "    axs[i0,i1].imshow(datain_tr[counter,:,:,0].transpose(), cmap=plt.get_cmap('gray'))\n",
        "    counter = counter +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZCHGLldrF69",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.3. Regression example: create and compile a CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters = 8, kernel_size=(3, 3), strides=(1, 1), input_shape=(shape1, shape2, shape3)))\n",
        "model.add(layers.LayerNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(layers.Conv2D(filters = 16, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model.add(layers.LayerNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model.add(layers.LayerNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(50 , activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(25 , activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(1  , activation='linear'))\n",
        "\n",
        "model.compile(optimizer='adam', loss = \"mean_squared_error\")\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnVfgz-2reHf",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.4. Regression example: train and test the CNN model\n",
        "history = model.fit(datain_tr, dataou_tr_calibrated, epochs = 100, batch_size = 128, verbose = 1, shuffle=True, validation_split=0.01)\n",
        "\n",
        "dataes_tr_calibrated = model.predict(datain_tr)\n",
        "dataes_te_calibrated = model.predict(datain_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQehZwH9BVNS",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.5. Regression example: plots\n",
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(dataou_tr_calibrated[:,0], dataes_tr_calibrated[:,0], '.', markersize = 3)\n",
        "plt.plot([0,1],[0,1], '-r', linewidth = 2)\n",
        "plt.xlabel('Real', fontsize = 20)\n",
        "plt.ylabel('Estimated', fontsize = 20)\n",
        "plt.title('Training Results | CNN', fontsize = 20)\n",
        "plt.legend(['datapoint','bi-sector'], fontsize = 20)\n",
        "matplotlib.rc('xtick', labelsize = 20)\n",
        "matplotlib.rc('ytick', labelsize = 20)\n",
        "\n",
        "plt.figure(figsize=[5,5])\n",
        "plt.plot(dataou_te_calibrated[:,0], dataes_te_calibrated[:,0], '.', markersize = 3)\n",
        "plt.plot([0,1],[0,1], '-r', linewidth = 2)\n",
        "plt.xlabel('Real', fontsize = 20)\n",
        "plt.ylabel('Estimated', fontsize = 20)\n",
        "plt.title('Testing Results | CNN', fontsize = 20)\n",
        "plt.legend(['datapoint','bi-sector'], fontsize = 20)\n",
        "matplotlib.rc('xtick', labelsize = 20)\n",
        "matplotlib.rc('ytick', labelsize = 20)\n",
        "\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(history.history['loss'],'--')\n",
        "plt.plot(history.history['val_loss'],'-')\n",
        "plt.title('model loss', fontsize = 20)\n",
        "plt.ylabel('loss', fontsize = 20)\n",
        "plt.xlabel('epoch', fontsize = 20)\n",
        "plt.legend(['training loss','validation loss'], fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGk5CzcHR9bP",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.6. Classification example: data preprocessing\n",
        "data_tr   = pd.read_csv('/content/mnist_train_classification.csv')\n",
        "data_te   = pd.read_csv('/content/mnist_test_classification.csv')\n",
        "\n",
        "datain_tr = data_tr.iloc[:,:-1]\n",
        "dataou_tr = data_tr.iloc[:,-1:]\n",
        "\n",
        "datain_te = data_te.iloc[:,:-1]\n",
        "dataou_te = data_te.iloc[:,-1:]\n",
        "\n",
        "print(\"training inputs: \\n\\n {} \\n\\n\".format(datain_tr))\n",
        "print(\"testing  inputs: \\n\\n {} \\n\\n\".format(datain_te))\n",
        "\n",
        "# get the values\n",
        "datain_tr = datain_tr.values\n",
        "dataou_tr = dataou_tr.values\n",
        "\n",
        "datain_te = datain_te.values\n",
        "dataou_te = dataou_te.values\n",
        "\n",
        "# No calibration (inputs are calibrated row-wised and outputs are \"classes\")\n",
        "\n",
        "# output to categorical\n",
        "dataou_tr_categorical = ku.to_categorical(dataou_tr)\n",
        "dataou_te_categorical = ku.to_categorical(dataou_te)\n",
        "\n",
        "\n",
        "# reshape for CNN layers\n",
        "\n",
        "shape0 = datain_tr.shape[0]\n",
        "shape1 = int(np.sqrt(datain_tr.shape[1]))\n",
        "shape2 = int(np.sqrt(datain_tr.shape[1]))\n",
        "shape3 = 1\n",
        "\n",
        "datain_tr = datain_tr.reshape((shape0, shape1, shape2, shape3))\n",
        "datain_te = datain_te.reshape((shape0, shape1, shape2, shape3))\n",
        "\n",
        "# observe some training data\n",
        "plt.figure(figsize=[10,10])\n",
        "fig, axs = plt.subplots(3, 3)\n",
        "counter = 0\n",
        "for i0 in range(3):\n",
        "  for i1 in range(3):\n",
        "    axs[i0,i1].imshow(datain_tr[counter,:,:,0].transpose(), cmap=plt.get_cmap('gray'))\n",
        "    counter = counter +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPS3GwJ7TIza",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.7. Classification example: create and compile a CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters = 8, kernel_size=(3, 3), strides=(1, 1), input_shape=(shape1, shape2, shape3)))\n",
        "model.add(layers.LayerNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(layers.Conv2D(filters = 16, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model.add(layers.LayerNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model.add(layers.LayerNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(50 , activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(25 , activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.1))\n",
        "model.add(layers.Dense(10  , activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFAzaQUJWE65",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.8. Classification example: train and test the CNN model\n",
        "history = model.fit(datain_tr, dataou_tr_categorical, epochs = 100, batch_size = 128, verbose = 1, shuffle=True, validation_split=0.01)\n",
        "\n",
        "dataes_tr_categorical = model.predict(datain_tr)\n",
        "dataes_te_categorical = model.predict(datain_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2naFHB3eWnAX",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.9. Classification example: compute accuracy\n",
        "def fun_accuracy(dataes, dataou):\n",
        "  num_err = np.count_nonzero( dataes.argmax(axis = 1) - dataou.argmax(axis = 1) )\n",
        "  accuracy = 1 - num_err/dataou.shape[0]\n",
        "  return accuracy \n",
        "\n",
        "print('training accuracy: {} %'.format( fun_accuracy(dataes_tr_categorical,dataou_tr_categorical)*100) )\n",
        "print('testing  accuracy: {} %'.format( fun_accuracy(dataes_te_categorical,dataou_te_categorical)*100) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dhGDJD5Weq3",
        "cellView": "form"
      },
      "source": [
        "#@title 6.5.10. Classification example: plots\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(history.history['loss'],'--')\n",
        "plt.plot(history.history['val_loss'],'-')\n",
        "plt.title('model loss', fontsize = 20)\n",
        "plt.ylabel('loss', fontsize = 20)\n",
        "plt.xlabel('epoch', fontsize = 20)\n",
        "plt.legend(['training loss','validation loss'], fontsize = 20)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(history.history['accuracy'],'--')\n",
        "plt.plot(history.history['val_accuracy'],'-')\n",
        "plt.title('model accuracy', fontsize = 20)\n",
        "plt.ylabel('accuracy', fontsize = 20)\n",
        "plt.xlabel('epoch', fontsize = 20)\n",
        "plt.legend(['training accuracy','validation accuracy'], fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}