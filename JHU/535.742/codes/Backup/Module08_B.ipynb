{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module08_B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u1b6PWRA2z9",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# Upload: \n",
        "# gan_faces_32.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo8F8nzIi6dz"
      },
      "source": [
        "# 8.4. Auto-Encoders for Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXMoQCyoB8Wl",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.1. Import some necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJljxZERFATM",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.2. Data processing\n",
        "# https://thispersondoesnotexist.com/ \n",
        "!unzip gan_faces_32.zip\n",
        "batch_files = glob.glob('/content/*.npy')\n",
        "\n",
        "datain = np.empty((len(batch_files) * 200,32,32,1))\n",
        "c = 0\n",
        "for i0 in range(len(batch_files)):\n",
        "  datain[c:c+200] = np.load(batch_files[i0])\n",
        "  c             = c + 200\n",
        "\n",
        "datain = datain/255\n",
        "\n",
        "# devide data into training and testing \n",
        "datain_tr, datain_te, _, _ = train_test_split(datain, datain, test_size = 0.1, random_state = 42) # we just define dataou to be datain just to run this line without any issue\n",
        "\n",
        "\n",
        "# input information for CNN layers\n",
        "shape0_tr = datain_tr.shape[0]\n",
        "shape0_te = datain_te.shape[0]\n",
        "shape1    = int(datain_tr.shape[1])\n",
        "shape2    = int(datain_tr.shape[2])\n",
        "shape3    = 1\n",
        "\n",
        "print(\"#####################################\")\n",
        "print(\"size of all      data: {}\".format(datain.shape   ) )\n",
        "print(\"size of training data: {}\".format(datain_tr.shape) )\n",
        "print(\"size of testing  data: {}\".format(datain_te.shape) )\n",
        "print(\"#####################################\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLxg0GGbcx0",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.3. Data observation\n",
        "num_data = 5\n",
        "f, ax           = plt.subplots(num_data, num_data, sharex= True, sharey= True, figsize=(num_data*3,num_data*3))\n",
        "f.subplots_adjust(hspace=0)\n",
        "\n",
        "c = 0\n",
        "for i0 in range(num_data):\n",
        "  for i1 in range(num_data):\n",
        "    ax[i0,i1].imshow(datain[c,:,:,0], cmap='gray' )\n",
        "    c = c + 1\n",
        "\n",
        "plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySx7lrUiaCuc",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.4. Encoder model\n",
        "model_encoder = models.Sequential()\n",
        "\n",
        "model_encoder.add(layers.Conv2D(filters = 16, kernel_size=(3, 3), strides=(1,1), input_shape=(shape1, shape2, shape3)))\n",
        "model_encoder.add(layers.LayerNormalization())\n",
        "model_encoder.add(layers.ReLU())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model_encoder.add(layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model_encoder.add(layers.LayerNormalization())\n",
        "model_encoder.add(layers.ReLU())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model_encoder.add(layers.Conv2D(filters = 64, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model_encoder.add(layers.LayerNormalization())\n",
        "model_encoder.add(layers.ReLU())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.Flatten())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.Dense(768, activation='relu'))\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.Dense(386, activation='relu'))\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "# Common layer between the encoder and the decoder\n",
        "\n",
        "model_encoder.add(layers.Dense(128, activation='relu'))\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "#model.compile(optimizer='adam', loss = \"mean_squared_error\")\n",
        "\n",
        "model_encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTD9bRrMiVeJ",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.5. Decoder model\n",
        "model_decoder = models.Sequential()\n",
        "\n",
        "model_decoder.add(layers.Dense(128, activation='relu',  input_dim = 128))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Dense(386, activation='relu'))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Dense(786, activation='relu'))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Dense(1024, activation='relu'))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Reshape((4, 4, 64)))\n",
        "model_decoder.add(layers.LayerNormalization())\n",
        "model_decoder.add(layers.Conv2DTranspose(filters = 16, kernel_size=(3, 3), strides=(1, 1)) )\n",
        "\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "model_decoder.add(layers.UpSampling2D((2, 2)) )\n",
        "model_decoder.add(layers.LayerNormalization())\n",
        "model_decoder.add(layers.Conv2DTranspose(filters = 32, kernel_size=(3,3), strides=(1, 1)) )\n",
        "\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "model_decoder.add(layers.UpSampling2D((2, 2)) )\n",
        "model_decoder.add(layers.LayerNormalization())\n",
        "model_decoder.add(layers.Conv2DTranspose(filters = 1, kernel_size=(5,5), strides=(1, 1)) )\n",
        "\n",
        "model_decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H9-_XuxhSvw",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.6. Auto-Encoder model\n",
        "model_autoencoder = models.Sequential()\n",
        "model_autoencoder.add(model_encoder)\n",
        "model_autoencoder.add(model_decoder)\n",
        "\n",
        "model_autoencoder.compile(optimizer='adam', loss = \"mean_squared_error\")\n",
        "\n",
        "model_autoencoder.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylFpsB40hS5w",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.7. Training the Auto-Encoder model\n",
        "history = model_autoencoder.fit(datain_tr, datain_tr, epochs = 500, batch_size = 128, verbose = 1, shuffle=True, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoTI0oSNhS-e",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.8. Training and testing estimations\n",
        "dataes_tr = model_autoencoder.predict(datain_tr)\n",
        "dataes_te = model_autoencoder.predict(datain_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpahiplfkmnx",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.9. Observe some training estimations\n",
        "f, ax = plt.subplots(10, 2, sharex= True, sharey= True, figsize=(5,15))\n",
        "f.subplots_adjust(hspace=0)\n",
        "for i0 in range(10):\n",
        "  ax[i0,0].imshow(datain_tr[i0,:,:,0], cmap='gray')\n",
        "  ax[i0,1].imshow(dataes_tr[i0,:,:,0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBrsrU7hS75",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.10. Observe some testing estimations\n",
        "f, ax = plt.subplots(10, 2, sharex= True, sharey= True, figsize=(5,15))\n",
        "f.subplots_adjust(hspace=0)\n",
        "for i0 in range(10):\n",
        "  ax[i0,0].imshow(datain_te[i0,:,:,0], cmap='gray')\n",
        "  ax[i0,1].imshow(dataes_te[i0,:,:,0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp28z1qYATcA",
        "cellView": "form"
      },
      "source": [
        "#@title 8.4.11. Training and validation plots \n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(history.history['loss'],'--')\n",
        "plt.plot(history.history['val_loss'],'-')\n",
        "plt.title('model loss', fontsize = 20)\n",
        "plt.ylabel('loss', fontsize = 20)\n",
        "plt.xlabel('epoch', fontsize = 20)\n",
        "plt.legend(['training loss','validation loss'], fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HouWhZLzpzRX"
      },
      "source": [
        "# 8.5. Auto-Encoders for Denoising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufYGlNXgpbb4",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.1. Import some necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZJl1UBYDVz0",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.2. Data processing\n",
        "# https://thispersondoesnotexist.com/ \n",
        "#!unzip gan_faces_32.zip\n",
        "batch_files = glob.glob('/content/*.npy')\n",
        "\n",
        "datain = np.empty((len(batch_files) * 200,32,32,1))\n",
        "c = 0\n",
        "for i0 in range(len(batch_files)):\n",
        "  datain[c:c+200] = np.load(batch_files[i0])\n",
        "  c             = c + 200\n",
        "\n",
        "datain = datain/255\n",
        "\n",
        "# devide data into training and testing \n",
        "datain_tr, datain_te, _, _ = train_test_split(datain, datain, test_size = 0.1, random_state = 42) # we just define dataou to be datain just to run this line without any issue\n",
        "\n",
        "\n",
        "# reshape for CNN layers\n",
        "shape0_tr = datain_tr.shape[0]\n",
        "shape0_te = datain_te.shape[0]\n",
        "shape1    = int(datain_tr.shape[1])\n",
        "shape2    = int(datain_tr.shape[2])\n",
        "shape3    = 1\n",
        "\n",
        "# Synthetic noisy distribution: apply a gaussian noise matrix and clip the images between 0 and 1. (ref: https://blog.keras.io/building-autoencoders-in-keras.html)\n",
        "noise_factor    = 0.05\n",
        "datain_tr_noisy = datain_tr + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=datain_tr.shape) \n",
        "datain_te_noisy = datain_te + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=datain_te.shape) \n",
        "\n",
        "datain_tr_noisy   = np.clip(datain_tr_noisy, 0., 1.)\n",
        "datain_te_noisy   = np.clip(datain_te_noisy, 0., 1.)\n",
        "\n",
        "datain_noisy      = np.concatenate((datain_tr_noisy, datain_te_noisy), axis = 0)\n",
        "datain_original   = np.concatenate((datain_tr      , datain_te      ), axis = 0)\n",
        "\n",
        "print(\"#####################################\")\n",
        "print(\"size of all      data: {}\".format(datain.shape   ) )\n",
        "print(\"size of training data: {}\".format(datain_tr.shape) )\n",
        "print(\"size of testing  data: {}\".format(datain_te.shape) )\n",
        "print(\"#####################################\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JIFd3Du0nN9",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.3. Noisy data observation\n",
        "# Original samples\n",
        "num_data = 5\n",
        "f, ax           = plt.subplots(num_data, num_data, sharex= True, sharey= True, figsize=(num_data*3,num_data*3))\n",
        "f.subplots_adjust(hspace=0)\n",
        "f.suptitle('Original', fontsize = 20)\n",
        "\n",
        "c = 0\n",
        "for i0 in range(num_data):\n",
        "  for i1 in range(num_data):\n",
        "    ax[i0,i1].imshow(datain_original[c,:,:,0], cmap='gray' )\n",
        "    c = c + 1\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "# Noisy samples \n",
        "num_data = 5\n",
        "f, ax           = plt.subplots(num_data, num_data, sharex= True, sharey= True, figsize=(num_data*3,num_data*3))\n",
        "f.subplots_adjust(hspace=0)\n",
        "f.suptitle('Noisy', fontsize = 20)\n",
        "\n",
        "c = 0\n",
        "for i0 in range(num_data):\n",
        "  for i1 in range(num_data):\n",
        "    ax[i0,i1].imshow(datain_noisy[c,:,:,0], cmap='gray' )\n",
        "    c = c + 1\n",
        "\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-sxPWA42aqY",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.4. Encoder model\n",
        "model_encoder = models.Sequential()\n",
        "\n",
        "model_encoder.add(layers.Conv2D(filters = 16, kernel_size=(3, 3), strides=(1,1), input_shape=(shape1, shape2, shape3)))\n",
        "model_encoder.add(layers.LayerNormalization())\n",
        "model_encoder.add(layers.ReLU())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model_encoder.add(layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model_encoder.add(layers.LayerNormalization())\n",
        "model_encoder.add(layers.ReLU())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model_encoder.add(layers.Conv2D(filters = 64, kernel_size=(3, 3), strides=(1, 1)))\n",
        "model_encoder.add(layers.LayerNormalization())\n",
        "model_encoder.add(layers.ReLU())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.Flatten())\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.Dense(768, activation='relu'))\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_encoder.add(layers.Dense(386, activation='relu'))\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "# Common layer between the encoder and the decoder\n",
        "\n",
        "model_encoder.add(layers.Dense(128, activation='relu'))\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "#model.compile(optimizer='adam', loss = \"mean_squared_error\")\n",
        "\n",
        "model_encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPn4Kyss4BiC",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.5. Decoder model\n",
        "model_decoder = models.Sequential()\n",
        "\n",
        "model_decoder.add(layers.Dense(128, activation='relu',  input_dim = 128))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Dense(386, activation='relu'))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Dense(786, activation='relu'))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Dense(1024, activation='relu'))\n",
        "model_decoder.add(layers.Dropout(rate = 0.1))\n",
        "\n",
        "model_decoder.add(layers.Reshape((4, 4, 64)))\n",
        "model_decoder.add(layers.LayerNormalization())\n",
        "model_decoder.add(layers.Conv2DTranspose(filters = 16, kernel_size=(3, 3), strides=(1, 1)) )\n",
        "\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "model_decoder.add(layers.UpSampling2D((2, 2)) )\n",
        "model_decoder.add(layers.LayerNormalization())\n",
        "model_decoder.add(layers.Conv2DTranspose(filters = 32, kernel_size=(3,3), strides=(1, 1)) )\n",
        "\n",
        "model_encoder.add(layers.Dropout(rate = 0.1))\n",
        "model_decoder.add(layers.UpSampling2D((2, 2)) )\n",
        "model_decoder.add(layers.LayerNormalization())\n",
        "model_decoder.add(layers.Conv2DTranspose(filters = 1, kernel_size=(5,5), strides=(1, 1)) )\n",
        "\n",
        "model_decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qptCRtA84BoH",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.6. Auto-Encoder model\n",
        "model_autoencoder = models.Sequential()\n",
        "model_autoencoder.add(model_encoder)\n",
        "model_autoencoder.add(model_decoder)\n",
        "\n",
        "model_autoencoder.compile(optimizer='adam', loss = \"mean_squared_error\")\n",
        "\n",
        "model_autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmAQ-QGA4BwF",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.7. Training the Auto-Encoder model\n",
        "history = model_autoencoder.fit(datain_tr, datain_tr_noisy, epochs = 1000, batch_size = 256, verbose = 1, shuffle=True, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moxm0yqQ4Bsr",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.8. Training and testing estimations\n",
        "dataes_tr = model_autoencoder.predict(datain_tr)\n",
        "dataes_te = model_autoencoder.predict(datain_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziRPCX1q4Bky",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.9. Observe some training estimations\n",
        "f, ax = plt.subplots(10, 2, sharex= True, sharey= True, figsize=(5,15))\n",
        "f.subplots_adjust(hspace=0)\n",
        "for i0 in range(10):\n",
        "  ax[i0,0].imshow(datain_tr_noisy[i0,:,:,0], cmap='gray')\n",
        "  ax[i0,1].imshow(dataes_tr[i0,:,:,0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk-lvmor4Bay",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.10. Observe some testing estimations\n",
        "f, ax = plt.subplots(10, 2, sharex= True, sharey= True, figsize=(2,15))\n",
        "f.subplots_adjust(hspace=0)\n",
        "for i0 in range(10):\n",
        "  ax[i0,0].imshow(datain_te_noisy[i0,:,:,0], cmap='gray')\n",
        "  ax[i0,1].imshow(dataes_te[i0,:,:,0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSJRt1eSFm6e",
        "cellView": "form"
      },
      "source": [
        "#@title 8.5.11. Training and validation plots \n",
        "plt.figure(figsize=[8,8])\n",
        "plt.plot(history.history['loss'],'--')\n",
        "plt.plot(history.history['val_loss'],'-')\n",
        "plt.title('model loss', fontsize = 20)\n",
        "plt.ylabel('loss', fontsize = 20)\n",
        "plt.xlabel('epoch', fontsize = 20)\n",
        "plt.legend(['training loss','validation loss'], fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8GiuDOX7I5e"
      },
      "source": [
        "# 8.6. Restricted Boltzmann Machine (RBM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJLka3Y-7FYj",
        "cellView": "form"
      },
      "source": [
        "#@title 8.6.1. Import some necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as fun_mse\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUawaIrj7uid"
      },
      "source": [
        "# **Reminder**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# One iteration in RBM\n",
        "\n",
        "\n",
        "$\\boldsymbol{H}=\\operatorname{sigmoid}(\\boldsymbol{X} \\boldsymbol{W}+\\boldsymbol{O B})$\n",
        "\n",
        "$\\widetilde{\\boldsymbol{H}}=\\boldsymbol{H} \\leq \\boldsymbol{R}$\n",
        "\n",
        "$\\overline{\\boldsymbol{X}}=\\operatorname{sigmoid}\\left(\\widetilde{\\boldsymbol{H}} \\boldsymbol{W}^{T}+\\boldsymbol{O} \\boldsymbol{C}\\right)$\n",
        "\n",
        "$\\overline{\\boldsymbol{H}}=\\operatorname{sigmoid}(\\overline{\\boldsymbol{X}} \\boldsymbol{W}+\\boldsymbol{O} \\boldsymbol{B})$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Learning (Constructive Divergence - CD -)\n",
        "\n",
        "\n",
        "$\\boldsymbol{W}^{s+1}=\\boldsymbol{W}^{S}+\\Delta \\boldsymbol{W}^{S}$\n",
        "\n",
        "$\\boldsymbol{B}^{s+1}=\\boldsymbol{B}^{S}+\\Delta \\boldsymbol{B}^{s}$\n",
        "\n",
        "$\\boldsymbol{C}^{S+1}=\\boldsymbol{C}^{S}+\\Delta \\boldsymbol{C}^{S}$\n",
        "\n",
        "$\\Delta \\boldsymbol{W}^{s}=\\mu \\Delta \\boldsymbol{W}^{s-1}+\\eta \\frac{\\left(\\boldsymbol{X}^{T} \\boldsymbol{H}-\\overline{\\boldsymbol{X}}^{T} \\overline{\\boldsymbol{H}}\\right)}{N}-W_{\\text {cost}} \\times \\boldsymbol{W}^{s}$\n",
        "\n",
        "$\\Delta \\boldsymbol{B}^{s}=\\mu \\Delta \\boldsymbol{B}^{s-1}+\\eta\\left(\\sum_{n=1}^{N} \\boldsymbol{H}_{n}-\\sum_{n=1}^{N} \\overline{\\boldsymbol{H}}_{n}\\right)$\n",
        "\n",
        "$\\Delta \\boldsymbol{\\Psi}^{s}=\\mu \\Delta \\boldsymbol{\\Psi}^{s-1}+\\eta\\left(\\sum_{n=1}^{N} \\boldsymbol{X}_{n}-\\sum_{n=1}^{N} \\overline{\\boldsymbol{X}}_{n}\\right)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Th8Hg5tybyE",
        "cellView": "form"
      },
      "source": [
        "#@title 8.6.2. Define RBM function\n",
        "\n",
        "#num_hidden = 128 \n",
        "#num_var    = 1024\n",
        "\n",
        "# To generate initial parameters and variables (weights, biases, etc.)\n",
        "def fun_rbm_options(num_hidden, num_var, random_state = 42):\n",
        "  np.random.seed(random_state)\n",
        "  options                         = {}\n",
        "\n",
        "  options['weights']              = np.random.rand(num_var, num_hidden) * 0.1\n",
        "  options['delta_weights']        = np.zeros((num_var, num_hidden))\n",
        "  options['weight_cost']          = 0.0002\n",
        "\n",
        "  options['hidden_biases' ]       = np.zeros((1, num_hidden))\n",
        "  options['delta_hidden_biases']  = np.zeros((1, num_hidden))\n",
        "\n",
        "  options['visible_biases']       = np.zeros((1,num_var))\n",
        "  options['delta_visible_biases'] = np.zeros((1,num_var))\n",
        "\n",
        "  options['mu']                   = 0.9 # recom: 0.9 for the a number of early epochs and 0.5 for the rest\n",
        "  options['learning_rate' ]       = 0.01\n",
        "\n",
        "  return options\n",
        "\n",
        "# The RBM function\n",
        "def fun_rbm(data, options):\n",
        "  # Define sigmoid function\n",
        "  def fun_sigmoid(x): return 1/(1+np.exp(-x))\n",
        "\n",
        "  # size of batch of visible inputs \n",
        "  batch_size = data.shape[0]\n",
        "  num_var    = data.shape[1]\n",
        "  num_hidden = options['weights'].shape[1]\n",
        "\n",
        "  # One iteration\n",
        "  H       = fun_sigmoid( np.dot(data    , options['weights'])             + options['hidden_biases' ].repeat(batch_size, axis = 0) ) \n",
        "  H_tilda = ( H < np.random.rand(batch_size, num_hidden)).astype(float)\n",
        "  X_bar   = fun_sigmoid( np.dot(H_tilda , options['weights'].transpose()) + options['visible_biases'].repeat(batch_size, axis = 0) )\n",
        "  H_bar   = fun_sigmoid( np.dot(X_bar   , options['weights'])             + options['hidden_biases' ].repeat(batch_size, axis = 0) )\n",
        "\n",
        "  output  = {'H':H, 'H_tilda':H_tilda, 'X_bar':X_bar, 'H_bar': H_bar}\n",
        "\n",
        "  # Learning\n",
        "  options['delta_weights']        = options['mu'] * options['delta_weights'] + \\\n",
        "                                    options['learning_rate' ]                * \\\n",
        "                                    ( (np.dot(data.transpose() , H) - np.dot(X_bar.transpose() , H_bar) ) / batch_size - options['weight_cost'] * options['weights'] )       \n",
        "\n",
        "  options['delta_hidden_biases']  = options['mu'] * options['delta_hidden_biases']  + \\\n",
        "                                    options['learning_rate' ]                       * (H.sum(axis = 0)    - H_bar.sum(axis = 0))\n",
        "\n",
        "  options['delta_visible_biases'] = options['mu'] * options['delta_visible_biases'] + \\\n",
        "                                    options['learning_rate']                        * (data.sum(axis = 0) - X_bar.sum(axis = 0))\n",
        "\n",
        "  options['weights']        = options['weights']        + options['delta_weights']\n",
        "  options['hidden_biases']  = options['hidden_biases']  + options['delta_hidden_biases']\n",
        "  options['visible_biases'] = options['visible_biases'] + options['delta_visible_biases']\n",
        "\n",
        "  return options, output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLCph3sw5xjk",
        "cellView": "form"
      },
      "source": [
        "#@title 8.6.3. Data processing\n",
        "# https://thispersondoesnotexist.com/ \n",
        "#!unzip gan_faces_32.zip\n",
        "batch_files = glob.glob('/content/*.npy')\n",
        "\n",
        "datain = np.empty((len(batch_files) * 200,32,32,1))\n",
        "c = 0\n",
        "for i0 in range(len(batch_files)):\n",
        "  datain[c:c+200] = np.load(batch_files[i0])\n",
        "  c             = c + 200\n",
        "\n",
        "datain = datain/255\n",
        "\n",
        "#flatten the data \n",
        "datain = datain.reshape(datain.shape[0], datain.shape[1] * datain.shape[2] * datain.shape[3])\n",
        "\n",
        "# select an image\n",
        "datain = datain[4:5,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmWzMA8i58UT",
        "cellView": "form"
      },
      "source": [
        "#@title 8.6.4. Training RBM\n",
        "epochs     = 1000\n",
        "num_hidden = 128\n",
        "\n",
        "num_var    = datain.shape[1]\n",
        "s_val      = int(np.sqrt(datain.shape[1]))\n",
        "\n",
        "options = fun_rbm_options(num_hidden, num_var)\n",
        "\n",
        "for i0 in range(epochs):\n",
        "\n",
        "  if i0>2:\n",
        "    options['mu']  = 0.5\n",
        "  \n",
        "  options, output = fun_rbm(datain, options)\n",
        "  mse_val         = np.mean( np.sqrt( ((datain - output['X_bar'])**2).sum(axis = 1) ) )\n",
        "  \n",
        "  clear_output(wait=True)\n",
        "\n",
        "  img_mat = np.concatenate((datain[:1,:].reshape(( int(s_val), int(s_val) )), output['X_bar'][:1,:].reshape(( int(s_val), int(s_val) ))), axis = 1)\n",
        "\n",
        "  plt.imshow(img_mat, cmap='gray')\n",
        "  plt.title('Epoch#: {:05.0f} | MSE: {:02.8f}'.format(i0+1, mse_val), fontsize = 15)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}