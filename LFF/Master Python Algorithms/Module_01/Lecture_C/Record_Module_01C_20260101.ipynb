{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f0094a",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Complexity Intuition**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ae48c",
   "metadata": {},
   "source": [
    ">Last update: 20260101.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe in plain language how input size affects algorithm running time. \n",
    "- Estimate the relative efficiency of simple Python functions using informal reasoning. \n",
    "- Relate code patterns such as loops and nested loops to growth behavior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679715ab",
   "metadata": {},
   "source": [
    "## **1. Understanding Runtime Growth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80864f",
   "metadata": {},
   "source": [
    "### **1.1. Input Size Perspective**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a6bb7",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_01_01.jpg?v=1767325034\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Algorithm speed depends mainly on input size\n",
    ">* Larger inputs make work grow, machine details matter less\n",
    "\n",
    ">* Increasing input size changes how long algorithms run\n",
    ">* Different algorithms speed up or slow down differently\n",
    "\n",
    ">* Large inputs can make simple problems infeasible\n",
    ">* We choose algorithms based on growth with size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe1d94",
   "metadata": {},
   "source": [
    "### **1.2. Ignoring Constant Factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91865eb",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_01_02.jpg?v=1767325043\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Focus on how runtime grows with input\n",
    ">* Treat constant speed differences as less important\n",
    "\n",
    ">* Ignore constant details; compare long-term algorithm behavior\n",
    ">* Focus on step growth to judge scalability\n",
    "\n",
    ">* Travel example shows constant overhead is irrelevant\n",
    ">* Focus on growth with distance or input size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e8a80",
   "metadata": {},
   "source": [
    "### **1.3. Timing Code Experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7607251",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_01_03.jpg?v=1767325055\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Time the function on different list sizes\n",
    ">* Compare timings to see how runtime grows\n",
    "\n",
    ">* Look at typical times and overall trends\n",
    ">* Relate time changes to growing input sizes\n",
    "\n",
    ">* Compare functions by timing them on growing inputs\n",
    ">* Use trends to see which algorithm scales better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Timing Code Experiments\n",
    "\n",
    "# Show how timing changes when input size grows.\n",
    "# Compare runtimes for different list sizes clearly.\n",
    "# Focus on trends instead of exact timing numbers.\n",
    "\n",
    "# pip install commands are unnecessary because we use standard library only.\n",
    "\n",
    "# Import time module for measuring elapsed seconds.\n",
    "import time\n",
    "\n",
    "# Define a simple function that processes each list item.\n",
    "def process_list(items):\n",
    "    total_length = 0\n",
    "    for name in items:\n",
    "        total_length += len(name)\n",
    "    return total_length\n",
    "\n",
    "# Define different input sizes representing small, medium, large lists.\n",
    "input_sizes = [1_000, 10_000, 100_000]\n",
    "\n",
    "# Prepare a base name string representing a typical short name.\n",
    "base_name = \"Alice\"\n",
    "\n",
    "# Print a header explaining what the table columns represent.\n",
    "print(\"Items  |  Time seconds  |  Total characters\")\n",
    "\n",
    "# Loop over each size, build data, time the processing.\n",
    "for size in input_sizes:\n",
    "    names = [base_name] * size\n",
    "    start = time.perf_counter()\n",
    "    total_chars = process_list(names)\n",
    "    end = time.perf_counter()\n",
    "    elapsed = end - start\n",
    "    print(f\"{size:6d} | {elapsed:12.6f} | {total_chars:16d}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80362a28",
   "metadata": {},
   "source": [
    "## **2. Code Patterns and Speed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a99cc0",
   "metadata": {},
   "source": [
    "### **2.1. Looping Through Lists**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cd3ee",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_02_01.jpg?v=1767325076\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Loop time grows with list length directly\n",
    ">* Touching more items means more total work\n",
    "\n",
    ">* Compare passes over the list and per-item work\n",
    ">* More full passes and heavier steps run slower\n",
    "\n",
    ">* Work inside each loop step affects speed\n",
    ">* Compare both passes and per-item effort\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa00c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Looping Through Lists\n",
    "\n",
    "# Demonstrate how looping through lists affects running time intuitively.\n",
    "# Compare one pass, three passes, and heavier work per list element.\n",
    "# Show simple timing results for different list sizes using clear prints.\n",
    "# pip install commands are unnecessary because this script uses only standard libraries.\n",
    "\n",
    "# Import time module for measuring simple elapsed times.\n",
    "import time\n",
    "\n",
    "# Create two different list sizes for timing comparisons.\n",
    "small_list = list(range(10000))\n",
    "large_list = list(range(1000000))\n",
    "\n",
    "# Define a light work function that loops once and sums values.\n",
    "def sum_once(values):\n",
    "    total = 0\n",
    "    for number in values:\n",
    "        total += number\n",
    "    return total\n",
    "\n",
    "# Define a function that loops three times doing similar light work.\n",
    "def sum_three_times(values):\n",
    "    total = 0\n",
    "    for number in values:\n",
    "        total += number\n",
    "    for number in values:\n",
    "        total += number\n",
    "    for number in values:\n",
    "        total += number\n",
    "    return total\n",
    "\n",
    "# Define a heavier work function that loops once with extra calculations.\n",
    "def heavy_work_once(values):\n",
    "    total = 0\n",
    "    for number in values:\n",
    "        total += number * number * number\n",
    "    return total\n",
    "\n",
    "# Define a helper function that measures elapsed time for any passed function.\n",
    "def measure_time(label, func, values):\n",
    "    start = time.time()\n",
    "    result = func(values)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(label, \"result\", result, \"seconds\", round(elapsed, 4))\n",
    "\n",
    "# Print a header explaining that timings are rough and machine dependent.\n",
    "print(\"Comparing simple list loop patterns using rough timing measurements.\")\n",
    "\n",
    "# Measure light single pass on small and large lists for comparison.\n",
    "measure_time(\"sum_once small_list\", sum_once, small_list)\n",
    "measure_time(\"sum_once large_list\", sum_once, large_list)\n",
    "\n",
    "# Measure three passes on small and large lists for comparison.\n",
    "measure_time(\"sum_three_times small_list\", sum_three_times, small_list)\n",
    "measure_time(\"sum_three_times large_list\", sum_three_times, large_list)\n",
    "\n",
    "# Measure heavier work single pass on small and large lists.\n",
    "measure_time(\"heavy_work_once small_list\", heavy_work_once, small_list)\n",
    "measure_time(\"heavy_work_once large_list\", heavy_work_once, large_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d2e90",
   "metadata": {},
   "source": [
    "### **2.2. Matrix Nested Loops**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2fc23",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_02_02.jpg?v=1767325098\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Nested loops scan every cell in grids\n",
    ">* Work grows like rows times columns; growth explodes\n",
    "\n",
    ">* Nested loops do far more total work\n",
    ">* Work explodes as input size increases dramatically\n",
    "\n",
    ">* Real-world grids make nested loops very costly\n",
    ">* Use cell counts to compare and predict slowdowns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37159c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Matrix Nested Loops\n",
    "\n",
    "# Show how nested loops scan every grid cell in a matrix.\n",
    "# Compare work done by single loop and matrix nested loops.\n",
    "# Help build intuition about how nested loops grow.\n",
    "\n",
    "# pip install numpy matplotlib seaborn  # Not needed in Colab default.\n",
    "\n",
    "# Import time module for simple timing measurements.\n",
    "import time\n",
    "\n",
    "# Create a simple list representing customers in a single month.\n",
    "customers_single_month = list(range(10000))\n",
    "\n",
    "# Create a simple matrix representing customers across several months.\n",
    "months_count = 100\n",
    "customers_many_months = list(range(1000))\n",
    "\n",
    "# Define a function that loops once through a single list.\n",
    "def single_loop_work(customers_list):\n",
    "    total_purchases = 0\n",
    "    for customer in customers_list:\n",
    "        total_purchases += customer % 5\n",
    "    return total_purchases\n",
    "\n",
    "# Define a function that loops through every cell in a matrix.\n",
    "def nested_loop_work(customers_list, months_number):\n",
    "    total_purchases = 0\n",
    "    for customer in customers_list:\n",
    "        for month_index in range(months_number):\n",
    "            total_purchases += (customer + month_index) % 5\n",
    "    return total_purchases\n",
    "\n",
    "# Time the single loop function using a simple timing pattern.\n",
    "start_single = time.time()\n",
    "single_result = single_loop_work(customers_single_month)\n",
    "end_single = time.time()\n",
    "\n",
    "# Time the nested loop function using the same timing pattern.\n",
    "start_nested = time.time()\n",
    "nested_result = nested_loop_work(customers_many_months, months_count)\n",
    "end_nested = time.time()\n",
    "\n",
    "# Compute elapsed times for both functions in seconds.\n",
    "single_time = end_single - start_single\n",
    "nested_time = end_nested - start_nested\n",
    "\n",
    "# Print results showing how much work each pattern performed.\n",
    "print(\"Single loop total purchases:\", single_result)\n",
    "print(\"Nested loops total purchases:\", nested_result)\n",
    "\n",
    "# Print approximate operation counts for both patterns.\n",
    "print(\"Single loop operations about:\", len(customers_single_month))\n",
    "print(\"Nested loops operations about:\", len(customers_many_months) * months_count)\n",
    "\n",
    "# Print timing information to compare relative speed of both patterns.\n",
    "print(\"Single loop time seconds:\", round(single_time, 6))\n",
    "print(\"Nested loops time seconds:\", round(nested_time, 6))\n",
    "\n",
    "# Print an informal comparison message about relative work growth.\n",
    "print(\"Nested loops did roughly\", (len(customers_many_months) * months_count) // len(customers_single_month), \"times more work.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb47ca",
   "metadata": {},
   "source": [
    "### **2.3. Early Exit Logic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e0db5",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_02_03.jpg?v=1767325117\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Early exit lets programs stop work sooner\n",
    ">* Think about best, worst, and average running time\n",
    "\n",
    ">* Early exit lets searches stop once goal found\n",
    ">* Actual runtime depends on defect position and frequency\n",
    "\n",
    ">* Order of checks changes real-world running time\n",
    ">* Estimate efficiency by how often paths run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec962c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Early Exit Logic\n",
    "\n",
    "# Demonstrate early exit logic using simple list search examples.\n",
    "# Compare best case and worst case search times informally.\n",
    "# Show how early exit affects typical running behavior.\n",
    "\n",
    "# pip install example_library_if_needed_here.\n",
    "\n",
    "# Import time module for measuring simple elapsed durations.\n",
    "import time\n",
    "\n",
    "# Define function that checks list for any negative value early.\n",
    "def contains_negative_early(numbers):\n",
    "    # Loop through each number and exit immediately when negative appears.\n",
    "    for value in numbers:\n",
    "        if value < 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Define function that checks list but never exits early.\n",
    "def contains_negative_slow(numbers):\n",
    "    # Loop through every number and remember if any negative appears.\n",
    "    found_negative = False\n",
    "    for value in numbers:\n",
    "        if value < 0:\n",
    "            found_negative = True\n",
    "    return found_negative\n",
    "\n",
    "# Create three lists representing best, middle, and worst search positions.\n",
    "short_list_best = [-1, 5, 7, 9, 11, 13, 15]\n",
    "short_list_middle = [5, 7, -1, 9, 11, 13, 15]\n",
    "\n",
    "# Create list where negative appears only at the very end position.\n",
    "short_list_worst = [5, 7, 9, 11, 13, 15, -1]\n",
    "\n",
    "# Helper function that measures and prints simple timing information.\n",
    "def measure_run(label, func, data):\n",
    "    start = time.perf_counter()\n",
    "    result = func(data)\n",
    "    end = time.perf_counter()\n",
    "    elapsed_microseconds = (end - start) * 1_000_000\n",
    "    print(label, \"result:\", result, \"time microseconds:\", round(elapsed_microseconds, 2))\n",
    "\n",
    "# Measure early exit behavior for best, middle, and worst positions.\n",
    "print(\"Early exit function timing examples:\")\n",
    "measure_run(\"Best case early exit\", contains_negative_early, short_list_best)\n",
    "measure_run(\"Middle case early exit\", contains_negative_early, short_list_middle)\n",
    "\n",
    "# Measure early exit behavior when negative appears at the very end.\n",
    "measure_run(\"Worst case early exit\", contains_negative_early, short_list_worst)\n",
    "\n",
    "# Measure slow function behavior for the same three example lists.\n",
    "print(\"Always scan function timing examples:\")\n",
    "measure_run(\"Best case always scan\", contains_negative_slow, short_list_best)\n",
    "measure_run(\"Middle case always scan\", contains_negative_slow, short_list_middle)\n",
    "measure_run(\"Worst case always scan\", contains_negative_slow, short_list_worst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15c122",
   "metadata": {},
   "source": [
    "## **3. Space Complexity Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407cf6f",
   "metadata": {},
   "source": [
    "### **3.1. Avoiding Extra Copies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88caad",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_03_01.jpg?v=1767325139\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Extra data copies quietly increase memory use\n",
    ">* Be intentional about when you duplicate structures\n",
    "\n",
    ">* Loops that rebuild full collections waste memory\n",
    ">* Nested loops duplicating datasets cause explosive space growth\n",
    "\n",
    ">* Be selective about creating new data structures\n",
    ">* Reuse or update data to keep memory scalable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Avoiding Extra Copies\n",
    "\n",
    "# Demonstrate avoiding extra copies with simple list processing example.\n",
    "# Compare memory behavior of copying versus in place modification approach.\n",
    "# Show how repeated copies inside loops increase total memory usage.\n",
    "\n",
    "# !pip install psutil memory_profiler matplotlib seaborn.\n",
    "\n",
    "# Import required modules for measuring memory usage and timing.\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "# Create a large list representing boxes in a warehouse in cubic feet.\n",
    "box_volumes = [1] * (500_000)\n",
    "\n",
    "# Define a function that repeatedly copies the list inside a loop.\n",
    "def process_with_copies(volumes):\n",
    "    copied = volumes\n",
    "    for _ in range(5):\n",
    "        copied = [v * 2 for v in copied]\n",
    "    return copied\n",
    "\n",
    "# Define a function that updates the list in place without extra full copies.\n",
    "def process_in_place(volumes):\n",
    "    for _ in range(5):\n",
    "        for i in range(len(volumes)):\n",
    "            volumes[i] = volumes[i] * 2\n",
    "    return volumes\n",
    "\n",
    "# Measure memory usage and time for the copying version using tracemalloc.\n",
    "tracemalloc.start()\n",
    "start_time = time.perf_counter()\n",
    "result_copies = process_with_copies(box_volumes)\n",
    "current_copies, peak_copies = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "# Recreate the original list for a fair in place comparison.\n",
    "box_volumes = [1] * (500_000)\n",
    "\n",
    "# Measure memory usage and time for the in place version using tracemalloc.\n",
    "tracemalloc.start()\n",
    "start_time_in_place = time.perf_counter()\n",
    "result_in_place = process_in_place(box_volumes)\n",
    "current_place, peak_place = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "# Print a short summary comparing peak memory usage and runtimes for both approaches.\n",
    "print(\"Peak bytes with copies:\", peak_copies, \"Peak bytes in place:\", peak_place)\n",
    "print(\"Result length copies:\", len(result_copies), \"Result length in place:\", len(result_in_place))\n",
    "print(\"Extra memory ratio copies:\", round(peak_copies / max(peak_place, 1), 2))\n",
    "print(\"Finished comparison of copying versus in place processing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187b976",
   "metadata": {},
   "source": [
    "### **3.2. In Place vs Copies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119bbd1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_03_02.jpg?v=1767325158\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* In-place algorithms reuse the same memory space\n",
    ">* Copy-based algorithms create full duplicates, using more memory\n",
    "\n",
    ">* In-place algorithms reuse memory; extra space stays small\n",
    ">* Copy-based patterns allocate new structures that grow\n",
    "\n",
    ">* In-place loops reuse data, keeping memory small\n",
    ">* Copying inside loops multiplies memory and risks crashes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - In Place vs Copies\n",
    "\n",
    "# Demonstrate in place list changes versus creating separate copied lists.\n",
    "# Show how memory usage grows when repeatedly copying versus reusing one list.\n",
    "# Help build intuition about space complexity using simple list operations.\n",
    "\n",
    "# !pip install nothing_needed_here_this_runs_with_standard_python_only.\n",
    "\n",
    "# Create a starting list representing daily miles walked this week.\n",
    "miles_week = [2, 3, 4, 3, 5, 4, 6]\n",
    "\n",
    "# Show original list before any in place or copy operations.\n",
    "print(\"Original miles list:\", miles_week)\n",
    "\n",
    "# In place update doubles each value directly inside the existing list.\n",
    "for index in range(len(miles_week)):\n",
    "    miles_week[index] = miles_week[index] * 2\n",
    "\n",
    "# Show list after in place update, still using same underlying list.\n",
    "print(\"After in-place doubling:\", miles_week)\n",
    "\n",
    "# Prepare a fresh list again for the copy based version demonstration.\n",
    "miles_week_copy = [2, 3, 4, 3, 5, 4, 6]\n",
    "\n",
    "# Copy based update builds a brand new list with doubled values each time.\n",
    "new_list = []\n",
    "for value in miles_week_copy:\n",
    "    new_list.append(value * 2)\n",
    "\n",
    "# Show both lists to highlight original unchanged and new separate copy.\n",
    "print(\"Original after copy-based:\", miles_week_copy)\n",
    "\n",
    "# Show new list which required extra memory proportional to original size.\n",
    "print(\"New copied doubled list:\", new_list)\n",
    "\n",
    "# Summarize concept that in place reuses space while copies allocate more.\n",
    "print(\"In-place reuses one list, copies create additional equally large lists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6647f",
   "metadata": {},
   "source": [
    "### **3.3. Time Space Tradeoffs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12d204",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_01/Lecture_C/image_03_03.jpg?v=1767325176\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Algorithms trade time for memory, and vice versa\n",
    ">* Extra data structures speed work; repeated loops save space\n",
    "\n",
    ">* Nested loops are slow but use little memory\n",
    ">* Extra data structures speed lookups but need space\n",
    "\n",
    ">* Systems trade memory use for faster, simpler loops\n",
    ">* Choose structures and loops based on problem constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2be284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Time Space Tradeoffs\n",
    "\n",
    "# Demonstrate time space tradeoff using two simple search strategies.\n",
    "# Compare repeated scanning loops with a precomputed lookup dictionary.\n",
    "# Show how extra memory can reduce repeated nested loop style work.\n",
    "\n",
    "# pip install numpy pandas matplotlib seaborn scikit-learn torch tensorflow.\n",
    "\n",
    "# Import time module for simple timing measurements.\n",
    "import time\n",
    "\n",
    "# Create a list of many product zip codes for searching.\n",
    "product_zip_codes = [str(10000 + i % 90000) for i in range(200000)]\n",
    "\n",
    "# Create a smaller list of target zip codes to repeatedly search.\n",
    "target_zip_codes = [\"10010\", \"30301\", \"60614\", \"94105\", \"75201\"]\n",
    "\n",
    "# Define a slow search that repeatedly scans the entire list.\n",
    "def slow_repeated_search(products, targets):\n",
    "    start = time.time()\n",
    "    found_count = 0\n",
    "    for target in targets:\n",
    "        for code in products:\n",
    "            if code == target:\n",
    "                found_count += 1\n",
    "    duration = time.time() - start\n",
    "    return found_count, duration\n",
    "\n",
    "# Define a faster search that first builds a lookup dictionary.\n",
    "def fast_lookup_search(products, targets):\n",
    "    start = time.time()\n",
    "    lookup = {}\n",
    "    for code in products:\n",
    "        lookup[code] = lookup.get(code, 0) + 1\n",
    "    found_count = 0\n",
    "    for target in targets:\n",
    "        found_count += lookup.get(target, 0)\n",
    "    duration = time.time() - start\n",
    "    return found_count, duration, len(lookup)\n",
    "\n",
    "# Run the slow repeated scanning search and record results.\n",
    "slow_found, slow_time = slow_repeated_search(product_zip_codes, target_zip_codes)\n",
    "\n",
    "# Run the fast lookup based search and record results.\n",
    "fast_found, fast_time, lookup_size = fast_lookup_search(product_zip_codes, target_zip_codes)\n",
    "\n",
    "# Print a short comparison showing time and space related behavior.\n",
    "print(\"Slow search found\", slow_found, \"matches, time seconds:\", round(slow_time, 4))\n",
    "\n",
    "# Print fast search results including approximate lookup dictionary size.\n",
    "print(\"Fast search found\", fast_found, \"matches, time seconds:\", round(fast_time, 4))\n",
    "\n",
    "# Print explanation line describing the time space tradeoff clearly.\n",
    "print(\"Fast search uses extra memory for lookup, reducing repeated scanning loop work.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d22052",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Complexity Intuition**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09c49f",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe in plain language how input size affects algorithm running time. \n",
    "- Estimate the relative efficiency of simple Python functions using informal reasoning. \n",
    "- Relate code patterns such as loops and nested loops to growth behavior. \n",
    "\n",
    "In the next Module (Module 2), we will go over 'Big-O And Math'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
