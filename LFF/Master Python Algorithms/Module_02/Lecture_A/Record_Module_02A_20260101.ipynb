{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1530d94b",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Big-O Basics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280b0ba",
   "metadata": {},
   "source": [
    ">Last update: 20260101.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Explain the meaning of Big-O, Big-Theta, and Big-Omega in the context of algorithm analysis. \n",
    "- Determine the time complexity class of simple Python functions by inspecting their structure. \n",
    "- Compare two algorithms using Big-O notation to justify which is asymptotically more efficient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d3d1f",
   "metadata": {},
   "source": [
    "## **1. Asymptotic Notation Essentials**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd5534",
   "metadata": {},
   "source": [
    "### **1.1. Big O Upper Bounds**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5869c2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_01_01.jpg?v=1767326446\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Big O describes algorithm growth for large inputs\n",
    ">* Gives an upper performance bound, ignoring constants\n",
    "\n",
    ">* Linear search checks each book; O(n) growth\n",
    ">* Binary-style search halves options; O(log n) bound\n",
    "\n",
    ">* Big O is a conservative upper-bound family\n",
    ">* Helps compare scalability and plan worst cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eecdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Big O Upper Bounds\n",
    "\n",
    "# Demonstrate Big O upper bounds using simple timing comparisons.\n",
    "# Show linear versus quadratic growth with increasing input sizes.\n",
    "# Illustrate that Big O gives a safe performance ceiling.\n",
    "\n",
    "# pip install numpy matplotlib seaborn  # Not required in Google Colab.\n",
    "\n",
    "# Import required standard library modules for timing operations.\n",
    "import time\n",
    "\n",
    "# Define a linear time function that loops once over the input list.\n",
    "def linear_sum(numbers):\n",
    "    total = 0\n",
    "    for value in numbers:\n",
    "        total += value\n",
    "    return total\n",
    "\n",
    "# Define a quadratic time function that checks all element pairs.\n",
    "def quadratic_pairs(numbers):\n",
    "    count = 0\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(len(numbers)):\n",
    "            count += numbers[i] * 0 + numbers[j] * 0\n",
    "    return count\n",
    "\n",
    "# Prepare different input sizes to observe growth behavior.\n",
    "input_sizes = [200, 400, 800, 1600]\n",
    "\n",
    "# Prepare containers for measured running times.\n",
    "linear_times = []\n",
    "quadratic_times = []\n",
    "\n",
    "# Measure running times for each input size using both functions.\n",
    "for n in input_sizes:\n",
    "    data = list(range(n))\n",
    "    start = time.perf_counter()\n",
    "    linear_sum(data)\n",
    "    end = time.perf_counter()\n",
    "    linear_times.append(end - start)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    quadratic_pairs(data)\n",
    "    end = time.perf_counter()\n",
    "    quadratic_times.append(end - start)\n",
    "\n",
    "# Print a compact header explaining the upcoming timing table.\n",
    "print(\"n, linear_time_seconds, quadratic_time_seconds\")\n",
    "\n",
    "# Print measured times to show different growth rates clearly.\n",
    "for n, t_lin, t_quad in zip(input_sizes, linear_times, quadratic_times):\n",
    "    print(f\"{n}, {t_lin:.6f}, {t_quad:.6f}\")\n",
    "\n",
    "# Print a final note connecting results to Big O upper bounds.\n",
    "print(\"Linear is O(n); quadratic is O(n^2) as safe upper bounds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bed53c",
   "metadata": {},
   "source": [
    "### **1.2. Theta Tight Bounds**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b7a79",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_01_02.jpg?v=1767326471\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Theta gives a precise growth rate bound\n",
    ">* It is both upper and lower runtime bound\n",
    "\n",
    ">* Order time grows directly with shirt count\n",
    ">* Theta means runtime grows proportionally with input\n",
    "\n",
    ">* Theta groups algorithms by true growth rate\n",
    ">* Helps compare long‑term efficiency beyond constant factors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Theta Tight Bounds\n",
    "\n",
    "# Demonstrate Theta tight bounds using simple counting loops.\n",
    "# Show how work grows directly with input size n.\n",
    "# Compare two algorithms that share the same Theta classification.\n",
    "# pip install numpy matplotlib seaborn.\n",
    "\n",
    "# Import time module for simple timing measurements.\n",
    "import time\n",
    "\n",
    "# Define a function that performs one simple loop.\n",
    "def single_loop_work(n):\n",
    "    # Initialize a counter that tracks performed operations.\n",
    "    count = 0\n",
    "    # Loop exactly n times performing constant work.\n",
    "    for _ in range(n):\n",
    "        count += 1\n",
    "    # Return the final count for verification.\n",
    "    return count\n",
    "\n",
    "# Define a function that performs two similar loops.\n",
    "def double_loop_work(n):\n",
    "    # Initialize a counter that tracks performed operations.\n",
    "    count = 0\n",
    "    # First loop runs exactly n times performing constant work.\n",
    "    for _ in range(n):\n",
    "        count += 1\n",
    "    # Second loop also runs exactly n times performing constant work.\n",
    "    for _ in range(n):\n",
    "        count += 1\n",
    "    # Return the final count for verification.\n",
    "    return count\n",
    "\n",
    "# Define a helper function that times another function.\n",
    "def time_function(func, n):\n",
    "    # Record the starting time using perf_counter.\n",
    "    start = time.perf_counter()\n",
    "    # Call the provided function with input size n.\n",
    "    result = func(n)\n",
    "    # Record the ending time using perf_counter.\n",
    "    end = time.perf_counter()\n",
    "    # Compute elapsed time in seconds for this run.\n",
    "    elapsed = end - start\n",
    "    # Return both elapsed time and result value.\n",
    "    return elapsed, result\n",
    "\n",
    "# Choose an input size representing number of items processed.\n",
    "n = 2000000\n",
    "\n",
    "# Time the single loop algorithm with input size n.\n",
    "single_time, single_result = time_function(single_loop_work, n)\n",
    "\n",
    "# Time the double loop algorithm with the same input size n.\n",
    "double_time, double_result = time_function(double_loop_work, n)\n",
    "\n",
    "# Print results showing counts and measured times.\n",
    "print(\"Input size n:\", n)\n",
    "print(\"Single loop operations:\", single_result)\n",
    "print(\"Double loop operations:\", double_result)\n",
    "print(\"Single loop time seconds:\", round(single_time, 6))\n",
    "print(\"Double loop time seconds:\", round(double_time, 6))\n",
    "print(\"Time ratio double_over_single:\", round(double_time / single_time, 2))\n",
    "print(\"Both algorithms are Theta of n overall.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b1795",
   "metadata": {},
   "source": [
    "### **1.3. Omega Lower Bounds**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf1338",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_01_03.jpg?v=1767326486\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Omega gives a guaranteed minimum running time\n",
    ">* Acts as a performance floor that algorithms exceed\n",
    "\n",
    ">* Omega describes unavoidable minimum work for problems\n",
    ">* Separates algorithm tricks from problem’s inherent difficulty\n",
    "\n",
    ">* Omega gives a performance floor; Big O ceiling\n",
    ">* Matching bounds tightly describe growth; guides realistic optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef990e7a",
   "metadata": {},
   "source": [
    "## **2. Reading Code Complexities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f804c06",
   "metadata": {},
   "source": [
    "### **2.1. Counting Key Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c0e50",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_02_01.jpg?v=1767326504\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Count key operations that drive running time\n",
    ">* Use these counts to classify time complexity\n",
    "\n",
    ">* Trace the code and count repeated actions\n",
    ">* Focus on how counts scale to classify\n",
    "\n",
    ">* Use operation counts to model real processes\n",
    ">* Identify dominant work to compare algorithm scalability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efe87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Counting Key Operations\n",
    "\n",
    "# Demonstrate counting key operations in simple Python functions.\n",
    "# Compare constant work and linear work using small list examples.\n",
    "# Print operation counts to connect them with time complexity ideas.\n",
    "# pip install numpy pandas matplotlib seaborn scikit-learn torch tensorflow.\n",
    "\n",
    "# Define a function that checks only first list element once.\n",
    "def check_first_element(numbers_list, target_value):\n",
    "    operations_count = 0\n",
    "    operations_count += 1  # Access first element from list once.\n",
    "    first_matches = numbers_list[0] == target_value\n",
    "    operations_count += 1  # Compare first element with target value.\n",
    "    return first_matches, operations_count\n",
    "\n",
    "# Define a function that scans entire list for target value.\n",
    "def scan_all_elements(numbers_list, target_value):\n",
    "    operations_count = 0\n",
    "    found_flag = False\n",
    "    for current_value in numbers_list:\n",
    "        operations_count += 1  # Access current element from list.\n",
    "        if current_value == target_value:\n",
    "            operations_count += 1  # Compare current element with target.\n",
    "            found_flag = True\n",
    "        else:\n",
    "            operations_count += 1  # Compare current element with target.\n",
    "    return found_flag, operations_count\n",
    "\n",
    "# Prepare two lists representing different input sizes.\n",
    "small_list = list(range(10))\n",
    "large_list = list(range(1000))\n",
    "\n",
    "# Choose a target value that appears inside both lists.\n",
    "target_value = 5\n",
    "\n",
    "# Measure operations for constant work function on both lists.\n",
    "small_first_result, small_first_ops = check_first_element(small_list, target_value)\n",
    "large_first_result, large_first_ops = check_first_element(large_list, target_value)\n",
    "\n",
    "# Measure operations for linear work function on both lists.\n",
    "small_scan_result, small_scan_ops = scan_all_elements(small_list, target_value)\n",
    "large_scan_result, large_scan_ops = scan_all_elements(large_list, target_value)\n",
    "\n",
    "# Print results showing constant operations versus growing operations.\n",
    "print(\"check_first_element small_list operations:\", small_first_ops)\n",
    "print(\"check_first_element large_list operations:\", large_first_ops)\n",
    "print(\"scan_all_elements small_list operations:\", small_scan_ops)\n",
    "print(\"scan_all_elements large_list operations:\", large_scan_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e91447",
   "metadata": {},
   "source": [
    "### **2.2. Combining Sequential Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c058aa",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_02_02.jpg?v=1767326529\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Sequential code blocks have costs that add\n",
    ">* Overall complexity is set by fastest-growing step\n",
    "\n",
    ">* Label each code block with its complexity\n",
    ">* Two linear passes plus constants still scale linearly\n",
    "\n",
    ">* Later, faster-growing steps dominate total runtime\n",
    ">* Identify the dominating segment to classify complexity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Combining Sequential Steps\n",
    "\n",
    "# Demonstrate combining sequential steps for overall time complexity understanding.\n",
    "# Show separate linear and quadratic steps and their combined dominating behavior.\n",
    "# Print simple timings to compare sequential step growth for increasing input sizes.\n",
    "# pip install some_required_library_if_needed_but_standard_libraries_are_sufficient.\n",
    "\n",
    "# Import required standard library modules for timing measurements.\n",
    "import time\n",
    "\n",
    "# Define a function performing two sequential linear passes over the list.\n",
    "def two_linear_passes(data_list):\n",
    "    total_sum = 0\n",
    "    for value in data_list:\n",
    "        total_sum += value\n",
    "    for value in data_list:\n",
    "        total_sum += value\n",
    "    return total_sum\n",
    "\n",
    "# Define a function performing one linear pass then one quadratic nested loop.\n",
    "def linear_then_quadratic(data_list):\n",
    "    total_sum = 0\n",
    "    for value in data_list:\n",
    "        total_sum += value\n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(len(data_list)):\n",
    "            total_sum += data_list[i] * 0\n",
    "    return total_sum\n",
    "\n",
    "# Define a helper function measuring average running time for a given function.\n",
    "def measure_time(func, data_list, repeats):\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(repeats):\n",
    "        func(data_list)\n",
    "    end_time = time.perf_counter()\n",
    "    average_time = (end_time - start_time) / repeats\n",
    "    return average_time\n",
    "\n",
    "# Prepare different input sizes to show how times grow with list length.\n",
    "input_sizes = [50, 100, 200]\n",
    "\n",
    "# Print header explaining which function corresponds to which complexity behavior.\n",
    "print(\"Comparing sequential steps: two linear passes versus linear plus quadratic.\")\n",
    "\n",
    "# Loop over input sizes and measure both functions for each size.\n",
    "for size in input_sizes:\n",
    "    data = list(range(size))\n",
    "    time_two_linear = measure_time(two_linear_passes, data, 50)\n",
    "    time_linear_quadratic = measure_time(linear_then_quadratic, data, 5)\n",
    "    print(f\"Size {size} items, two linear passes time: {time_two_linear:.6f} seconds.\")\n",
    "    print(f\"Size {size} items, linear then quadratic time: {time_linear_quadratic:.6f} seconds.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24252cec",
   "metadata": {},
   "source": [
    "### **2.3. Nested Loops And Calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665418c",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_02_03.jpg?v=1767326545\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Nested loops multiply work based on input size\n",
    ">* More nesting makes runtime grow very quickly\n",
    "\n",
    ">* Nested loop bounds can shrink with progress\n",
    ">* Total work may still grow quadratically overall\n",
    "\n",
    ">* Loop cost equals iterations times function cost\n",
    ">* Analyze each loop and call to combine complexities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Nested Loops And Calls\n",
    "\n",
    "# Demonstrate nested loops time complexity with simple pair comparisons.\n",
    "# Show function calls inside loops and their combined time complexity effect.\n",
    "# Print operation counts for different input sizes to observe growth patterns.\n",
    "# pip install some_required_library_if_needed_but_standard_libraries_are_sufficient.\n",
    "\n",
    "# Define a simple function that simulates constant time work.\n",
    "def constant_work(student_a, student_b, distance_feet):\n",
    "    total_inches = distance_feet * 12 + 6\n",
    "    return f\"Pair {student_a}-{student_b} checked {total_inches} inches apart.\"\n",
    "\n",
    "# Define a function with a nested loop over all student pairs.\n",
    "def check_all_pairs(students):\n",
    "    operations = 0\n",
    "    n = len(students)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            _ = constant_work(students[i], students[j], 3)\n",
    "            operations += 1\n",
    "    return operations\n",
    "\n",
    "# Define a function that calls a linear helper inside an outer loop.\n",
    "def linear_helper(students):\n",
    "    total = 0\n",
    "    for _ in students:\n",
    "        total += 1\n",
    "    return total\n",
    "\n",
    "# Define a function that shows nested behavior using a helper call.\n",
    "def outer_with_helper(students):\n",
    "    operations = 0\n",
    "    for _ in students:\n",
    "        operations += linear_helper(students)\n",
    "    return operations\n",
    "\n",
    "# Prepare small input sizes to keep output readable and clear.\n",
    "input_sizes = [3, 5, 8]\n",
    "\n",
    "# Loop over sizes and show operation counts for both patterns.\n",
    "for size in input_sizes:\n",
    "    students = [f\"S{i}\" for i in range(size)]\n",
    "    pair_ops = check_all_pairs(students)\n",
    "    helper_ops = outer_with_helper(students)\n",
    "    print(f\"Size {size}: pair_ops={pair_ops}, helper_ops={helper_ops}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c55268",
   "metadata": {},
   "source": [
    "## **3. Comparing Algorithm Growth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47870e1b",
   "metadata": {},
   "source": [
    "### **3.1. Core Complexity Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccf105",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_03_01.jpg?v=1767326561\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Core classes describe how runtime grows with input\n",
    ">* Constant, logarithmic, linear time are most efficient\n",
    "\n",
    ">* Linearithmic, quadratic, and higher polynomials grow faster\n",
    ">* For large inputs, n log n beats n squared\n",
    "\n",
    ">* Exponential and factorial algorithms explode with input size\n",
    ">* Polynomial algorithms always scale better for large problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Core Complexity Classes\n",
    "\n",
    "# Demonstrate core complexity classes using simple timing comparisons.\n",
    "# Show constant, linear, quadratic, and exponential style growth behaviors.\n",
    "# Help compare algorithm growth as input size increases clearly.\n",
    "\n",
    "# pip install numpy matplotlib seaborn  # Not required in this simple example.\n",
    "\n",
    "# Import required standard library modules for timing and math operations.\n",
    "import time\n",
    "\n",
    "# Define a constant time function that always performs the same tiny work.\n",
    "def constant_time(n):\n",
    "    total = 0\n",
    "    for _ in range(10):\n",
    "        total += 1\n",
    "    return total\n",
    "\n",
    "# Define a linear time function that loops once over the input range.\n",
    "def linear_time(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "# Define a quadratic time function that uses nested loops over input.\n",
    "def quadratic_time(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            total += i + j\n",
    "    return total\n",
    "\n",
    "# Define an exponential time function using recursive Fibonacci calculation.\n",
    "def exponential_time(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return exponential_time(n - 1) + exponential_time(n - 2)\n",
    "\n",
    "# Define a helper function that measures execution time for another function.\n",
    "def measure_time(func, n):\n",
    "    start = time.perf_counter()\n",
    "    func(n)\n",
    "    end = time.perf_counter()\n",
    "    return end - start\n",
    "\n",
    "# Choose input sizes that keep runtime reasonable for demonstration purposes.\n",
    "input_sizes = [10, 50, 100]\n",
    "\n",
    "# Print header describing what will be measured for each complexity class.\n",
    "print(\"Comparing core complexity classes with simple timing measurements:\")\n",
    "\n",
    "# Measure and print times for constant, linear, and quadratic functions.\n",
    "for n in input_sizes:\n",
    "    t_const = measure_time(constant_time, n)\n",
    "    t_linear = measure_time(linear_time, n)\n",
    "    t_quad = measure_time(quadratic_time, n)\n",
    "    print(f\"n={n:3d} | constant={t_const:.6f}s | linear={t_linear:.6f}s | quadratic={t_quad:.6f}s\")\n",
    "\n",
    "# Measure exponential time for small n values to avoid huge runtimes.\n",
    "for n in [10, 20, 25]:\n",
    "    t_exp = measure_time(exponential_time, n)\n",
    "    print(f\"n={n:3d} | exponential Fibonacci time={t_exp:.6f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb7a6a",
   "metadata": {},
   "source": [
    "### **3.2. When O n log n beats O n squared**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f93471",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_03_02.jpg?v=1767326575\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Focus on long-term growth, not small inputs\n",
    ">* Beyond a crossover size, n log n dominates\n",
    "\n",
    ">* n squared seems fine small, then explodes\n",
    ">* n log n scales better, despite higher overhead\n",
    "\n",
    ">* Real systems need algorithms that scale efficiently\n",
    ">* n log n stays practical while n squared explodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7306fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - When O n log n beats O n squared\n",
    "\n",
    "# Demonstrate when n log n beats n squared eventually.\n",
    "# Compare simple algorithms with different Big O growth behaviors.\n",
    "# Show crossover where n log n becomes faster than n squared.\n",
    "\n",
    "# pip install numpy matplotlib seaborn.\n",
    "\n",
    "# Import required standard math module for logarithms.\n",
    "import math\n",
    "\n",
    "# Define function that simulates O(n log n) operations.\n",
    "def work_n_log_n(n):\n",
    "    total = 0\n",
    "    for i in range(1, n + 1):\n",
    "        steps = int(math.log2(i + 1))\n",
    "        for _ in range(steps):\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "# Define function that simulates O(n squared) operations.\n",
    "def work_n_squared(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        for _ in range(n):\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "# Choose input sizes that stay small but still illustrative.\n",
    "input_sizes = [50, 100, 200, 400, 800]\n",
    "\n",
    "# Prepare header explaining printed comparison values.\n",
    "print(\"n, n_log_n_steps, n_squared_steps\")\n",
    "\n",
    "# Loop through sizes and compute simulated operation counts.\n",
    "for n in input_sizes:\n",
    "    steps_nlogn = work_n_log_n(n)\n",
    "    steps_n2 = work_n_squared(n)\n",
    "    print(n, steps_nlogn, steps_n2)\n",
    "\n",
    "# Print final note highlighting when n log n becomes smaller.\n",
    "print(\"Notice n squared grows faster than n log n as n increases.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602698b9",
   "metadata": {},
   "source": [
    "### **3.3. Dropping Constants and Terms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549cd43",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master Python Algorithms/Module_02/Lecture_A/image_03_03.jpg?v=1767326592\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Focus on how runtime grows with input\n",
    ">* Ignore constants; dominant term defines complexity class\n",
    "\n",
    ">* Fixed setup costs matter less as inputs grow\n",
    ">* Same linear scaling means same Big-O class\n",
    "\n",
    ">* n log n outgrows n squared eventually\n",
    ">* Dominant term predicts long-term scalability and usability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675217c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Dropping Constants and Terms\n",
    "\n",
    "# Demonstrate why constants and smaller terms are ignored in Big O comparisons.\n",
    "# Compare two linear functions with different constant multipliers and extra terms.\n",
    "# Show that growth pattern, not constants, determines Big O classification.\n",
    "\n",
    "# pip install numpy matplotlib.\n",
    "\n",
    "# Import time module for simple timing measurements.\n",
    "import time\n",
    "\n",
    "# Define a simple linear style function with smaller constant factor.\n",
    "def process_orders_linear(n):\n",
    "    total = 0\n",
    "    for _ in range(n):\n",
    "        total += 1\n",
    "    return total\n",
    "\n",
    "# Define another linear style function with larger constant factor.\n",
    "def process_orders_linear_heavy(n):\n",
    "    total = 0\n",
    "    for _ in range(3 * n):\n",
    "        total += 1\n",
    "    return total\n",
    "\n",
    "# Helper function measuring runtime for a given function and input size.\n",
    "def measure_runtime(func, n):\n",
    "    start = time.perf_counter()\n",
    "    func(n)\n",
    "    end = time.perf_counter()\n",
    "    return end - start\n",
    "\n",
    "# Choose several input sizes representing number of customer orders.\n",
    "input_sizes = [1_000, 5_000, 10_000, 50_000]\n",
    "\n",
    "# Print header explaining upcoming comparison results.\n",
    "print(\"n, time_linear, time_heavy, heavy_divided_by_three\")\n",
    "\n",
    "# Loop through sizes and compare runtimes for both functions.\n",
    "for n in input_sizes:\n",
    "    t1 = measure_runtime(process_orders_linear, n)\n",
    "    t2 = measure_runtime(process_orders_linear_heavy, n)\n",
    "    ratio_adjusted = t2 / 3\n",
    "    print(f\"{n}, {t1:.6f}, {t2:.6f}, {ratio_adjusted:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a3a5b",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Big-O Basics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424fee9",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Explain the meaning of Big-O, Big-Theta, and Big-Omega in the context of algorithm analysis. \n",
    "- Determine the time complexity class of simple Python functions by inspecting their structure. \n",
    "- Compare two algorithms using Big-O notation to justify which is asymptotically more efficient. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Math For Analysis'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
