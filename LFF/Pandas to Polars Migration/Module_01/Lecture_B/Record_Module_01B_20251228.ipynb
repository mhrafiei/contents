{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f376963",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Pandas vs Polars**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fbefa",
   "metadata": {},
   "source": [
    ">Last update: 20251228.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Compare the core data structures and execution models of Pandas and Polars. \n",
    "- Explain how Polars’ lazy and eager APIs relate to typical Pandas workflows. \n",
    "- Identify common areas where Pandas habits may not map directly to Polars. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29700bf7",
   "metadata": {},
   "source": [
    "## **1. Core Data Structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e6334",
   "metadata": {},
   "source": [
    "### **1.1. Pandas Core Structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab8c42",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_01_01.jpg?v=1766974710\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pandas centers on Series and DataFrames\n",
    ">* Aligned Series make table-like analysis operations easy\n",
    "\n",
    ">* Index labels rows with meaningful identifiers\n",
    ">* Index drives alignment, joins, and reshaping behavior\n",
    "\n",
    ">* Pandas uses NumPy arrays and vectorized operations\n",
    ">* Fast in-memory, single-threaded, eager but limited scalability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Pandas Core Structures\n",
    "\n",
    "# Demonstrate Pandas Series and DataFrame core structures clearly.\n",
    "# Show labeled index behavior and automatic alignment during operations.\n",
    "# Highlight eager execution and NumPy backed column oriented storage.\n",
    "\n",
    "# pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm.\n",
    "\n",
    "# Import pandas library for Series and DataFrame structures.\n",
    "import pandas as pd\n",
    "\n",
    "# Create a simple Series with labeled index values.\n",
    "sales_series = pd.Series([100, 150, 200], index=[\"Mon\", \"Tue\", \"Wed\"])\n",
    "\n",
    "# Create another Series with overlapping and missing index labels.\n",
    "returns_series = pd.Series([5, 7], index=[\"Mon\", \"Wed\"])\n",
    "\n",
    "# Create a DataFrame from multiple aligned Series columns.\n",
    "store_df = pd.DataFrame({\"sales_dollars\": sales_series, \"returns_dollars\": returns_series})\n",
    "\n",
    "# Print the Series objects to show labeled one dimensional arrays.\n",
    "print(\"Sales Series with index labels:\\n\", sales_series)\n",
    "\n",
    "# Print the DataFrame to show aligned Series forming a table.\n",
    "print(\"\\nStore DataFrame with aligned columns:\\n\", store_df)\n",
    "\n",
    "# Show automatic index based alignment during arithmetic operations.\n",
    "net_series = sales_series - returns_series\n",
    "\n",
    "# Print the result highlighting alignment and missing value handling.\n",
    "print(\"\\nNet sales after returns by day:\\n\", net_series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48301df1",
   "metadata": {},
   "source": [
    "### **1.2. Polars Series and DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241974f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_01_02.jpg?v=1766974736\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Series are typed columns; DataFrames group Series\n",
    ">* Column-first design enables fast, whole-column operations\n",
    "\n",
    ">* Polars stores columns in contiguous, columnar memory\n",
    ">* Columnar layout enables fast vectorized, column-wise operations\n",
    "\n",
    ">* Series can store nested, complex column values\n",
    ">* Keeps hierarchical data intact for efficient analytics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb04889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Polars Series and DataFrames\n",
    "\n",
    "# Demonstrate basic Polars Series and DataFrame usage clearly.\n",
    "# Show strongly typed columns and column wise operations simply.\n",
    "# Compare Series and DataFrame views for beginner understanding.\n",
    "\n",
    "# pip install polars.\n",
    "\n",
    "# Import polars library with conventional alias pl.\n",
    "import polars as pl\n",
    "\n",
    "# Create a Polars Series representing customer ages.\n",
    "ages_series = pl.Series(name=\"age_years\", values=[25, 32, 40, 28])\n",
    "\n",
    "# Create another Series representing purchase amounts in dollars.\n",
    "amount_series = pl.Series(name=\"purchase_usd\", values=[19.5, 45.0, 13.0, 27.5])\n",
    "\n",
    "# Build a DataFrame from the two Series objects together.\n",
    "df = pl.DataFrame({\"age_years\": ages_series, \"purchase_usd\": amount_series})\n",
    "\n",
    "# Print the Series to show single column structure.\n",
    "print(\"Polars Series example:\\n\", ages_series)\n",
    "\n",
    "# Print the DataFrame to show multiple aligned Series columns.\n",
    "print(\"\\nPolars DataFrame example:\\n\", df)\n",
    "\n",
    "# Add a new column using whole column arithmetic operations.\n",
    "df_with_tax = df.with_columns((pl.col(\"purchase_usd\") * 1.07).alias(\"with_tax_usd\"))\n",
    "\n",
    "# Show resulting DataFrame emphasizing column oriented transformation.\n",
    "print(\"\\nDataFrame with tax column:\\n\", df_with_tax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e302c7b",
   "metadata": {},
   "source": [
    "### **1.3. Arrow Columnar Foundations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865d93b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_01_03.jpg?v=1766974755\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars uses Apache Arrow’s columnar memory layout\n",
    ">* Column-wise storage speeds common analytical data operations\n",
    "\n",
    ">* Shared Arrow format enables low-copy data exchange\n",
    ">* Column layout boosts CPU efficiency and vectorization\n",
    "\n",
    ">* Think in typed columns with clear representations\n",
    ">* Shared Arrow model boosts scalability, speed, interoperability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a38688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Arrow Columnar Foundations\n",
    "\n",
    "# Show how columnar data speeds column operations using Polars and Arrow foundations.\n",
    "# Compare column wise operations with row wise style using simple numeric example.\n",
    "# Help beginners connect Arrow column layout with faster analytical style computations.\n",
    "\n",
    "# !pip install polars pyarrow.\n",
    "\n",
    "# Import required libraries for Polars DataFrame creation and timing demonstration.\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Create small example data representing daily temperatures in Fahrenheit degrees.\n",
    "data = {\"day\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"], \"temp_f\": [70, 72, 68, 75, 71]}\n",
    "\n",
    "# Build Polars DataFrame which internally uses Arrow style columnar memory layout.\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Show DataFrame so learners see columns stored and processed together conceptually.\n",
    "print(\"Polars DataFrame with columnar layout:\")\n",
    "print(df)\n",
    "\n",
    "# Compute average temperature using vectorized column operation over contiguous memory.\n",
    "start_column = time.time()\n",
    "avg_temp_column = df[\"temp_f\"].mean()\n",
    "end_column = time.time()\n",
    "\n",
    "# Simulate row wise style by looping through values and summing manually in Python.\n",
    "start_row = time.time()\n",
    "manual_sum = 0\n",
    "for value in df[\"temp_f\"]:\n",
    "    manual_sum += value\n",
    "avg_temp_row = manual_sum / len(df[\"temp_f\"])\n",
    "end_row = time.time()\n",
    "\n",
    "# Print both averages to confirm identical numerical results from both computation styles.\n",
    "print(\"\\nAverage temperature using column operation:\", avg_temp_column)\n",
    "print(\"Average temperature using row style loop:\", avg_temp_row)\n",
    "\n",
    "# Print rough timing comparison to highlight efficiency of column wise vectorized operations.\n",
    "print(\"\\nColumn operation time seconds:\", round(end_column - start_column, 7))\n",
    "print(\"Row loop operation time seconds:\", round(end_row - start_row, 7))\n",
    "\n",
    "# Show that selecting a column returns Series representing contiguous Arrow backed values.\n",
    "print(\"\\nTemperature column as Polars Series:\")\n",
    "print(df[\"temp_f\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb247",
   "metadata": {},
   "source": [
    "## **2. Polars Execution Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c208fa3",
   "metadata": {},
   "source": [
    "### **2.1. Rowwise to columnar shift**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fa04b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_02_01.jpg?v=1766974781\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Shift mindset from row-based to column-based thinking\n",
    ">* Column storage boosts performance, parallelism, and clarity\n",
    "\n",
    ">* Row mindset loops through individual sales transactions\n",
    ">* Column mindset applies vectorized operations for performance\n",
    "\n",
    ">* Avoid row-by-row loops; think in columns\n",
    ">* Use column expressions for faster, clearer transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Rowwise to columnar shift\n",
    "\n",
    "# Demonstrate shifting from rowwise thinking to columnwise thinking using Polars.\n",
    "# Compare a manual loop style with a vectorized column expression style.\n",
    "# Show how whole column operations replace per row calculations efficiently.\n",
    "# !pip install polars.\n",
    "\n",
    "# Import required Polars library for columnar data operations.\n",
    "import polars as pl\n",
    "\n",
    "# Create small sales dataset with store, quantity, and unit price columns.\n",
    "data = {\"store\": [\"A\", \"A\", \"B\", \"B\"], \"quantity\": [2, 5, 1, 3], \"price_usd\": [10.0, 8.0, 12.0, 7.5]}\n",
    "\n",
    "# Build Polars DataFrame from the dictionary data structure.\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Show original DataFrame to understand the starting point structure.\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Simulate rowwise mindset using explicit Python loop calculations.\n",
    "row_totals = []\n",
    "\n",
    "# Loop through each row and compute revenue manually per transaction.\n",
    "for row in df.iter_rows():\n",
    "    store, quantity, price_usd = row\n",
    "    row_totals.append(quantity * price_usd)\n",
    "\n",
    "# Print manual rowwise revenue results for comparison purposes.\n",
    "print(\"\\nRowwise revenue list:\", row_totals)\n",
    "\n",
    "# Use columnar mindset by defining a new revenue column expression.\n",
    "df_columnar = df.with_columns((pl.col(\"quantity\") * pl.col(\"price_usd\")).alias(\"revenue_usd\"))\n",
    "\n",
    "# Print DataFrame with new revenue column computed columnwise.\n",
    "print(\"\\nColumnar revenue DataFrame:\\n\", df_columnar)\n",
    "\n",
    "# Show total revenue using a single column aggregation expression.\n",
    "print(\"\\nTotal revenue using columnar aggregation:\", df_columnar[\"revenue_usd\"].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d0c6c4",
   "metadata": {},
   "source": [
    "### **2.2. Lazy Query Planning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a717e1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_02_02.jpg?v=1766974801\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars records steps as a logical plan\n",
    ">* Execution is deferred to optimize the whole pipeline\n",
    "\n",
    ">* Lazy workflows replace immediate, stepwise feedback loops\n",
    ">* Planner reorders steps to minimize data processing\n",
    "\n",
    ">* Planner optimizes, parallelizes, and reuses computations\n",
    ">* Describe pipeline once, execute efficiently only when needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Lazy Query Planning\n",
    "\n",
    "# Demonstrate lazy query planning with simple Polars example.\n",
    "# Compare building a plan versus immediately executing steps.\n",
    "# Show when work actually happens during lazy and eager operations.\n",
    "\n",
    "# !pip install polars pyarrow fsspec.\n",
    "\n",
    "# Import required libraries for data handling and timing.\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Create a small example dataset representing daily miles driven.\n",
    "data = {\n",
    "    \"day\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n",
    "    \"miles\": [30, 42, 25, 60, 55],\n",
    "}\n",
    "\n",
    "# Build an eager DataFrame that executes operations immediately.\n",
    "df_eager = pl.DataFrame(data)\n",
    "\n",
    "# Build a lazy DataFrame that records a plan only.\n",
    "df_lazy = df_eager.lazy()\n",
    "\n",
    "# Define a helper function to time any callable execution.\n",
    "def time_call(label, func):\n",
    "    start = time.time()\n",
    "    result = func()\n",
    "    duration = time.time() - start\n",
    "    print(f\"{label}: {duration:.6f} seconds\")\n",
    "    return result\n",
    "\n",
    "# Time an eager filter and average miles computation.\n",
    "print(\"Eager execution starts immediately below.\")\n",
    "result_eager = time_call(\n",
    "    \"Eager filter and average\",\n",
    "    lambda: df_eager.filter(pl.col(\"miles\") > 40).select(pl.col(\"miles\").mean()),\n",
    ")\n",
    "\n",
    "# Show eager result printed directly.\n",
    "print(\"Eager result DataFrame below.\")\n",
    "print(result_eager)\n",
    "\n",
    "# Build a lazy plan with multiple chained operations.\n",
    "print(\"Building lazy plan without execution.\")\n",
    "lazy_plan = df_lazy.filter(pl.col(\"miles\") > 40).select(pl.col(\"miles\").mean())\n",
    "\n",
    "# Time the collection step that triggers lazy execution.\n",
    "print(\"Lazy execution happens only on collect call.\")\n",
    "result_lazy = time_call(\"Lazy collect call\", lambda: lazy_plan.collect())\n",
    "\n",
    "# Show lazy result printed directly for comparison.\n",
    "print(\"Lazy result DataFrame below.\")\n",
    "print(result_lazy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd366f7",
   "metadata": {},
   "source": [
    "### **2.3. Eager API Parallels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfb16e",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_02_03.jpg?v=1766974821\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Eager mode feels familiar to Pandas users\n",
    ">* Supports quick, interactive work while bridging to optimization\n",
    "\n",
    ">* Eager mode still uses column-based expressions\n",
    ">* Interactive work trains you for lazy pipelines\n",
    "\n",
    ">* Start with eager Polars as familiar replacement\n",
    ">* Later refactor eager steps into lazy pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c11b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Eager API Parallels\n",
    "\n",
    "# Demonstrate Polars eager API parallels with familiar Pandas style operations.\n",
    "# Show immediate execution when filtering, selecting, and creating new derived columns.\n",
    "# Highlight column expressions that feel familiar yet use Polars efficient engine.\n",
    "\n",
    "# !pip install polars pandas matplotlib.\n",
    "\n",
    "# Import required libraries for data handling and plotting.\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create small customer dataset using a Python dictionary.\n",
    "data = {\n",
    "    \"customer_id\": [1, 2, 3, 4],\n",
    "    \"visits_per_week\": [1, 3, 5, 2],\n",
    "    \"spend_dollars\": [20.0, 55.0, 120.0, 35.0],\n",
    "}\n",
    "\n",
    "# Build a Pandas DataFrame to show familiar starting point.\n",
    "pd_df = pd.DataFrame(data)\n",
    "\n",
    "# Build a Polars DataFrame using the same dictionary data.\n",
    "pl_df = pl.DataFrame(data)\n",
    "\n",
    "# Use Pandas eagerly to create a new column with weekly revenue estimate.\n",
    "pd_df[\"weekly_revenue\"] = pd_df[\"visits_per_week\"] * pd_df[\"spend_dollars\"]\n",
    "\n",
    "# Use Polars eager API with column expression for same calculation.\n",
    "pl_df = pl_df.with_columns(\n",
    "    (pl.col(\"visits_per_week\") * pl.col(\"spend_dollars\")).alias(\"weekly_revenue\")\n",
    ")\n",
    "\n",
    "# Filter frequent visitors in Pandas using boolean indexing eagerly.\n",
    "pd_frequent = pd_df[pd_df[\"visits_per_week\"] >= 3]\n",
    "\n",
    "# Filter frequent visitors in Polars using expression based filter eagerly.\n",
    "pl_frequent = pl_df.filter(pl.col(\"visits_per_week\") >= 3)\n",
    "\n",
    "# Print both filtered tables to compare familiar eager style outputs.\n",
    "print(\"Pandas frequent visitors table:\\n\", pd_frequent)\n",
    "print(\"\\nPolars frequent visitors table:\\n\", pl_frequent)\n",
    "\n",
    "# Plot weekly revenue from Polars to show immediate visual feedback.\n",
    "plt.bar(pl_df[\"customer_id\"].to_list(), pl_df[\"weekly_revenue\"].to_list())\n",
    "plt.xlabel(\"Customer identifier code\")\n",
    "plt.ylabel(\"Weekly revenue dollars\")\n",
    "plt.title(\"Weekly revenue per customer using Polars eager mode\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf87790",
   "metadata": {},
   "source": [
    "## **3. Polars Ecosystem Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416af561",
   "metadata": {},
   "source": [
    "### **3.1. NumPy and Arrow Bridges**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02210a8e",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_03_01.jpg?v=1766974859\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars columns are Arrow arrays, not NumPy\n",
    ">* Convert only needed columns to NumPy endpoints\n",
    "\n",
    ">* Polars works directly on Arrow-based columnar data\n",
    ">* Keep Arrow format, convert small NumPy slices\n",
    "\n",
    ">* Arrow enforces strict types, nulls, and nesting\n",
    ">* Conversions to NumPy can lose structure and performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e99a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - NumPy and Arrow Bridges\n",
    "\n",
    "# Demonstrate Polars Arrow backbone and NumPy conversion boundary clearly.\n",
    "# Show efficient Polars operations before converting small slices to NumPy arrays.\n",
    "# Highlight that conversion is explicit, not automatic, between ecosystems.\n",
    "# !pip install polars pyarrow numpy.\n",
    "\n",
    "# Import required libraries for Polars, Arrow, and NumPy interoperability.\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "\n",
    "# Create a small Polars DataFrame representing hourly energy loads.\n",
    "data = {\n",
    "    \"hour\": np.arange(0, 6, 1),\n",
    "    \"load_kw\": np.array([10.0, 12.5, 11.0, 13.5, 14.0, 15.5]),\n",
    "}\n",
    "\n",
    "# Build the Polars DataFrame using Arrow friendly columnar structures.\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Show the Polars DataFrame to confirm Arrow backed tabular structure.\n",
    "print(\"Polars DataFrame (Arrow backed):\")\n",
    "print(df)\n",
    "\n",
    "# Perform an efficient Polars operation before any NumPy conversion.\n",
    "df_summary = df.select([\n",
    "    pl.col(\"load_kw\").mean().alias(\"mean_load_kw\"),\n",
    "    pl.col(\"load_kw\").std().alias(\"std_load_kw\"),\n",
    "])\n",
    "\n",
    "# Display the summary to emphasize staying in Polars for analytics.\n",
    "print(\"\\nPolars summary before NumPy conversion:\")\n",
    "print(df_summary)\n",
    "\n",
    "# Extract only the load column as a NumPy array for numerical solver usage.\n",
    "load_numpy = df[\"load_kw\"].to_numpy()\n",
    "\n",
    "# Show the NumPy array, highlighting explicit boundary crossing step.\n",
    "print(\"\\nNumPy array used for numerical solver:\")\n",
    "print(load_numpy)\n",
    "\n",
    "# Convert the Polars column to a PyArrow array, the natural bridge format.\n",
    "load_arrow = df[\"load_kw\"].to_arrow()\n",
    "\n",
    "# Display Arrow array type information, showing richer metadata and structure.\n",
    "print(\"\\nArrow array type and values:\")\n",
    "print(load_arrow, \"| type:\", load_arrow.type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea834cdb",
   "metadata": {},
   "source": [
    "### **3.2. File Formats in Polars**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41beb9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_03_02.jpg?v=1766974883\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pandas users often default to CSV files\n",
    ">* Polars favors Parquet or Arrow for performance\n",
    "\n",
    ">* Polars prefers files with clear, fixed schemas\n",
    ">* Stricter typing exposes messy, mixed-type CSV data\n",
    "\n",
    ">* Prefer columnar formats throughout most data pipelines\n",
    ">* Avoid CSV-centric habits to unlock Polars performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - File Formats in Polars\n",
    "\n",
    "# Show Polars reading CSV versus Parquet performance and schema clarity.\n",
    "# Highlight how columnar formats preserve data types and improve speed.\n",
    "# Encourage preferring Parquet over CSV for larger analytic workflows.\n",
    "\n",
    "# !pip install polars pyarrow fastparquet.\n",
    "\n",
    "# Import required libraries for data handling and timing.\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Create a small example DataFrame with mixed realistic columns.\n",
    "df = pl.DataFrame({\"city\": [\"Boston\", \"Dallas\", \"Denver\", \"Seattle\"], \"temp_f\": [70.5, 88.2, 65.0, 59.3], \"visitors\": [1200, 2300, 900, 1500]})\n",
    "\n",
    "# Define file paths for CSV and Parquet outputs.\n",
    "csv_path = \"example_weather.csv\"\n",
    "parquet_path = \"example_weather.parquet\"\n",
    "\n",
    "# Save the DataFrame as a CSV text file.\n",
    "df.write_csv(csv_path)\n",
    "\n",
    "# Save the same DataFrame as a Parquet columnar file.\n",
    "df.write_parquet(parquet_path)\n",
    "\n",
    "# Time reading the CSV file using Polars read_csv function.\n",
    "start_csv = time.time(); df_csv = pl.read_csv(csv_path); csv_time = time.time() - start_csv\n",
    "\n",
    "# Time reading the Parquet file using Polars read_parquet function.\n",
    "start_parquet = time.time(); df_parquet = pl.read_parquet(parquet_path); parquet_time = time.time() - start_parquet\n",
    "\n",
    "# Print basic timing comparison for both file formats.\n",
    "print(\"CSV read seconds:\", round(csv_time, 6))\n",
    "print(\"Parquet read seconds:\", round(parquet_time, 6))\n",
    "\n",
    "# Show inferred schema when reading from CSV text format.\n",
    "print(\"CSV schema:\", df_csv.schema)\n",
    "\n",
    "# Show preserved schema when reading from Parquet columnar format.\n",
    "print(\"Parquet schema:\", df_parquet.schema)\n",
    "\n",
    "# Display both DataFrames to confirm identical values and structures.\n",
    "print(\"CSV data:\", df_csv)\n",
    "print(\"Parquet data:\", df_parquet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e731b6",
   "metadata": {},
   "source": [
    "### **3.3. Tooling and Library Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174bacc",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_03_03.jpg?v=1766974994\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Most tools assume inputs are Pandas DataFrames\n",
    ">* With Polars, you must manage conversions explicitly\n",
    "\n",
    ">* ML libraries expect Pandas-specific DataFrame behaviors\n",
    ">* With Polars, explicitly convert and validate model inputs\n",
    "\n",
    ">* Pandas-focused debugging and profiling tools may break\n",
    ">* Polars needs explicit execution and new inspection habits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f752fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tooling and Library Integration\n",
    "\n",
    "# Demonstrate Polars integration with plotting and modeling tools.\n",
    "# Show where conversions from Polars to Pandas are needed.\n",
    "# Highlight explicit data contracts at tool boundaries.\n",
    "\n",
    "# !pip install polars pandas matplotlib scikit-learn.\n",
    "\n",
    "# Import required libraries for data, plotting, and modeling.\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a simple Polars DataFrame with miles and gallons columns.\n",
    "data_pl = pl.DataFrame({\"miles_driven\":[10,20,30,40],\"gallons_used\":[1,2,2,3]})\n",
    "\n",
    "# Show that Polars prints fine but some tools expect Pandas DataFrames.\n",
    "print(\"Polars DataFrame preview:\")\n",
    "print(data_pl.head(3))\n",
    "\n",
    "# Convert Polars DataFrame to Pandas for plotting compatibility.\n",
    "data_pd = data_pl.to_pandas()\n",
    "\n",
    "# Create a simple scatter plot using Pandas compatible Matplotlib.\n",
    "plt.scatter(data_pd[\"miles_driven\"],data_pd[\"gallons_used\"],color=\"blue\")\n",
    "plt.xlabel(\"Miles driven (miles)\")\n",
    "plt.ylabel(\"Gallons used (gallons)\")\n",
    "plt.title(\"Fuel usage scatter plot example\")\n",
    "plt.show()\n",
    "\n",
    "# Prepare feature matrix and target vector for modeling library.\n",
    "X = data_pd[[\"miles_driven\"]].values\n",
    "y = data_pd[\"gallons_used\"].values\n",
    "\n",
    "# Fit a simple linear regression model using scikit learn.\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "# Print learned slope and intercept to show successful integration.\n",
    "print(\"Model slope gallons per mile:\",model.coef_[0])\n",
    "print(\"Model intercept gallons baseline:\",model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58e91b",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Pandas vs Polars**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf68d3a",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Compare the core data structures and execution models of Pandas and Polars. \n",
    "- Explain how Polars’ lazy and eager APIs relate to typical Pandas workflows. \n",
    "- Identify common areas where Pandas habits may not map directly to Polars. \n",
    "\n",
    "In the next Lecture (Lecture C), we will go over 'Setting Up Polars'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
