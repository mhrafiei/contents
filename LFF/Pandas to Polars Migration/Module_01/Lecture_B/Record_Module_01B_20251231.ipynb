{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241f735b",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Pandas vs Polars**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ef773",
   "metadata": {},
   "source": [
    ">Last update: 20251231.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Compare the core data structures and execution models of Pandas and Polars. \n",
    "- Explain how Polars’ lazy and eager APIs relate to typical Pandas workflows. \n",
    "- Identify common areas where Pandas habits may not map directly to Polars. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48429850",
   "metadata": {},
   "source": [
    "## **1. Pandas and Polars structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be3ad2",
   "metadata": {},
   "source": [
    "### **1.1. Pandas Core Structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc09aa4",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_01_01.jpg?v=1767231027\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pandas uses labeled in-memory DataFrame and Series\n",
    ">* Labels enable spreadsheet-like access, alignment, and joins\n",
    "\n",
    ">* DataFrames are column-based Series backed by NumPy\n",
    ">* Fast vectorized operations but limited by RAM\n",
    "\n",
    ">* Pandas runs operations immediately, creating intermediates\n",
    ">* Index-driven alignment shapes behavior, performance, limitations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffa955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Pandas Core Structures\n",
    "\n",
    "# Demonstrate Pandas DataFrame and Series core labeled structures.\n",
    "# Show column oriented storage with row oriented access patterns.\n",
    "# Illustrate eager execution and index based automatic alignment.\n",
    "\n",
    "# !pip install pandas matplotlib seaborn  # Colab already includes these libraries.\n",
    "\n",
    "# Import pandas library for DataFrame and Series structures.\n",
    "import pandas as pd\n",
    "\n",
    "# Create simple patient records as a Python dictionary.\n",
    "patient_data = {\"age_years\": [30, 45, 60], \"days_stayed\": [3, 5, 2]}\n",
    "\n",
    "# Build a DataFrame with custom index labels for patients.\n",
    "patients_df = pd.DataFrame(patient_data, index=[\"patient_A\", \"patient_B\", \"patient_C\"])\n",
    "\n",
    "# Select a single labeled column as a Series object.\n",
    "age_series = patients_df[\"age_years\"]\n",
    "\n",
    "# Print the full DataFrame showing labeled rows and columns.\n",
    "print(\"Full patients DataFrame with labeled index and columns:\")\n",
    "print(patients_df)\n",
    "\n",
    "# Print the age Series to highlight one dimensional labeled structure.\n",
    "print(\"\\nAge Series extracted from DataFrame structure:\")\n",
    "print(age_series)\n",
    "\n",
    "# Create another Series with overlapping index labels for alignment.\n",
    "extra_days = pd.Series({\"patient_A\": 1, \"patient_C\": 2})\n",
    "\n",
    "# Add Series objects to show index based automatic alignment behavior.\n",
    "adjusted_stay = patients_df[\"days_stayed\"] + extra_days\n",
    "\n",
    "# Print the result showing aligned addition and missing value handling.\n",
    "print(\"\\nAdjusted stay length after adding extra days by index:\")\n",
    "print(adjusted_stay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59261980",
   "metadata": {},
   "source": [
    "### **1.2. Polars Core Structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adeaed6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_01_02.jpg?v=1767231050\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars DataFrame is column-based and Arrow-backed\n",
    ">* Column layout enables fast, parallel analytics at scale\n",
    "\n",
    ">* Series are typed, column-based units of computation\n",
    ">* Arrow-backed Series enable fast, reliable large-scale operations\n",
    "\n",
    ">* Expressions describe column operations before running\n",
    ">* Engine optimizes whole plans for scalable performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bf37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Polars Core Structures\n",
    "\n",
    "# Demonstrate Polars DataFrame, Series, and expressions basics.\n",
    "# Show columnar operations on small tabular customer transactions.\n",
    "# Compare direct Series math with expression based lazy style.\n",
    "\n",
    "# !pip install polars pyarrow.\n",
    "\n",
    "# Import polars library for DataFrame and Series structures.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small DataFrame with typed columns and rows.\n",
    "transactions_df = pl.DataFrame({\"customer_id\": [1, 2, 1], \"amount_usd\": [20.0, 35.5, 15.0], \"items\": [2, 3, 1]})\n",
    "\n",
    "# Show the DataFrame structure and column types briefly.\n",
    "print(\"Polars DataFrame structure and data:\")\n",
    "print(transactions_df)\n",
    "\n",
    "# Access a single column as a Series structure object.\n",
    "amount_series = transactions_df[\"amount_usd\"]\n",
    "\n",
    "# Show the Series to highlight columnar typed data behavior.\n",
    "print(\"\\nAmount Series values and type:\")\n",
    "print(amount_series)\n",
    "\n",
    "# Perform a vectorized Series operation using columnar contiguous memory.\n",
    "amount_with_tax = amount_series * 1.07\n",
    "\n",
    "# Print the computed Series to show efficient column wide math.\n",
    "print(\"\\nAmount Series with seven_percent tax:\")\n",
    "print(amount_with_tax)\n",
    "\n",
    "# Build an expression that computes revenue per item lazily.\n",
    "revenue_per_item_expr = (pl.col(\"amount_usd\") / pl.col(\"items\")).alias(\"revenue_per_item\")\n",
    "\n",
    "# Use select with expression to create optimized computation plan.\n",
    "result_df = transactions_df.select([\"customer_id\", revenue_per_item_expr])\n",
    "\n",
    "# Print final DataFrame showing expression based computation result.\n",
    "print(\"\\nRevenue per item computed using expressions:\")\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06204f77",
   "metadata": {},
   "source": [
    "### **1.3. Columnar Arrow Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0627dc",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_01_03.jpg?v=1767231096\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Columnar layout stores each column in blocks\n",
    ">* Arrow standardizes columnar memory, enabling zero-copy sharing\n",
    "\n",
    ">* Columnar Arrow layout enables fast, cache-friendly scans\n",
    ">* Metadata helps Polars optimize analytical operations efficiently\n",
    "\n",
    ">* Arrow lets tools share data without copying\n",
    ">* Enables declarative pipelines and Polars’ lazy execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac1c5b",
   "metadata": {},
   "source": [
    "## **2. Polars Execution Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1f6c6",
   "metadata": {},
   "source": [
    "### **2.1. Rowwise Versus Columnar**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027de7ba",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_02_01.jpg?v=1767231115\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Shift mindset from row-based to column-based thinking\n",
    ">* Column operations enable faster, optimized Polars execution\n",
    "\n",
    ">* Rowwise thinking processes one record at once\n",
    ">* Polars optimizes whole-column operations using lazy planning\n",
    "\n",
    ">* Row-based custom loops don’t translate efficiently\n",
    ">* Use column expressions to exploit Polars optimizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Rowwise Versus Columnar\n",
    "\n",
    "# Demonstrate rowwise thinking versus columnar thinking using Polars expressions.\n",
    "# Show how per row loops differ from whole column operations conceptually.\n",
    "# Keep the example small, clear, and beginner friendly for Colab users.\n",
    "\n",
    "# !pip install polars pyarrow fsspec connectorx if needed in local environments.\n",
    "\n",
    "# Import Polars for columnar DataFrame operations.\n",
    "import polars as pl\n",
    "\n",
    "# Create a tiny transactions DataFrame with three simple columns.\n",
    "transactions = pl.DataFrame({\"customer_id\": [1, 1, 2, 2], \"amount_usd\": [5, 20, 50, 7], \"is_online\": [True, False, True, False]})\n",
    "\n",
    "# Show the original data to understand the starting point clearly.\n",
    "print(\"Original transactions DataFrame:\\n\", transactions)\n",
    "\n",
    "# Imagine rowwise thinking as checking each record one by one conceptually.\n",
    "print(\"\\nConceptual rowwise thinking: check each transaction record individually.\")\n",
    "\n",
    "# Columnar thinking uses expressions that operate on whole columns at once.\n",
    "flagged = transactions.with_columns([\n",
    "    pl.when((pl.col(\"amount_usd\") > 10) & (pl.col(\"is_online\") == True)).then(True).otherwise(False).alias(\"flag_suspicious\")\n",
    "])\n",
    "\n",
    "# Show the new column created using columnar expressions instead of Python loops.\n",
    "print(\"\\nColumnar result with suspicious flag column:\\n\", flagged)\n",
    "\n",
    "# Group by customer to aggregate flagged transactions using columnar operations.\n",
    "summary = flagged.group_by(\"customer_id\").agg([\n",
    "    pl.col(\"flag_suspicious\").sum().alias(\"suspicious_count\"),\n",
    "    pl.col(\"amount_usd\").sum().alias(\"total_amount_usd\")\n",
    "])\n",
    "\n",
    "# Display the summary to highlight efficient column based aggregation behavior.\n",
    "print(\"\\nColumnar customer summary with counts and totals:\\n\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04463c34",
   "metadata": {},
   "source": [
    "### **2.2. Lazy Query Planning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406fd5e4",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_02_02.jpg?v=1767231137\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars records a plan instead of executing\n",
    ">* Engine optimizes whole pipeline before running once\n",
    "\n",
    ">* Lazy pipelines replace many intermediate DataFrames\n",
    ">* Engine reorders steps to cut work and memory\n",
    "\n",
    ">* Design full pipelines, then run them once\n",
    ">* Trust lazy optimization, think declaratively for scalability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ea954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Lazy Query Planning\n",
    "\n",
    "# Demonstrate Polars lazy planning versus eager Pandas style operations.\n",
    "# Show that Polars builds a plan before executing transformations.\n",
    "# Compare when work actually happens and what gets printed.\n",
    "\n",
    "# !pip install polars pandas.\n",
    "\n",
    "# Import required libraries for dataframes and lazy queries.\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create a small Pandas DataFrame with simple transaction data.\n",
    "pd_df = pd.DataFrame({\"customer\":[\"A\",\"A\",\"B\",\"B\"],\"amount\":[10,20,5,40]})\n",
    "\n",
    "# Perform eager Pandas operations that run immediately and create intermediates.\n",
    "pd_filtered = pd_df[pd_df[\"amount\"] > 10]\n",
    "pd_grouped = pd_filtered.groupby(\"customer\")[\"amount\"].sum()\n",
    "\n",
    "# Print Pandas result showing eager execution and intermediate materialization.\n",
    "print(\"Pandas eager result:\")\n",
    "print(pd_grouped)\n",
    "\n",
    "# Create an equivalent Polars DataFrame from the same data dictionary.\n",
    "pl_df = pl.DataFrame({\"customer\":[\"A\",\"A\",\"B\",\"B\"],\"amount\":[10,20,5,40]})\n",
    "\n",
    "# Build a lazy query that only describes the transformation pipeline steps.\n",
    "lazy_query = (\n",
    "    pl_df.lazy()\n",
    "    .filter(pl.col(\"amount\") > 10)\n",
    "    .group_by(\"customer\")\n",
    "    .agg(pl.col(\"amount\").sum())\n",
    ")\n",
    "\n",
    "# Print the lazy plan to show recorded operations without actual execution.\n",
    "print(\"\\nPolars lazy plan only:\")\n",
    "print(lazy_query.explain())\n",
    "\n",
    "# Trigger execution explicitly to materialize the final Polars result.\n",
    "result = lazy_query.collect()\n",
    "\n",
    "# Print the executed Polars result after the lazy plan runs once.\n",
    "print(\"\\nPolars executed result:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d6c44",
   "metadata": {},
   "source": [
    "### **2.3. Pandas Style Eager Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ff290",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_02_03.jpg?v=1767231159\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Eager Polars runs commands immediately, like Pandas\n",
    ">* Great for stepwise exploration with fast feedback\n",
    "\n",
    ">* Everyday analysis maps easily to eager Polars\n",
    ">* Prototype transformations interactively using a data scratchpad\n",
    "\n",
    ">* Eager workflows can be converted into lazy queries\n",
    ">* Helps transition from interactive exploration to scalable pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd200ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Pandas Style Eager Operations\n",
    "\n",
    "# Demonstrate Polars eager operations similar to familiar Pandas workflows.\n",
    "# Show immediate feedback when filtering, selecting, and creating new columns.\n",
    "# Contrast eager DataFrame with equivalent lazy query execution later.\n",
    "# !pip install polars --quiet.\n",
    "\n",
    "# Import Polars library for columnar DataFrame operations.\n",
    "import polars as pl\n",
    "\n",
    "# Create small sales DataFrame directly inside the script.\n",
    "sales_df = pl.DataFrame({\"day\": [\"Mon\", \"Tue\", \"Tue\", \"Wed\"], \"country\": [\"US\", \"US\", \"CA\", \"US\"], \"device\": [\"mobile\", \"desktop\", \"mobile\", \"mobile\"], \"revenue_usd\": [120.0, 80.0, 50.0, 200.0]})\n",
    "\n",
    "# Show original eager DataFrame to understand starting point.\n",
    "print(\"Original eager DataFrame:\")\n",
    "print(sales_df)\n",
    "\n",
    "# Filter rows eagerly for United States mobile visitors only.\n",
    "filtered_df = sales_df.filter((pl.col(\"country\") == \"US\") & (pl.col(\"device\") == \"mobile\"))\n",
    "\n",
    "# Show filtered result immediately after applying conditions.\n",
    "print(\"\\nFiltered eager DataFrame (US mobile only):\")\n",
    "print(filtered_df)\n",
    "\n",
    "# Add new eager column converting revenue from dollars to cents.\n",
    "with_cents_df = filtered_df.with_columns((pl.col(\"revenue_usd\") * 100).alias(\"revenue_cents\"))\n",
    "\n",
    "# Show updated DataFrame with new derived column included.\n",
    "print(\"\\nEager DataFrame with derived cents column:\")\n",
    "print(with_cents_df)\n",
    "\n",
    "# Build equivalent lazy query using same transformation steps conceptually.\n",
    "lazy_query = sales_df.lazy().filter((pl.col(\"country\") == \"US\") & (pl.col(\"device\") == \"mobile\")).with_columns((pl.col(\"revenue_usd\") * 100).alias(\"revenue_cents\"))\n",
    "\n",
    "# Collect lazy query to execute all steps together efficiently.\n",
    "result_lazy = lazy_query.collect()\n",
    "\n",
    "# Show lazy result matching eager pipeline output for comparison.\n",
    "print(\"\\nLazy query result matching eager pipeline:\")\n",
    "print(result_lazy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6deb78",
   "metadata": {},
   "source": [
    "## **3. Ecosystem and Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09510e63",
   "metadata": {},
   "source": [
    "### **3.1. NumPy and Arrow Bridges**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba52ef",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_03_01.jpg?v=1767231191\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Array conversions aren’t always cheap or simple\n",
    ">* Be deliberate choosing when and how to convert\n",
    "\n",
    ">* Old workflows treat tables as array staging\n",
    ">* Modern systems favor Arrow-style columnar data sharing\n",
    "\n",
    ">* Tabular engines can replace many array workflows\n",
    ">* Choose array or columnar formats deliberately for integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7596364",
   "metadata": {},
   "source": [
    "### **3.2. Data IO Differences**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a6911",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_03_02.jpg?v=1767231227\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pandas and Polars handle data IO differently\n",
    ">* Polars favors clean, columnar, high performance pipelines\n",
    "\n",
    ">* Polars favors fast columnar formats like Parquet\n",
    ">* Work with partitioned datasets and immutable outputs\n",
    "\n",
    ">* Reading becomes a deferred, memory efficient plan\n",
    ">* IO steps integrate into one optimized pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d07d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Data IO Differences\n",
    "\n",
    "# Demonstrate different data reading patterns between Pandas and Polars.\n",
    "# Show eager in memory CSV loading versus lazy Parquet style planning.\n",
    "# Highlight how lazy pipelines delay reading until explicit collection or writing.\n",
    "\n",
    "# !pip install pandas polars pyarrow.\n",
    "\n",
    "# Import required libraries for data handling and comparison.\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "\n",
    "# Create a small Pandas DataFrame representing weekly sales data.\n",
    "pd_sales = pd.DataFrame({\"week\":[1,2,3],\"store\":[\"A\",\"A\",\"B\"],\"dollars\":[120.0,150.5,99.9]})\n",
    "\n",
    "# Save the Pandas DataFrame as a CSV file on local storage.\n",
    "pd_sales.to_csv(\"weekly_sales.csv\",index=False)\n",
    "\n",
    "# Save the same data as a Parquet file using Pandas convenience wrapper.\n",
    "pd_sales.to_parquet(\"weekly_sales.parquet\",engine=\"pyarrow\",index=False)\n",
    "\n",
    "# Read CSV eagerly with Pandas, data immediately loaded into memory.\n",
    "pd_eager = pd.read_csv(\"weekly_sales.csv\")\n",
    "\n",
    "# Print a short message showing Pandas eager CSV reading result.\n",
    "print(\"Pandas eager CSV rows:\",len(pd_eager))\n",
    "\n",
    "# Read Parquet lazily with Polars, building a deferred scan plan.\n",
    "pl_lazy = pl.scan_parquet(\"weekly_sales.parquet\")\n",
    "\n",
    "# Show that Polars lazy object represents a plan, not materialized data.\n",
    "print(\"Polars lazy plan type:\",type(pl_lazy))\n",
    "\n",
    "# Add a transformation lazily, filtering weeks with dollars above threshold.\n",
    "pl_filtered = pl_lazy.filter(pl.col(\"dollars\")>110.0)\n",
    "\n",
    "# Collect materialized result, triggering actual Parquet reading and filtering.\n",
    "pl_result = pl_filtered.collect()\n",
    "\n",
    "# Print number of rows after lazy filter, demonstrating deferred execution.\n",
    "print(\"Polars filtered lazy rows:\",pl_result.height)\n",
    "\n",
    "# Show that original CSV file remains unchanged, emphasizing immutable style.\n",
    "print(\"Original CSV still rows:\",len(pd.read_csv(\"weekly_sales.csv\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4215997",
   "metadata": {},
   "source": [
    "### **3.3. Tooling Compatibility Shifts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1995e7",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_01/Lecture_B/image_03_03.jpg?v=1767231258\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Many tools assume inputs are Pandas DataFrames\n",
    ">* Polars objects may need explicit conversion for compatibility\n",
    "\n",
    ">* Polars pipelines need explicit conversion between tools\n",
    ">* Plan boundaries, data types, and workflow memory carefully\n",
    "\n",
    ">* Lazy execution breaks some Pandas-based tools\n",
    ">* Plan conversions, materialization, and Polars-aware alternatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tooling Compatibility Shifts\n",
    "\n",
    "# Demonstrate Pandas friendly tooling expectations with simple plotting example.\n",
    "# Show Polars requiring explicit conversion before using same plotting tool.\n",
    "# Highlight mental shift around DataFrame types and ecosystem boundaries.\n",
    "\n",
    "# !pip install polars pandas matplotlib.\n",
    "\n",
    "# Import required libraries for data handling and plotting.\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create simple Pandas DataFrame representing car speeds in miles per hour.\n",
    "pd_df = pd.DataFrame({\"car_model\": [\"A\", \"B\", \"C\"], \"speed_mph\": [30, 45, 60]})\n",
    "\n",
    "# Plot directly from Pandas DataFrame using built in plotting support.\n",
    "pd_df.plot(x=\"car_model\", y=\"speed_mph\", kind=\"bar\", title=\"Pandas direct plotting example\")\n",
    "\n",
    "# Show plot before moving to Polars conversion and compatibility shift.\n",
    "plt.show()\n",
    "\n",
    "# Create equivalent Polars DataFrame showing same car speed information.\n",
    "pl_df = pl.DataFrame({\"car_model\": [\"A\", \"B\", \"C\"], \"speed_mph\": [30, 45, 60]})\n",
    "\n",
    "# Convert Polars DataFrame into Pandas DataFrame for plotting compatibility.\n",
    "pl_to_pd_df = pl_df.to_pandas()\n",
    "\n",
    "# Plot converted DataFrame to highlight explicit conversion requirement.\n",
    "pl_to_pd_df.plot(x=\"car_model\", y=\"speed_mph\", kind=\"bar\", title=\"Polars converted plotting example\")\n",
    "\n",
    "# Show second plot and emphasize tooling compatibility shift visually.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893a151",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Pandas vs Polars**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e27c05",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Compare the core data structures and execution models of Pandas and Polars. \n",
    "- Explain how Polars’ lazy and eager APIs relate to typical Pandas workflows. \n",
    "- Identify common areas where Pandas habits may not map directly to Polars. \n",
    "\n",
    "In the next Lecture (Lecture C), we will go over 'Setting Up Polars'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
