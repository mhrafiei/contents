{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dad5092",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Joins and Reshaping**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750bf50",
   "metadata": {},
   "source": [
    ">Last update: 20251227.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Execute common join types in Polars that correspond to Pandas merge operations. \n",
    "- Reshape Polars DataFrames using pivot and melt to match existing Pandas wide‑to‑long and long‑to‑wide transformations. \n",
    "- Diagnose and resolve typical join and reshape issues that arise during migration, such as key mismatches and duplicated columns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc684b9f",
   "metadata": {},
   "source": [
    "## **1. Core Join Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6a2f1",
   "metadata": {},
   "source": [
    "### **1.1. Core Join Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0db94",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_01_01.jpg?v=1766897130\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars joins mirror familiar database join types\n",
    ">* Inner and left joins control which rows remain\n",
    "\n",
    ">* Right joins keep all rows from right table\n",
    ">* Outer joins keep every row from both tables\n",
    "\n",
    ">* Cross joins create all row combinations across tables\n",
    ">* Used rarely for full Cartesian scenarios and comparisons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a59d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Core Join Types\n",
    "\n",
    "# Demonstrate core join types using simple Polars DataFrames.\n",
    "# Compare inner, left, right, outer, and cross joins visually.\n",
    "# Keep outputs small and readable for beginner friendly exploration.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a small left table with customer identifiers and states.\n",
    "left_customers = pl.DataFrame({\"customer_id\": [1, 2, 3], \"state\": [\"NY\", \"CA\", \"TX\"]})\n",
    "\n",
    "# Create a small right table with customer identifiers and total orders.\n",
    "right_orders = pl.DataFrame({\"customer_id\": [2, 3, 4], \"orders\": [5, 2, 7]})\n",
    "\n",
    "# Show the original tables to understand starting information clearly.\n",
    "print(\"Left table customers with states:\")\n",
    "print(left_customers)\n",
    "print(\"\\nRight table customers with orders:\")\n",
    "print(right_orders)\n",
    "\n",
    "# Perform an inner join keeping only matching customer identifiers.\n",
    "inner_join = left_customers.join(right_orders, on=\"customer_id\", how=\"inner\")\n",
    "print(\"\\nInner join keeps overlapping customers only:\")\n",
    "print(inner_join)\n",
    "\n",
    "# Perform a left join keeping all left customers and matching orders.\n",
    "left_join = left_customers.join(right_orders, on=\"customer_id\", how=\"left\")\n",
    "print(\"\\nLeft join keeps all left customers:\")\n",
    "print(left_join)\n",
    "\n",
    "# Perform a right join keeping all right customers and matching states.\n",
    "right_join = left_customers.join(right_orders, on=\"customer_id\", how=\"right\")\n",
    "print(\"\\nRight join keeps all right customers:\")\n",
    "print(right_join)\n",
    "\n",
    "# Perform an outer join keeping every customer from both tables.\n",
    "outer_join = left_customers.join(right_orders, on=\"customer_id\", how=\"outer\")\n",
    "print(\"\\nOuter join keeps all customers from both:\")\n",
    "print(outer_join)\n",
    "\n",
    "# Perform a cross join showing every possible customer and order pairing.\n",
    "cross_join = left_customers.join(right_orders, how=\"cross\")\n",
    "print(\"\\nCross join shows every possible pairing:\")\n",
    "print(cross_join)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb242a",
   "metadata": {},
   "source": [
    "### **1.2. Key Based Joins**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04b7aa",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_01_02.jpg?v=1766897144\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Choose join keys based on business meaning\n",
    ">* Use correct column combinations to uniquely match rows\n",
    "\n",
    ">* Different tables may name key columns differently\n",
    ">* Explicitly map mismatched key names during joins\n",
    "\n",
    ">* Use composite keys carefully to avoid misjoins\n",
    ">* Check missing keys, uniqueness, and row counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Key Based Joins\n",
    "\n",
    "# Demonstrate key based joins using Polars DataFrames in simple examples.\n",
    "# Show single key joins where column names match across both tables.\n",
    "# Show composite and renamed keys where column names differ between tables.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a customers table with a single key column customer_id.\n",
    "customers = pl.DataFrame({\"customer_id\": [1, 2, 3], \"name\": [\"Alice\", \"Bob\", \"Carol\"]})\n",
    "\n",
    "# Create an orders table using the same key column name customer_id.\n",
    "orders = pl.DataFrame({\"order_id\": [101, 102, 103], \"customer_id\": [1, 2, 2]})\n",
    "\n",
    "# Join on the shared key column customer_id using a left join type.\n",
    "single_key_join = customers.join(orders, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Print the result to show how rows align using the single key.\n",
    "print(\"Single key join using customer_id column:\")\n",
    "print(single_key_join)\n",
    "\n",
    "# Create a daily_sales table using a composite key with customer_id and order_date.\n",
    "daily_sales = pl.DataFrame({\"customer_id\": [1, 1, 2], \"order_date\": [\"2025-01-01\", \"2025-01-02\", \"2025-01-01\"], \"dollars\": [50, 75, 20]})\n",
    "\n",
    "# Create a promotions table where the key columns use different names.\n",
    "promotions = pl.DataFrame({\"cust_id\": [1, 2], \"promo_date\": [\"2025-01-01\", \"2025-01-01\"], \"discount\": [5, 3]})\n",
    "\n",
    "# Join using a composite key mapping different column names between both tables.\n",
    "composite_join = daily_sales.join(promotions, left_on=[\"customer_id\", \"order_date\"], right_on=[\"cust_id\", \"promo_date\"], how=\"left\")\n",
    "\n",
    "# Print the result to show how composite and renamed keys control matching.\n",
    "print(\"\\nComposite key join using customer_id and order_date columns:\")\n",
    "print(composite_join)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5503b",
   "metadata": {},
   "source": [
    "### **1.3. Column Suffix Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028b951",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_01_03.jpg?v=1766897159\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Overlapping column names in joins cause confusion\n",
    ">* Use clear, consistent suffixes to distinguish sources\n",
    "\n",
    ">* Generic suffixes become confusing in complex joins\n",
    ">* Use descriptive suffixes to clarify column origins\n",
    "\n",
    ">* Consistent suffixes improve maintenance, collaboration, debugging\n",
    ">* Source-based suffix patterns reveal origins and issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ce121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Column Suffix Strategies\n",
    "\n",
    "# Demonstrate Polars join column suffix behavior clearly.\n",
    "# Show default suffixes for overlapping column names visually.\n",
    "# Show custom descriptive suffixes for overlapping column names.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a simple customers DataFrame with overlapping column names.\n",
    "customers = pl.DataFrame({\"customer_id\": [1, 2], \"region\": [\"East\", \"West\"], \"created_at\": [\"2024-01-01\", \"2024-02-01\"]})\n",
    "\n",
    "# Create a simple orders DataFrame with overlapping column names.\n",
    "orders = pl.DataFrame({\"customer_id\": [1, 2], \"region\": [\"North\", \"South\"], \"created_at\": [\"2024-03-01\", \"2024-04-01\"]})\n",
    "\n",
    "# Perform a join using default Polars suffixes for overlapping columns.\n",
    "joined_default = customers.join(orders, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Perform a join using custom descriptive suffixes for overlapping columns.\n",
    "joined_custom = customers.join(orders, on=\"customer_id\", how=\"inner\", suffix=\"_order\")\n",
    "\n",
    "# Print the original DataFrames to understand overlapping column names.\n",
    "print(\"Customers DataFrame:\\n\", customers)\n",
    "\n",
    "# Print the orders DataFrame to compare overlapping column names.\n",
    "print(\"\\nOrders DataFrame:\\n\", orders)\n",
    "\n",
    "# Print the joined result with default suffixes for overlapping columns.\n",
    "print(\"\\nJoined with default suffixes:\\n\", joined_default)\n",
    "\n",
    "# Print the joined result with custom descriptive suffixes for overlapping columns.\n",
    "print(\"\\nJoined with custom '_order' suffix:\\n\", joined_custom)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a1cba",
   "metadata": {},
   "source": [
    "## **2. Pivot and Melt Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c4b2d",
   "metadata": {},
   "source": [
    "### **2.1. Wide to Long Melt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aba282",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_02_01.jpg?v=1766897187\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Melt converts many related columns into pairs\n",
    ">* Id columns stay fixed while values stack vertically\n",
    "\n",
    ">* Melt turns visit columns into visit, value pairs\n",
    ">* Each patient gets one row per visit observation\n",
    "\n",
    ">* Many domains store repeated measures in columns\n",
    ">* Melting creates tidy long data for flexible analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c64643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Wide to Long Melt\n",
    "\n",
    "# Demonstrate wide to long melt transformation using Polars DataFrame example.\n",
    "# Show patient blood pressure readings reshaped from wide format to long format.\n",
    "# Help beginners see how id columns stay fixed while value columns stack vertically.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a simple wide DataFrame with patient blood pressure readings.\n",
    "wide_df = pl.DataFrame({\n",
    "    \"patient_id\": [1, 2],\n",
    "    \"age_years\": [45, 60],\n",
    "    \"bp_visit1\": [120, 135],\n",
    "    \"bp_visit2\": [118, 140],\n",
    "})\n",
    "\n",
    "# Show the original wide DataFrame for comparison clarity.\n",
    "print(\"Original wide DataFrame:\")\n",
    "print(wide_df)\n",
    "\n",
    "# Melt the DataFrame from wide format to long format using Polars melt.\n",
    "long_df = wide_df.melt(\n",
    "    id_vars=[\"patient_id\", \"age_years\"],\n",
    "    value_vars=[\"bp_visit1\", \"bp_visit2\"],\n",
    "    variable_name=\"visit_label\",\n",
    "    value_name=\"blood_pressure\",\n",
    ")\n",
    "\n",
    "# Show the resulting long DataFrame after melting transformation.\n",
    "print(\"\\nLong DataFrame after melt:\")\n",
    "print(long_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00785bdf",
   "metadata": {},
   "source": [
    "### **2.2. Pivoting Long To Wide**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21976227",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_02_02.jpg?v=1766897201\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Turn long tables into wide column layouts\n",
    ">* Choose id, pivot, and value columns explicitly\n",
    "\n",
    ">* Pivot sales so categories become separate columns\n",
    ">* Same idea applies to many measurement domains\n",
    "\n",
    ">* Check uniqueness of index and pivot combinations\n",
    ">* Choose aggregation that matches your business meaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Pivoting Long To Wide\n",
    "\n",
    "# Demonstrate long to wide pivot using Polars DataFrame pivot operation.\n",
    "# Show how identifier columns stay rows while category values become columns.\n",
    "# Aggregate duplicate combinations using sum to handle repeated measurements.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a simple long format sales table with repeated category entries.\n",
    "data = {\n",
    "    \"store_id\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"],\n",
    "    \"month\": [\"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\"],\n",
    "    \"category\": [\"electronics\", \"clothing\", \"electronics\", \"clothing\", \"groceries\", \"groceries\"],\n",
    "    \"sales_dollars\": [1200, 300, 800, 500, 200, 150],\n",
    "}\n",
    "\n",
    "# Build the Polars DataFrame from the dictionary data structure.\n",
    "long_df = pl.DataFrame(data)\n",
    "\n",
    "# Show the original long layout where categories appear as multiple rows.\n",
    "print(\"Long layout sales table:\")\n",
    "print(long_df)\n",
    "\n",
    "# Pivot to wide layout keeping store and month as identifier columns.\n",
    "wide_df = long_df.pivot(\n",
    "    values=\"sales_dollars\",\n",
    "    index=[\"store_id\", \"month\"],\n",
    "    columns=\"category\",\n",
    "    aggregate_fn=\"sum\",\n",
    ")\n",
    "\n",
    "# Show the wide layout where categories become separate columns.\n",
    "print(\"\\nWide layout after pivot:\")\n",
    "print(wide_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e462b",
   "metadata": {},
   "source": [
    "### **2.3. Pivot Aggregation Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940af10",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_02_03.jpg?v=1766897215\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pivoting requires combining overlapping data values\n",
    ">* Choose sum, average, min, or max thoughtfully\n",
    "\n",
    ">* Different contexts need different pivot aggregations\n",
    ">* Chosen aggregation changes how the wide table’s interpreted\n",
    "\n",
    ">* Match pivot aggregations to legacy tool behavior\n",
    ">* Validate key cells to preserve meaning and trust\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Pivot Aggregation Strategies\n",
    "\n",
    "# Demonstrate pivot aggregation strategies using simple Polars examples.\n",
    "# Compare sum and mean aggregations for repeated store month revenue values.\n",
    "# Highlight how aggregation choices change the meaning of pivoted tables.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a simple long format sales DataFrame with repeated store month entries.\n",
    "data = {\n",
    "    \"store\": [\"North\", \"North\", \"North\", \"South\", \"South\", \"South\"],\n",
    "    \"month\": [\"Jan\", \"Jan\", \"Feb\", \"Jan\", \"Jan\", \"Feb\"],\n",
    "    \"revenue_dollars\": [100.0, 150.0, 200.0, 80.0, 120.0, 160.0],\n",
    "}\n",
    "\n",
    "sales_long = pl.DataFrame(data)\n",
    "\n",
    "# Show the original long format data to understand repeated store month combinations.\n",
    "print(\"Long format sales data with repeated store month rows:\")\n",
    "print(sales_long)\n",
    "\n",
    "# Pivot using sum aggregation to combine repeated store month revenue values.\n",
    "sales_pivot_sum = sales_long.pivot_table(\n",
    "    values=\"revenue_dollars\",\n",
    "    index=\"store\",\n",
    "    columns=\"month\",\n",
    "    aggregate_function=\"sum\",\n",
    ")\n",
    "\n",
    "print(\"\\nPivoted sales data using sum aggregation strategy:\")\n",
    "print(sales_pivot_sum)\n",
    "\n",
    "# Pivot using mean aggregation to compare with the sum based pivot result.\n",
    "sales_pivot_mean = sales_long.pivot_table(\n",
    "    values=\"revenue_dollars\",\n",
    "    index=\"store\",\n",
    "    columns=\"month\",\n",
    "    aggregate_function=\"mean\",\n",
    ")\n",
    "\n",
    "print(\"\\nPivoted sales data using mean aggregation strategy:\")\n",
    "print(sales_pivot_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe0dc6",
   "metadata": {},
   "source": [
    "## **3. Join Migration Pitfalls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac563be",
   "metadata": {},
   "source": [
    "### **3.1. Key Mismatches and Nulls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea48576",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_03_01.jpg?v=1766897236\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Mismatched join keys and nulls cause errors\n",
    ">* Standardize types, formatting, and null handling before joining\n",
    "\n",
    ">* Different ID formats stop matching related records\n",
    ">* Unstandardized nulls silently exclude or misclassify data\n",
    "\n",
    ">* Carefully inspect join keys and null patterns\n",
    ">* Standardize types and null rules to prevent errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1861971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Key Mismatches and Nulls\n",
    "\n",
    "# Demonstrate join key mismatches between Pandas and Polars joins.\n",
    "# Show how types and null encodings affect join results.\n",
    "# Illustrate simple fixes for mismatched keys and null values.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create small Pandas DataFrames with subtle key differences.\n",
    "left_pd = pd.DataFrame({\"id\": [101, 102, 103], \"value_left\": [\"A\", \"B\", \"C\"]})\n",
    "right_pd = pd.DataFrame({\"id\": [\"101 \", \"102\", None], \"value_right\": [10, 20, 30]})\n",
    "\n",
    "# Show Pandas inner join result with mismatched types and whitespace.\n",
    "merged_pd = left_pd.merge(right_pd, on=\"id\", how=\"inner\")\n",
    "print(\"Pandas inner join rows:\", len(merged_pd))\n",
    "\n",
    "# Convert Pandas DataFrames to Polars DataFrames for comparison.\n",
    "left_pl = pl.from_pandas(left_pd)\n",
    "right_pl = pl.from_pandas(right_pd)\n",
    "\n",
    "# Show Polars inner join result before cleaning keys and nulls.\n",
    "merged_pl = left_pl.join(right_pl, on=\"id\", how=\"inner\")\n",
    "print(\"Polars inner join rows before cleaning:\", merged_pl.height)\n",
    "\n",
    "# Clean keys in Polars by casting types and trimming whitespace.\n",
    "right_pl_clean = right_pl.with_columns([\n",
    "    pl.col(\"id\").cast(pl.Utf8).str.strip().alias(\"id\")\n",
    "])\n",
    "\n",
    "# Replace placeholder null like strings with real nulls if needed.\n",
    "right_pl_clean = right_pl_clean.with_columns([\n",
    "    pl.when(pl.col(\"id\") == \"N A\").then(None).otherwise(pl.col(\"id\")).alias(\"id\")\n",
    "])\n",
    "\n",
    "# Perform Polars inner join again after cleaning keys and nulls.\n",
    "merged_pl_clean = left_pl.join(right_pl_clean, on=\"id\", how=\"inner\")\n",
    "print(\"Polars inner join rows after cleaning:\", merged_pl_clean.height)\n",
    "\n",
    "# Display final cleaned Polars join result for verification.\n",
    "print(\"Final cleaned Polars join:\")\n",
    "print(merged_pl_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a587cd7",
   "metadata": {},
   "source": [
    "### **3.2. Managing Duplicate Join Keys**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3ec2de",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_03_02.jpg?v=1766897316\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Duplicate join keys create many-to-many joins\n",
    ">* They inflate rows, distort metrics, and performance\n",
    "\n",
    ">* Check assumed unique keys for hidden duplicates\n",
    ">* Compare key counts and join rows to locate issues\n",
    "\n",
    ">* Shape, filter, or aggregate to control duplicates\n",
    ">* Document choices to keep joins meaningful and efficient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abca48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Managing Duplicate Join Keys\n",
    "\n",
    "# Demonstrate duplicate join keys causing row multiplication in Polars joins.\n",
    "# Compare Pandas style expectations with Polars join behavior using simple tables.\n",
    "# Show how grouping can enforce uniqueness before performing a safer join.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a left table with unique customer identifiers and simple order counts.\n",
    "left_orders = pl.DataFrame({\"customer_id\": [1, 2, 3], \"orders\": [2, 1, 4]})\n",
    "\n",
    "# Create a right table with duplicate customer identifiers representing multiple records.\n",
    "right_customers = pl.DataFrame({\"customer_id\": [1, 1, 2], \"state\": [\"CA\", \"NY\", \"TX\"]})\n",
    "\n",
    "# Perform a join that multiplies rows because of duplicate keys on the right side.\n",
    "joined_many = left_orders.join(right_customers, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Aggregate the right table to enforce uniqueness before joining again safely.\n",
    "right_unique = right_customers.group_by(\"customer_id\").agg(pl.col(\"state\").first())\n",
    "\n",
    "# Perform a second join using the deduplicated right table for controlled row counts.\n",
    "joined_unique = left_orders.join(right_unique, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Print row counts and joined tables to compare duplicate key effects clearly.\n",
    "print(\"Rows before join left:\", left_orders.height)\n",
    "print(\"Rows before join right:\", right_customers.height)\n",
    "print(\"Rows after join many:\", joined_many.height)\n",
    "print(\"Rows after join unique:\", joined_unique.height)\n",
    "print(\"Joined with duplicates keys:\\n\", joined_many)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff5cc8",
   "metadata": {},
   "source": [
    "### **3.3. Index Based Join Alignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82777081",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_03/Lecture_B/image_03_03.jpg?v=1766897331\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Implicit index-based row alignment no longer happens\n",
    ">* Always join using explicit keys to prevent mismatches\n",
    "\n",
    ">* Row-based joins break after sorting or filtering\n",
    ">* Always join on explicit, stable identifier keys\n",
    "\n",
    ">* Trace table history to spot broken alignments\n",
    ">* Rebuild explicit keys and make alignment verifiable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Index Based Join Alignment\n",
    "\n",
    "# Demonstrate index based alignment differences between Pandas and Polars joins.\n",
    "# Show how implicit index alignment can silently misalign related customer rows.\n",
    "# Emphasize using explicit customer_id keys for safe predictable joins.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create a simple Pandas DataFrame with customer_id and churn_score columns.\n",
    "customers_pd = pd.DataFrame({\"customer_id\": [101, 102, 103], \"churn_score\": [0.2, 0.8, 0.5]})\n",
    "\n",
    "# Create another Pandas DataFrame with the same index but shuffled customer_id order.\n",
    "responses_pd = pd.DataFrame({\"customer_id\": [103, 101, 102], \"responded\": [\"yes\", \"no\", \"yes\"]})\n",
    "\n",
    "# Show both Pandas tables to highlight that index positions match but customers differ.\n",
    "print(\"Pandas customers table with index alignment:\")\n",
    "print(customers_pd)\n",
    "\n",
    "# Perform a Pandas join that aligns only on the shared index positions, not customer_id.\n",
    "joined_pd = customers_pd.join(responses_pd[[\"responded\"]])\n",
    "\n",
    "# Display the incorrect Pandas join where churn_score pairs with wrong responded values.\n",
    "print(\"\\nPandas join using implicit index alignment only:\")\n",
    "print(joined_pd)\n",
    "\n",
    "# Convert the original Pandas tables into Polars DataFrames for explicit key joins.\n",
    "customers_pl = pl.from_pandas(customers_pd)\n",
    "responses_pl = pl.from_pandas(responses_pd)\n",
    "\n",
    "# Perform a Polars join using explicit customer_id keys, ignoring any hidden index ideas.\n",
    "joined_pl = customers_pl.join(responses_pl, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Display the correct Polars join where churn_score aligns with matching customer_id.\n",
    "print(\"\\nPolars join using explicit customer_id key:\")\n",
    "print(joined_pl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b32757",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Joins and Reshaping**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9666b",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Execute common join types in Polars that correspond to Pandas merge operations. \n",
    "- Reshape Polars DataFrames using pivot and melt to match existing Pandas wide‑to‑long and long‑to‑wide transformations. \n",
    "- Diagnose and resolve typical join and reshape issues that arise during migration, such as key mismatches and duplicated columns. \n",
    "\n",
    "In the next Module (Module 4), we will go over 'Lazy Queries and Performance'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
