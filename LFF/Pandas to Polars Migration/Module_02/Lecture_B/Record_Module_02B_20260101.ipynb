{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca1082a",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Selecting and Filtering**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8781a",
   "metadata": {},
   "source": [
    ">Last update: 20260101.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Apply Polars column selection and projection syntax to reproduce common pandas selection patterns. \n",
    "- Translate pandas boolean indexing and query-style filters into Polars expressions on DataFrames and LazyFrames. \n",
    "- Refactor chained pandas selection and filtering code into readable, idiomatic Polars pipelines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62ae67",
   "metadata": {},
   "source": [
    "## **1. Polars Column Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428613b",
   "metadata": {},
   "source": [
    "### **1.1. Column Name Patterns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43f8e5",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_01_01.jpg?v=1767312877\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use name patterns instead of listing columns\n",
    ">* Group related columns by prefixes or suffixes\n",
    "\n",
    ">* Consistent column naming enables powerful pattern selection\n",
    ">* Patterns reduce typing, mistakes, and improve transparency\n",
    "\n",
    ">* Consistent name patterns lead to better schemas\n",
    ">* Patterns keep selection code stable and portable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Column Name Patterns\n",
    "\n",
    "# Demonstrate selecting Polars columns using simple name patterns.\n",
    "# Show prefix and suffix based column selection with clear printed output.\n",
    "# Compare manual column listing with concise pattern based selection.\n",
    "#pip install polars.\n",
    "\n",
    "#import polars library for DataFrame creation and selection.\n",
    "import polars as pl\n",
    "\n",
    "#create a small DataFrame with patterned column names.\n",
    "df = pl.DataFrame({\n",
    "    \"price_usd\": [10, 20, 30],\n",
    "    \"price_eur\": [9, 18, 27],\n",
    "    \"sales_count\": [2, 3, 4],\n",
    "    \"cost_usd\": [5, 7, 9],\n",
    "})\n",
    "\n",
    "#print the full DataFrame to understand available columns.\n",
    "print(\"Full DataFrame with all columns:\\n\", df)\n",
    "\n",
    "#select columns manually by listing each price related column.\n",
    "manual_price = df.select([\"price_usd\", \"price_eur\"])\n",
    "\n",
    "#print manual selection result for comparison clarity.\n",
    "print(\"\\nManual selection of price columns:\\n\", manual_price)\n",
    "\n",
    "#select columns automatically using prefix pattern for price columns.\n",
    "pattern_price = df.select(pl.col(\"^price_.*$\"))\n",
    "\n",
    "#print pattern based selection showing same result more concisely.\n",
    "print(\"\\nPattern selection using prefix 'price_*':\\n\", pattern_price)\n",
    "\n",
    "#select columns automatically using suffix pattern for usd currency.\n",
    "pattern_usd = df.select(pl.col(\"^.*_usd$\"))\n",
    "\n",
    "#print suffix based selection to highlight flexible name patterns.\n",
    "print(\"\\nPattern selection using suffix '*_usd':\\n\", pattern_usd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95d4db",
   "metadata": {},
   "source": [
    "### **1.2. Dropping Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726d286",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_01_02.jpg?v=1767312919\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Dropping columns shapes the dataset flowing forward\n",
    ">* Select columns to keep; others drop implicitly\n",
    "\n",
    ">* Sometimes explicitly drop irrelevant or duplicate columns\n",
    ">* Use projections to implement dropping by name pattern\n",
    "\n",
    ">* Combine exclusions and inclusions in one projection\n",
    ">* Keeps important columns as schemas grow and change\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f58b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Dropping Columns\n",
    "\n",
    "# Demonstrate dropping columns using Polars projections.\n",
    "# Compare keeping columns versus explicitly dropping columns.\n",
    "# Show how projection shapes downstream analysis data.\n",
    "\n",
    "# pip install polars for DataFrame operations.\n",
    "# pip install pyarrow for optional backend support.\n",
    "\n",
    "# Import polars library for column operations.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small customer DataFrame example.\n",
    "df = pl.DataFrame({\"customer_id\": [1, 2, 3], \"age_years\": [25, 40, 31], \"raw_notes\": [\"VIP\", \"Late payer\", \"New\"], \"temp_score\": [0.8, 0.3, 0.6]})\n",
    "\n",
    "# Show original DataFrame with all columns.\n",
    "print(\"Original DataFrame with all columns:\")\n",
    "print(df)\n",
    "\n",
    "# Keep only important identifier and metric columns.\n",
    "project_keep = df.select([pl.col(\"customer_id\"), pl.col(\"temp_score\")])\n",
    "\n",
    "# Show DataFrame after positive selection projection.\n",
    "print(\"\\nAfter projection keeping id and score:\")\n",
    "print(project_keep)\n",
    "\n",
    "# Drop sensitive or temporary columns using exclude pattern.\n",
    "project_drop = df.select(pl.all().exclude([\"raw_notes\", \"temp_score\"]))\n",
    "\n",
    "# Show DataFrame after dropping notes and temporary score.\n",
    "print(\"\\nAfter dropping notes and temporary score:\")\n",
    "print(project_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3e784",
   "metadata": {},
   "source": [
    "### **1.3. Expression Based Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d467d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_01_03.jpg?v=1767312936\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Define output columns using Polars expressions directly\n",
    ">* Combine selection and transformations into one readable step\n",
    "\n",
    ">* Like spreadsheet formulas that create visible columns\n",
    ">* Select columns and define new ones in-place\n",
    "\n",
    ">* Lazy expressions improve efficiency and avoid redundancy\n",
    ">* Selections stay readable, showing final engineered columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf52613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Expression Based Selection\n",
    "\n",
    "# Demonstrate Polars expression based column selection with simple sales data.\n",
    "# Show selecting original, transformed, and newly derived columns together.\n",
    "# Keep everything beginner friendly and runnable inside Google Colab.\n",
    "\n",
    "# !pip install polars pyarrow fsspec.\n",
    "\n",
    "# Import Polars library for DataFrame operations.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small DataFrame with simple sales information.\n",
    "data = pl.DataFrame({\"product\": [\"A\", \"B\", \"C\"], \"price_usd\": [10, 20, 15], \"quantity\": [2, 1, 4]})\n",
    "\n",
    "# Use expression based selection to define resulting columns directly.\n",
    "result = data.select([\n",
    "    pl.col(\"product\"),\n",
    "    (pl.col(\"price_usd\") * 1.1).alias(\"price_with_tax_usd\"),\n",
    "    (pl.col(\"price_usd\") * pl.col(\"quantity\")).alias(\"revenue_usd\"),\n",
    "    pl.when(pl.col(\"price_usd\") * pl.col(\"quantity\") > 30).then(pl.lit(\"high\")).otherwise(pl.lit(\"low\")).alias(\"revenue_flag\"),\n",
    "])\n",
    "\n",
    "# Print original DataFrame to compare with expression based selection result.\n",
    "print(\"Original DataFrame:\\n\", data)\n",
    "\n",
    "# Print resulting DataFrame showing selected and derived columns together.\n",
    "print(\"\\nSelected and derived columns:\\n\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5291419",
   "metadata": {},
   "source": [
    "## **2. Filtering Rows with Expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ad6a4",
   "metadata": {},
   "source": [
    "### **2.1. Boolean Filters with plcol**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82da42",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_02_01.jpg?v=1767312993\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Filters are boolean expressions built from columns\n",
    ">* Expressions return true rows, replacing pandas masks\n",
    "\n",
    ">* Use column helper to define row conditions\n",
    ">* Write clear filters directly on relevant columns\n",
    "\n",
    ">* Combine multiple column conditions into one expression\n",
    ">* Use composite boolean expressions for clear, predictable filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Boolean Filters with plcol\n",
    "\n",
    "# Demonstrate basic boolean filtering using Polars column helper expressions.\n",
    "# Show how column expressions create boolean masks for filtering rows.\n",
    "# Compare multiple simple filters on a small customer transactions DataFrame.\n",
    "\n",
    "# pip install polars if running outside Google Colab environment.\n",
    "\n",
    "# Import Polars library for DataFrame creation and filtering.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small DataFrame with customer transaction information.\n",
    "customers_df = pl.DataFrame({\"age\": [25, 32, 45, 29], \"amount_usd\": [40, 120, 75, 200], \"country\": [\"US\", \"US\", \"UK\", \"CA\"]})\n",
    "\n",
    "# Show the original DataFrame to understand available columns.\n",
    "print(\"Original DataFrame:\")\n",
    "print(customers_df)\n",
    "\n",
    "# Build a boolean expression selecting customers older than thirty years.\n",
    "age_filter_expr = pl.col(\"age\") > 30\n",
    "\n",
    "# Apply the age filter expression using filter method on DataFrame.\n",
    "older_customers_df = customers_df.filter(age_filter_expr)\n",
    "\n",
    "# Display filtered rows where age condition is true only.\n",
    "print(\"\\nCustomers older than thirty:\")\n",
    "print(older_customers_df)\n",
    "\n",
    "# Build a boolean expression selecting large purchases above one hundred dollars.\n",
    "large_purchase_expr = pl.col(\"amount_usd\") > 100\n",
    "\n",
    "# Apply the large purchase filter expression using filter method.\n",
    "large_purchases_df = customers_df.filter(large_purchase_expr)\n",
    "\n",
    "# Display filtered rows where purchase amount condition is true only.\n",
    "print(\"\\nPurchases greater than one hundred dollars:\")\n",
    "print(large_purchases_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070863c3",
   "metadata": {},
   "source": [
    "### **2.2. Logical Condition Chaining**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e350b32",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_02_02.jpg?v=1767313011\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Combine multiple conditions using logical boolean operators\n",
    ">* Think in optimized expression trees instead of masks\n",
    "\n",
    ">* Use clear, grouped conditions to maintain readability\n",
    ">* Combine multiple rules carefully to avoid logic mistakes\n",
    "\n",
    ">* Combine many conditions into one Polars expression\n",
    ">* Improves performance, readability, and query optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Logical Condition Chaining\n",
    "\n",
    "# Demonstrate logical condition chaining with simple Polars filters.\n",
    "# Compare separate filters versus one combined chained condition expression.\n",
    "# Show how parentheses clarify complex logical filter groupings.\n",
    "\n",
    "# !pip install polars pyarrow.\n",
    "\n",
    "# Import Polars for DataFrame creation and filtering.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small customer DataFrame with simple example data.\n",
    "customers = pl.DataFrame({\"name\": [\"Ann\", \"Bob\", \"Cara\", \"Dan\"], \"active\": [True, False, True, True], \"spend_usd\": [120.0, 40.0, 300.0, 80.0], \"region\": [\"US\", \"US\", \"EU\", \"US\"]})\n",
    "\n",
    "# Show the original DataFrame for reference before filtering operations.\n",
    "print(\"Original customers DataFrame:\")\n",
    "print(customers)\n",
    "\n",
    "# Build separate simple conditions for activity and spending threshold.\n",
    "cond_active = pl.col(\"active\") == True\n",
    "cond_spend = pl.col(\"spend_usd\") >= 100\n",
    "\n",
    "# Chain conditions using logical AND to keep active high spending customers.\n",
    "filtered_and = customers.filter(cond_active & cond_spend)\n",
    "\n",
    "# Display result of chained AND condition filtering operation.\n",
    "print(\"\\nActive customers spending at least 100 USD:\")\n",
    "print(filtered_and)\n",
    "\n",
    "# Build a third condition for region being United States specifically.\n",
    "cond_region_us = pl.col(\"region\") == \"US\"\n",
    "\n",
    "# Chain conditions mixing AND and OR with explicit parentheses grouping.\n",
    "filtered_complex = customers.filter(cond_active & (cond_spend | cond_region_us))\n",
    "\n",
    "# Display result showing logical chaining with mixed operators and parentheses.\n",
    "print(\"\\nActive customers with high spend or located in US region:\")\n",
    "print(filtered_complex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9a043",
   "metadata": {},
   "source": [
    "### **2.3. Eager vs Lazy Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51536c",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_02_03.jpg?v=1767313026\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Eager mode runs each filter immediately, materializing DataFrames\n",
    ">* Lazy mode stores a plan, executing filters later\n",
    "\n",
    ">* Eager filtering creates many intermediate DataFrames\n",
    ">* Lazy filtering optimizes whole query, saving resources\n",
    "\n",
    ">* Use eager filtering for small, interactive exploration\n",
    ">* Use lazy filtering for scalable, optimized data pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Eager vs Lazy Filtering\n",
    "\n",
    "# Demonstrate eager versus lazy filtering using Polars DataFrames and LazyFrames.\n",
    "# Show that eager executes immediately while lazy builds a deferred query plan.\n",
    "# Compare printed results to see identical logic with different execution strategies.\n",
    "\n",
    "# !pip install polars pyarrow fsspec.\n",
    "\n",
    "# Import polars library for DataFrame and LazyFrame operations.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small DataFrame representing daily temperatures in Fahrenheit.\n",
    "df = pl.DataFrame({\"day\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"], \"temp_f\": [70, 65, 80, 90, 75]})\n",
    "\n",
    "# Show original DataFrame to understand starting point before filtering.\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Apply eager filtering directly, executed immediately on the DataFrame.\n",
    "filtered_eager = df.filter(pl.col(\"temp_f\") > 75)\n",
    "\n",
    "# Print eager filtering result, showing only hotter days above threshold.\n",
    "print(\"\\nEager filtering result:\")\n",
    "print(filtered_eager)\n",
    "\n",
    "# Build a LazyFrame from the same DataFrame for lazy execution.\n",
    "lazy_plan = df.lazy()\n",
    "\n",
    "# Add lazy filter expression, not executed until collect is called.\n",
    "lazy_filtered = lazy_plan.filter(pl.col(\"temp_f\") > 75)\n",
    "\n",
    "# Print the lazy query plan to highlight deferred execution behavior.\n",
    "print(\"\\nLazy query plan:\")\n",
    "print(lazy_filtered.explain())\n",
    "\n",
    "# Collect lazy result, triggering actual execution and materialization of filtered data.\n",
    "filtered_lazy = lazy_filtered.collect()\n",
    "\n",
    "# Print lazy filtering result, matching eager result but optimized internally.\n",
    "print(\"\\nLazy filtering collected result:\")\n",
    "print(filtered_lazy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343615a",
   "metadata": {},
   "source": [
    "## **3. Refactoring Filter Chains**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc9268",
   "metadata": {},
   "source": [
    "### **3.1. Replacing chained pandas loc calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2bbb2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_03_01.jpg?v=1767313089\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Replace many pandas filters with one pipeline\n",
    ">* Polars groups all filter conditions for clarity\n",
    "\n",
    ">* Describe the final filtered dataset in Polars\n",
    ">* Combine all filter rules into one pipeline\n",
    "\n",
    ">* Separate filtering from column selection and calculations\n",
    ">* Single Polars pipeline makes logic clearer and maintainable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c083468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Replacing chained pandas loc calls\n",
    "\n",
    "# Demonstrate replacing chained pandas loc filters with one clear Polars pipeline.\n",
    "# Show equivalent customer filtering logic in pandas and Polars side by side.\n",
    "# Keep data tiny and output short for easy beginner friendly understanding.\n",
    "\n",
    "# !pip install polars pandas.\n",
    "\n",
    "# Import required libraries for pandas and Polars examples.\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create small customer dataset with country, status, and lifetime value columns.\n",
    "customers_data = {\n",
    "    \"customer_id\": [1, 2, 3, 4],\n",
    "    \"country\": [\"USA\", \"USA\", \"Canada\", \"USA\"],\n",
    "    \"status\": [\"active\", \"inactive\", \"active\", \"active\"],\n",
    "    \"lifetime_value_usd\": [1200, 300, 2500, 800],\n",
    "}\n",
    "\n",
    "# Build pandas DataFrame from dictionary for chained loc filtering demonstration.\n",
    "df_pd = pd.DataFrame(customers_data)\n",
    "\n",
    "# Show original pandas DataFrame to understand starting customer records clearly.\n",
    "print(\"Pandas original DataFrame:\")\n",
    "print(df_pd)\n",
    "\n",
    "# Apply chained pandas loc filters stepwise for country, status, and value.\n",
    "df_pd_filtered = df_pd.loc[df_pd[\"country\"] == \"USA\"]\n",
    "\n",
    "# Continue pandas filtering chain for active status customers only.\n",
    "df_pd_filtered = df_pd_filtered.loc[df_pd_filtered[\"status\"] == \"active\"]\n",
    "\n",
    "# Final pandas filter keeps customers with lifetime value above threshold.\n",
    "df_pd_filtered = df_pd_filtered.loc[df_pd_filtered[\"lifetime_value_usd\"] > 1000]\n",
    "\n",
    "# Display final pandas filtered result after multiple chained loc calls.\n",
    "print(\"\\nPandas filtered customers:\")\n",
    "print(df_pd_filtered)\n",
    "\n",
    "# Build Polars DataFrame from same dictionary for pipeline style filtering.\n",
    "df_pl = pl.DataFrame(customers_data)\n",
    "\n",
    "# Apply single Polars filter combining all conditions in one clear expression.\n",
    "df_pl_filtered = df_pl.filter(\n",
    "    (pl.col(\"country\") == \"USA\")\n",
    "    & (pl.col(\"status\") == \"active\")\n",
    "    & (pl.col(\"lifetime_value_usd\") > 1000)\n",
    ")\n",
    "\n",
    "# Display Polars filtered result showing same customers using one pipeline.\n",
    "print(\"\\nPolars filtered customers:\")\n",
    "print(df_pl_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f9bc8",
   "metadata": {},
   "source": [
    "### **3.2. Readable Polars Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8fffb9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_03_02.jpg?v=1767313104\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use one clear Polars pipeline for transformations\n",
    ">* Tell a readable story from raw to result\n",
    "\n",
    ">* Group related filters into clear conceptual steps\n",
    ">* Match pipeline structure and names to domain language\n",
    "\n",
    ">* Keep steps concise, explicit, and conceptually complete\n",
    ">* Name intermediate columns clearly to support understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea915018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Readable Polars Pipelines\n",
    "\n",
    "# Demonstrate readable Polars filtering pipelines with simple customer orders example.\n",
    "# Compare scattered filters with a single clear Polars pipeline expression.\n",
    "# Show how named steps improve understanding for beginners and collaborators.\n",
    "\n",
    "# !pip install polars pyarrow --quiet.\n",
    "\n",
    "# Import Polars for DataFrame and expression based pipelines.\n",
    "import polars as pl\n",
    "\n",
    "# Create a small example DataFrame with customer orders data.\n",
    "orders = pl.DataFrame({\"customer\": [\"Alice\", \"Bob\", \"Cara\", \"Dan\"],\n",
    "                       \"region\": [\"West\", \"East\", \"West\", \"South\"],\n",
    "                       \"order_value_usd\": [120.0, 40.0, 300.0, 80.0],\n",
    "                       \"days_since_order\": [10, 50, 5, 20]})\n",
    "\n",
    "# Show the original raw orders DataFrame for quick reference.\n",
    "print(\"Raw orders DataFrame:\")\n",
    "print(orders)\n",
    "\n",
    "# Build a readable pipeline describing high value recent western customers.\n",
    "pipeline_result = (\n",
    "    orders\n",
    "    .filter(pl.col(\"region\") == \"West\")\n",
    "    .filter(pl.col(\"order_value_usd\") >= 100.0)\n",
    "    .filter(pl.col(\"days_since_order\") <= 30)\n",
    "    .with_columns((pl.col(\"order_value_usd\") > 250.0)\n",
    "                  .alias(\"is_very_high_value\"))\n",
    ")\n",
    "\n",
    "# Print the final filtered result with clear narrative meaning.\n",
    "print(\"\\nHigh value recent western customers:\")\n",
    "print(pipeline_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029d52b0",
   "metadata": {},
   "source": [
    "### **3.3. Validating Filtered Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7131bd1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_B/image_03_03.jpg?v=1767313143\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Verify refactored Polars filters match intended results\n",
    ">* Compare with trusted baselines, crucial in highâ€‘stakes domains\n",
    "\n",
    ">* Compare global summaries between old and new pipelines\n",
    ">* Check local edge-case rows to confirm matching behavior\n",
    "\n",
    ">* Make validation ongoing with regression-style checks\n",
    ">* Document filter intent to prevent hidden data issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd230e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Validating Filtered Outputs\n",
    "\n",
    "# Demonstrate validating filtered outputs between pandas and Polars pipelines.\n",
    "# Show global checks like row counts and simple aggregate comparisons.\n",
    "# Show local checks using specific known example customer records.\n",
    "\n",
    "# !pip install polars pandas.\n",
    "\n",
    "# Import required libraries for pandas and Polars usage.\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create small example sales data with simple customer transactions.\n",
    "data = {\n",
    "    \"customer_id\": [1, 2, 3, 4, 5, 6],\n",
    "    \"state\": [\"CA\", \"CA\", \"NY\", \"CA\", \"TX\", \"CA\"],\n",
    "    \"amount_usd\": [120.0, 80.0, 200.0, 150.0, 50.0, 300.0],\n",
    "    \"is_test_account\": [False, True, False, False, False, True],\n",
    "}\n",
    "\n",
    "# Build pandas DataFrame representing original trusted filtering logic.\n",
    "df_pd = pd.DataFrame(data)\n",
    "\n",
    "# Apply original pandas filter for California real customers over threshold.\n",
    "filtered_pd = df_pd[(df_pd[\"state\"] == \"CA\") & (df_pd[\"amount_usd\"] >= 100.0) & (~df_pd[\"is_test_account\"])]\n",
    "\n",
    "# Build Polars DataFrame representing refactored pipeline version.\n",
    "df_pl = pl.DataFrame(data)\n",
    "\n",
    "# Apply Polars filter using expression based pipeline style.\n",
    "filtered_pl = (\n",
    "    df_pl\n",
    "    .filter(\n",
    "        (pl.col(\"state\") == \"CA\")\n",
    "        & (pl.col(\"amount_usd\") >= 100.0)\n",
    "        & (~pl.col(\"is_test_account\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Perform global validation by comparing row counts between both filtered results.\n",
    "print(\"Row counts pandas versus polars:\", len(filtered_pd), len(filtered_pl))\n",
    "\n",
    "# Perform global validation by comparing total revenue for filtered transactions.\n",
    "print(\"Total revenue pandas versus polars:\", filtered_pd[\"amount_usd\"].sum(), filtered_pl[\"amount_usd\"].sum())\n",
    "\n",
    "# Select local check customers that should pass filters for manual verification.\n",
    "check_ids = [1, 4]\n",
    "\n",
    "# Show pandas inclusion results for selected customer identifiers.\n",
    "print(\"Pandas included ids:\", sorted(filtered_pd[\"customer_id\"].tolist()))\n",
    "\n",
    "# Show Polars inclusion results for selected customer identifiers.\n",
    "print(\"Polars included ids:\", sorted(filtered_pl[\"customer_id\"].to_list()))\n",
    "\n",
    "# Confirm both systems include same benchmark identifiers for confidence.\n",
    "print(\"Local check passed:\", sorted(check_ids) == sorted(filtered_pl[\"customer_id\"].to_list()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd91443",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Selecting and Filtering**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a82fb",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Apply Polars column selection and projection syntax to reproduce common pandas selection patterns. \n",
    "- Translate pandas boolean indexing and query-style filters into Polars expressions on DataFrames and LazyFrames. \n",
    "- Refactor chained pandas selection and filtering code into readable, idiomatic Polars pipelines. \n",
    "\n",
    "In the next Module (Module 3), we will go over 'Transformations and Pipelines'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
