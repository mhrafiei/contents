{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef430bc0",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**DataFrames and Series**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c41ee",
   "metadata": {},
   "source": [
    ">Last update: 20251227.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Create Polars DataFrames and Series from common Python and file inputs used in Pandas workflows. \n",
    "- Inspect Polars DataFrame schemas and summarize data using built‑in methods. \n",
    "- Explain how Polars’ data types and null handling compare to Pandas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb7882",
   "metadata": {},
   "source": [
    "## **1. Building Polars DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753236b",
   "metadata": {},
   "source": [
    "### **1.1. From Python Collections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02015f6c",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_01_01.jpg?v=1766892459\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars builds DataFrames from familiar Python collections\n",
    ">* Keys become columns, list items become rows\n",
    "\n",
    ">* Use dictionaries of lists to define columns\n",
    ">* Polars aligns list positions into rows for analysis\n",
    "\n",
    ">* Polars handles lists of record-like dictionaries\n",
    ">* Design data shapes for easy DataFrame creation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e88805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - From Python Collections\n",
    "\n",
    "# Demonstrate creating Polars DataFrames from simple Python collections.\n",
    "# Show dictionary of lists and list of dictionaries as DataFrame inputs.\n",
    "# Print small DataFrames to connect Python objects with tabular structures.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create simple Python lists representing order information for a small store.\n",
    "order_ids = [101, 102, 103, 104]\n",
    "regions = [\"West\", \"East\", \"South\", \"West\"]\n",
    "order_totals_usd = [29.99, 49.50, 15.75, 99.10]\n",
    "\n",
    "# Build a dictionary where keys are column names and values are data lists.\n",
    "orders_dict = {\n",
    "    \"order_id\": order_ids,\n",
    "    \"region\": regions,\n",
    "    \"total_usd\": order_totals_usd,\n",
    "}\n",
    "\n",
    "# Create a Polars DataFrame directly from the dictionary of lists.\n",
    "df_from_dict = pl.DataFrame(orders_dict)\n",
    "\n",
    "# Print the resulting DataFrame to see columns and rows clearly.\n",
    "print(\"DataFrame from dictionary of lists:\")\n",
    "print(df_from_dict)\n",
    "\n",
    "# Create a list of dictionaries, each dictionary representing one order row.\n",
    "orders_records = [\n",
    "    {\"order_id\": 201, \"region\": \"North\", \"total_usd\": 10.00},\n",
    "    {\"order_id\": 202, \"region\": \"West\", \"total_usd\": 75.25},\n",
    "]\n",
    "\n",
    "# Create another Polars DataFrame from the list of record dictionaries.\n",
    "df_from_records = pl.DataFrame(orders_records)\n",
    "\n",
    "# Print the second DataFrame to compare input shapes and results.\n",
    "print(\"\\nDataFrame from list of dictionaries:\")\n",
    "print(df_from_records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df84a2",
   "metadata": {},
   "source": [
    "### **1.2. Loading CSV and Parquet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdfbb2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_01_02.jpg?v=1766892478\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars loads CSV and Parquet into DataFrames\n",
    ">* Optimized for large files, memory, and speed\n",
    "\n",
    ">* Polars reads CSV headers and infers column types\n",
    ">* You can override types, then use the DataFrame\n",
    "\n",
    ">* Parquet stores typed, columnar data for Polars\n",
    ">* Enables fast, reliable loading and large-scale analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52576af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Loading CSV and Parquet\n",
    "\n",
    "# Demonstrate loading CSV files into Polars DataFrames in a simple beginner friendly way.\n",
    "# Demonstrate loading Parquet files into Polars DataFrames using the same sample data.\n",
    "# Compare inferred data types between CSV loading and Parquet loading in Polars.\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small pandas DataFrame that mimics daily sales in dollars.\n",
    "# This DataFrame will be saved as both CSV and Parquet files locally.\n",
    "sales_pd = pd.DataFrame({\"day\": [\"Mon\", \"Tue\", \"Wed\"], \"orders\": [10, 14, 9], \"revenue_usd\": [250.5, 310.0, 199.9]})\n",
    "\n",
    "# Save the pandas DataFrame as a CSV file for Polars loading demonstration.\n",
    "# Save the same DataFrame as a Parquet file to compare loading behavior.\n",
    "sales_pd.to_csv(\"daily_sales.csv\", index=False)\n",
    "sales_pd.to_parquet(\"daily_sales.parquet\", index=False)\n",
    "\n",
    "# Load the CSV file using Polars read_csv function into a new DataFrame.\n",
    "# Print the DataFrame and its schema to inspect inferred column data types.\n",
    "df_csv = pl.read_csv(\"daily_sales.csv\")\n",
    "print(\"CSV DataFrame loaded by Polars:\")\n",
    "print(df_csv)\n",
    "\n",
    "# Display the schema for the CSV DataFrame to show inferred types clearly.\n",
    "# This helps beginners see how Polars guesses column data types automatically.\n",
    "print(\"\\nCSV DataFrame schema:\")\n",
    "print(df_csv.schema)\n",
    "\n",
    "# Load the Parquet file using Polars read_parquet function into another DataFrame.\n",
    "# Print the DataFrame and its schema to compare with the CSV loading behavior.\n",
    "df_parquet = pl.read_parquet(\"daily_sales.parquet\")\n",
    "print(\"\\nParquet DataFrame loaded by Polars:\")\n",
    "print(df_parquet)\n",
    "\n",
    "# Display the schema for the Parquet DataFrame which uses stored type information.\n",
    "# This highlights that Parquet provides exact types without additional inference steps.\n",
    "print(\"\\nParquet DataFrame schema:\")\n",
    "print(df_parquet.schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737d662",
   "metadata": {},
   "source": [
    "### **1.3. From existing Pandas DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbbfdd",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_01_03.jpg?v=1766892494\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Convert existing Pandas DataFrames into Polars\n",
    ">* Keep structure while gaining faster, columnar performance\n",
    "\n",
    ">* Prepare data in Pandas, then convert to Polars\n",
    ">* Use Polars for heavy analysis and performance\n",
    "\n",
    ">* Convert Pandas outputs to Polars for processing\n",
    ">* Adopt Polars gradually without changing existing interfaces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6970b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - From existing Pandas DataFrames\n",
    "\n",
    "# Demonstrate converting Pandas DataFrame into Polars DataFrame.\n",
    "# Show a simple workflow starting with familiar Pandas objects.\n",
    "# Highlight that structure and values remain consistent after conversion.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create a small Pandas DataFrame representing monthly sales in dollars.\n",
    "pd_df = pd.DataFrame({\"month\": [\"Jan\", \"Feb\", \"Mar\"], \"sales_usd\": [1200, 1500, 1700]})\n",
    "\n",
    "# Display the original Pandas DataFrame to confirm its structure and values.\n",
    "print(\"Pandas DataFrame:\")\n",
    "print(pd_df)\n",
    "\n",
    "# Convert the Pandas DataFrame into a Polars DataFrame using from_pandas.\n",
    "pl_df = pl.from_pandas(pd_df)\n",
    "\n",
    "# Show the Polars DataFrame to verify that columns and values are preserved.\n",
    "print(\"\\nPolars DataFrame:\")\n",
    "print(pl_df)\n",
    "\n",
    "# Perform a simple Polars operation to demonstrate continued analysis after conversion.\n",
    "print(\"\\nTotal quarterly sales using Polars:\")\n",
    "print(pl_df[\"sales_usd\"].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130ae61",
   "metadata": {},
   "source": [
    "## **2. Inspecting Polars DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243eac7",
   "metadata": {},
   "source": [
    "### **2.1. Quick DataFrame Peeks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac2099",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_02_01.jpg?v=1766892512\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use quick peeks to verify DataFrame structure\n",
    ">* Polars shows small slices efficiently, even for big data\n",
    "\n",
    ">* Small peeks quickly reveal messy, inconsistent data\n",
    ">* Repeated samples guide cleaning, typing, and trust decisions\n",
    "\n",
    ">* Use small, on-screen slices for huge datasets\n",
    ">* Frequent peeks catch issues early and boost performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Quick DataFrame Peeks\n",
    "\n",
    "# Demonstrate quick Polars DataFrame peeks for fast initial inspection.\n",
    "# Show how to view a small representative slice of a larger dataset.\n",
    "# Highlight lightweight methods that avoid printing every single available row.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a small example DataFrame representing simple store sales data.\n",
    "data = {\"store\": [\"North\", \"South\", \"East\", \"West\", \"North\"],\n",
    "        \"day\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n",
    "        \"revenue_usd\": [120.5, 99.0, 143.2, 87.3, 160.0]}\n",
    "\n",
    "# Build the Polars DataFrame from the dictionary of column lists.\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Show a quick peek at the first few rows using head method.\n",
    "print(\"First rows quick peek:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# Show a quick peek at the last few rows using tail method.\n",
    "print(\"\\nLast rows quick peek:\")\n",
    "print(df.tail(2))\n",
    "\n",
    "# Show a random sample of rows to quickly inspect varied values.\n",
    "print(\"\\nRandom sample quick peek:\")\n",
    "print(df.sample(n=3, with_replacement=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a96d6",
   "metadata": {},
   "source": [
    "### **2.2. Descriptive Statistics Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c2b72",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_02_02.jpg?v=1766892534\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use Polars summaries to understand data distributions\n",
    ">* Run stats early to validate data quality\n",
    "\n",
    ">* Polars summarizes each column using type-aware stats\n",
    ">* Numeric and non-numeric columns get appropriate measures\n",
    "\n",
    ">* Use stats flexibly to compare data patterns\n",
    ">* Iterate summaries on subsets to refine insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b320ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Descriptive Statistics Overview\n",
    "\n",
    "# Show simple Polars descriptive statistics for numeric and non numeric columns.\n",
    "# Compare describe output with a filtered subset of the same DataFrame.\n",
    "# Help beginners see how summaries reveal distributions and potential unusual values.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a small DataFrame with monthly sales and region categories.\n",
    "data = {\n",
    "    \"month\": [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"],\n",
    "    \"region\": [\"East\", \"West\", \"East\", \"West\", \"East\", \"West\"],\n",
    "    \"sales_dollars\": [1200, 800, 1500, 4000, 900, 700],\n",
    "}\n",
    "\n",
    "# Build the Polars DataFrame from the dictionary data.\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Show the full DataFrame to understand the raw values.\n",
    "print(\"Full sales DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Compute descriptive statistics for all columns using describe method.\n",
    "print(\"\\nDescriptive statistics for all columns:\")\n",
    "summary_all = df.describe()\n",
    "print(summary_all)\n",
    "\n",
    "# Filter to East region only and recompute descriptive statistics.\n",
    "print(\"\\nDescriptive statistics for East region only:\")\n",
    "summary_east = df.filter(pl.col(\"region\") == \"East\").describe()\n",
    "print(summary_east)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76759ea",
   "metadata": {},
   "source": [
    "### **2.3. Schema and Dtypes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd38ee",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_02_03.jpg?v=1766892546\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Schema lists each column and its type\n",
    ">* Checking schema prevents type mistakes in analysis\n",
    "\n",
    ">* Column dtypes affect speed, memory, and methods\n",
    ">* Check and adjust dtypes for accurate analysis\n",
    "\n",
    ">* Consistent schemas improve data quality and collaboration\n",
    ">* Regular checks prevent join issues and silent errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Schema and Dtypes\n",
    "\n",
    "# Show Polars DataFrame schema and dtypes clearly.\n",
    "# Compare inferred dtypes with manual casting choices.\n",
    "# Help beginners inspect and adjust column data types.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a simple DataFrame with mixed column types.\n",
    "# Prices use floats, quantities use integers, dates use strings.\n",
    "\n",
    "df = pl.DataFrame({\"item\": [\"apple\", \"banana\", \"orange\"], \"price_usd\": [1.5, 0.75, 2.25], \"quantity\": [10, 5, 8], \"sale_date\": [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\"]})\n",
    "\n",
    "# Show the DataFrame to understand the raw values.\n",
    "# This helps connect values with their inferred types.\n",
    "\n",
    "print(\"Original DataFrame values:\")\n",
    "print(df)\n",
    "\n",
    "# Inspect the schema to see column names and Polars dtypes.\n",
    "# This is similar to a contract for your data.\n",
    "\n",
    "print(\"\\nInferred schema and dtypes:\")\n",
    "print(df.schema)\n",
    "\n",
    "# Cast the sale_date column into a proper Date dtype.\n",
    "# This enables time based operations later.\n",
    "\n",
    "df_cast = df.with_columns(pl.col(\"sale_date\").str.strptime(pl.Date, strict=False))\n",
    "\n",
    "# Inspect the new schema after casting the date column.\n",
    "# Notice the sale_date dtype changed from Utf8 to Date.\n",
    "\n",
    "print(\"\\nSchema after casting sale_date to Date:\")\n",
    "print(df_cast.schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7592f",
   "metadata": {},
   "source": [
    "## **3. Types and Nulls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb9c44",
   "metadata": {},
   "source": [
    "### **3.1. Polars Type System**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5711d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_03_01.jpg?v=1766892563\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars enforces clear, consistent column data types\n",
    ">* Strict typing enables efficient, scalable query execution\n",
    "\n",
    ">* Polars keeps column types strict and unchanged\n",
    ">* This prevents subtle bugs and clarifies analysis\n",
    "\n",
    ">* Specialized types model real-world, nested, temporal data\n",
    ">* Expressive types reduce ambiguity and boost performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa64b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Polars Type System\n",
    "\n",
    "# Show strict Polars column types compared with flexible Pandas behavior.\n",
    "# Create small example tables and inspect their inferred data types.\n",
    "# Demonstrate how Polars preserves strings instead of silently converting them.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "pandas_data = {\"quantity\": [1, 2, 3], \"price\": [\"9.99\", \"10.50\", \"8.75\"]}\n",
    "polars_data = {\"quantity\": [1, 2, 3], \"price\": [\"9.99\", \"10.50\", \"8.75\"]}\n",
    "\n",
    "pandas_df = pd.DataFrame(pandas_data)\n",
    "polars_df = pl.DataFrame(polars_data)\n",
    "\n",
    "print(\"Pandas dtypes for each column:\")\n",
    "print(pandas_df.dtypes)\n",
    "\n",
    "print(\"\\nPolars dtypes for each column:\")\n",
    "print(polars_df.dtypes)\n",
    "\n",
    "polars_casted = polars_df.with_columns(pl.col(\"price\").cast(pl.Float64))\n",
    "print(\"\\nPolars dtypes after explicit cast:\")\n",
    "print(polars_casted.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21acdc",
   "metadata": {},
   "source": [
    "### **3.2. Handling nulls and NaNs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e06a8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_03_02.jpg?v=1766892576\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars separates nulls from floating-point NaNs clearly\n",
    ">* Nulls mean no value; NaNs mean invalid float\n",
    "\n",
    ">* Aggregations usually skip nulls instead of counting\n",
    ">* Flexible options to drop, fill, or keep nulls\n",
    "\n",
    ">* Nulls and NaNs mean different missing situations\n",
    ">* Polars lets you handle nulls and NaNs separately\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Handling nulls and NaNs\n",
    "\n",
    "# Show Polars nulls and NaNs differences clearly.\n",
    "# Create small DataFrame with nulls and NaNs values.\n",
    "# Compare basic operations handling nulls and NaNs.\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Create simple data including nulls and NaNs values.\n",
    "data = {\n",
    "    \"temp_f\": [72.0, np.nan, 68.0, None],\n",
    "    \"city\": [\"Austin\", \"Boston\", None, \"Denver\"],\n",
    "}\n",
    "\n",
    "# Build Polars DataFrame from dictionary data.\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Show DataFrame and schema for quick inspection.\n",
    "print(\"DataFrame with nulls and NaNs:\")\n",
    "print(df)\n",
    "print(\"\\nSchema showing column data types:\")\n",
    "print(df.schema)\n",
    "\n",
    "# Check which rows contain nulls or NaNs values.\n",
    "print(\"\\nIs null in temp_f column:\")\n",
    "print(df[\"temp_f\"].is_null())\n",
    "print(\"Is NaN in temp_f column:\")\n",
    "print(df[\"temp_f\"].is_nan())\n",
    "\n",
    "# Compute mean temperature ignoring nulls and NaNs values.\n",
    "mean_temp = df[\"temp_f\"].mean()\n",
    "print(\"\\nMean temperature ignoring nulls and NaNs:\", mean_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c84278",
   "metadata": {},
   "source": [
    "### **3.3. Casting and Coercion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa93d6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_02/Lecture_A/image_03_03.jpg?v=1766892590\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Polars enforces clear, consistent column data types\n",
    ">* You must explicitly choose and apply type conversions\n",
    "\n",
    ">* Polars uses explicit casts with strict, clear rules\n",
    ">* Invalid or out-of-range values become nulls\n",
    "\n",
    ">* Polars promotes numeric types to safe common types\n",
    ">* Mixed incompatible types raise errors or produce nulls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Casting and Coercion\n",
    "\n",
    "# Demonstrate Polars casting behavior with mixed type columns and explicit conversions.\n",
    "# Show how invalid conversions become null instead of silent incorrect values.\n",
    "# Compare automatic coercion in expressions with explicit casting operations.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Create a DataFrame with mixed numeric and string values.\n",
    "# Polars will infer a string type for the mixed column.\n",
    "# This simulates messy real world imported data.\n",
    "\n",
    "sales_df = pl.DataFrame({\"order_id\": [\"1001\", \"1002\", \"oops\"], \"amount_dollars\": [\"10.5\", \"20.0\", \"bad\"]})\n",
    "\n",
    "# Attempt to cast order_id to integer and observe null for invalid value.\n",
    "# Strict casting will turn non numeric strings into null values.\n",
    "# This avoids silent incorrect conversions.\n",
    "\n",
    "order_cast = sales_df.with_columns(pl.col(\"order_id\").cast(pl.Int64, strict=False).alias(\"order_id_int\"))\n",
    "\n",
    "# Attempt to cast amount_dollars to float and then to integer dollars.\n",
    "# Invalid numeric strings become null during the float conversion.\n",
    "# Integer casting then truncates fractional cents values.\n",
    "\n",
    "amount_cast = order_cast.with_columns([pl.col(\"amount_dollars\").cast(pl.Float64, strict=False).alias(\"amount_float\"), pl.col(\"amount_dollars\").cast(pl.Float64, strict=False).cast(pl.Int64, strict=False).alias(\"amount_int_dollars\")])\n",
    "\n",
    "# Show final DataFrame to inspect casting and resulting null values.\n",
    "# Output remains short and readable for beginners.\n",
    "# Notice how invalid entries become null instead of incorrect numbers.\n",
    "\n",
    "print(amount_cast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db9d0",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**DataFrames and Series**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033379f5",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Create Polars DataFrames and Series from common Python and file inputs used in Pandas workflows. \n",
    "- Inspect Polars DataFrame schemas and summarize data using built‑in methods. \n",
    "- Explain how Polars’ data types and null handling compare to Pandas. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Selecting and Filtering'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
