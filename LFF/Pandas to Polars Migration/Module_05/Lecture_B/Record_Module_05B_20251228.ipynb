{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d0ee3a",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Interoperability and Testing**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6fc61",
   "metadata": {},
   "source": [
    ">Last update: 20251228.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Convert data between Pandas and Polars safely when partial migration is required. \n",
    "- Design tests that compare outputs of Pandas and Polars implementations for the same logic. \n",
    "- Detect and handle subtle behavioral differences between Pandas and Polars, such as type coercion or null semantics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053d33a",
   "metadata": {},
   "source": [
    "## **1. Safe Data Conversion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f163f",
   "metadata": {},
   "source": [
    "### **1.1. Pandas Polars Conversion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f3c0d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_01_01.jpg?v=1766903734\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Treat Pandasâ€“Polars conversion as a critical boundary\n",
    ">* Preserve schema details and meaning during round trips\n",
    "\n",
    ">* Understand and align Pandas and Polars dtypes\n",
    ">* Clean data and verify Polars schema after conversion\n",
    "\n",
    ">* Preserve data meaning when returning to Pandas\n",
    ">* Document, validate, and control schema changes on conversion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Pandas Polars Conversion\n",
    "\n",
    "# Demonstrate safe conversion between Pandas and Polars dataframes.\n",
    "# Show how mixed types in Pandas affect Polars conversion.\n",
    "# Compare schemas before and after conversion for safer partial migration.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create a small Pandas dataframe with mixed type column.\n",
    "# Revenue column mixes numbers and string unknown marker.\n",
    "data_pandas = {\n",
    "    \"customer_id\": [1, 2, 3],\n",
    "    \"revenue_usd\": [100.0, \"unknown\", 250.5],\n",
    "}\n",
    "\n",
    "# Build the Pandas dataframe and inspect dtypes.\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "print(\"Pandas dataframe dtypes before cleaning:\")\n",
    "print(df_pandas.dtypes)\n",
    "\n",
    "# Clean the mixed column by coercing non numeric values to missing.\n",
    "df_pandas[\"revenue_usd\"] = pd.to_numeric(df_pandas[\"revenue_usd\"], errors=\"coerce\")\n",
    "print(\"\\nPandas dataframe dtypes after cleaning:\")\n",
    "print(df_pandas.dtypes)\n",
    "\n",
    "# Convert cleaned Pandas dataframe into Polars dataframe safely.\n",
    "df_polars = pl.from_pandas(df_pandas)\n",
    "print(\"\\nPolars schema after conversion:\")\n",
    "print(df_polars.schema)\n",
    "\n",
    "# Convert back from Polars to Pandas and compare dtypes again.\n",
    "df_roundtrip = df_polars.to_pandas()\n",
    "print(\"\\nRoundtrip Pandas dataframe dtypes:\")\n",
    "print(df_roundtrip.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58b20e",
   "metadata": {},
   "source": [
    "### **1.2. Arrow Interchange Bridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1cbd6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_01_02.jpg?v=1766903752\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use Arrow as neutral format between libraries\n",
    ">* Reduces quirks and keeps mixed pipelines consistent\n",
    "\n",
    ">* Arrow handles complex types consistently across systems\n",
    ">* Standardized schemas prevent subtle conversion bugs appearing\n",
    "\n",
    ">* Arrow standardizes shared datasets across diverse teams\n",
    ">* Enables reproducible analyses and reliable cross-tool interoperability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Arrow Interchange Bridge\n",
    "\n",
    "# Demonstrate Arrow bridge between Pandas and Polars safely.\n",
    "# Show conversion Pandas to Arrow then Polars clearly.\n",
    "# Highlight preserved types and missing values across conversions.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "\n",
    "# Create simple Pandas DataFrame with mixed types.\n",
    "# Include float, category, timestamp, and missing value.\n",
    "\n",
    "df_pandas = pd.DataFrame({\n",
    "    \"city\": pd.Series([\"Boston\", \"Dallas\", \"Miami\"], dtype=\"category\"),\n",
    "    \"temperature_f\": [72.5, None, 88.0],\n",
    "    \"timestamp\": pd.to_datetime([\n",
    "        \"2024-01-01 10:00:00\",\n",
    "        \"2024-01-01 11:00:00\",\n",
    "        \"2024-01-01 12:00:00\",\n",
    "    ]),\n",
    "})\n",
    "\n",
    "# Convert Pandas DataFrame into Arrow Table container.\n",
    "# Arrow acts as neutral shipping container here.\n",
    "\n",
    "table_arrow = pa.Table.from_pandas(df_pandas, preserve_index=False)\n",
    "\n",
    "# Convert Arrow Table into Polars DataFrame safely.\n",
    "# Polars understands Arrow columnar format.\n",
    "\n",
    "df_polars = pl.from_arrow(table_arrow)\n",
    "\n",
    "# Show Pandas dtypes and head for comparison.\n",
    "# This helps visualize original representation.\n",
    "\n",
    "print(\"PANDAS DATAFRAME AND DTYPES:\")\n",
    "print(df_pandas.dtypes)\n",
    "print(df_pandas.head())\n",
    "\n",
    "# Show Polars schema and head after Arrow bridge.\n",
    "# Types and nulls should remain consistent.\n",
    "\n",
    "print(\"\\nPOLARS DATAFRAME AND SCHEMA:\")\n",
    "print(df_polars.schema)\n",
    "print(df_polars.head())\n",
    "\n",
    "# Convert back from Polars to Arrow then Pandas again.\n",
    "# Confirm roundtrip stability through Arrow bridge.\n",
    "\n",
    "table_arrow_back = df_polars.to_arrow()\n",
    "df_pandas_back = table_arrow_back.to_pandas()\n",
    "\n",
    "# Show final Pandas dtypes after roundtrip conversion.\n",
    "# Compare with original to check safety.\n",
    "\n",
    "print(\"\\nPANDAS DTYPES AFTER ROUNDTRIP:\")\n",
    "print(df_pandas_back.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd1565",
   "metadata": {},
   "source": [
    "### **1.3. Conversion Performance Tradeoffs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79cfb2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_01_03.jpg?v=1766903814\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Dataframe conversions add memory and time overhead\n",
    ">* Frequent small conversions can outweigh engine speed gains\n",
    "\n",
    ">* Plan around data size and conversion frequency\n",
    ">* Convert big tables rarely; reuse small converted data\n",
    "\n",
    ">* Conversion overhead affects memory, scalability, reliability\n",
    ">* Minimize conversions with selective columns and batching\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58681604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Conversion Performance Tradeoffs\n",
    "\n",
    "# Compare conversion heavy workflow versus conversion light workflow performance.\n",
    "# Show how repeated conversions add overhead and reduce overall speed.\n",
    "# Help reason about when conversions are worth the performance toll.\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import polars as pl\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install polars --quiet\n",
    "    import polars as pl\n",
    "\n",
    "n_rows = 2_000_000\n",
    "n_conversions_heavy = 20\n",
    "n_conversions_light = 2\n",
    "\n",
    "values = np.random.rand(n_rows)\n",
    "ids = np.random.randint(0, 100, size=n_rows)\n",
    "\n",
    "pdf = pd.DataFrame({\"id\": ids, \"value\": values})\n",
    "\n",
    "start_heavy = time.time()\n",
    "current_pdf = pdf.copy()\n",
    "\n",
    "for i in range(n_conversions_heavy):\n",
    "    pl_df = pl.from_pandas(current_pdf)\n",
    "    pl_df = pl_df.with_columns((pl.col(\"value\") * 1.01).alias(\"value\"))\n",
    "    current_pdf = pl_df.to_pandas()\n",
    "\n",
    "heavy_duration = time.time() - start_heavy\n",
    "\n",
    "start_light = time.time()\n",
    "pl_df_light = pl.from_pandas(pdf)\n",
    "\n",
    "pl_df_light = pl_df_light.with_columns((pl.col(\"value\") * 1.01).alias(\"value\"))\n",
    "pl_df_light = pl_df_light.with_columns((pl.col(\"value\") * 1.01).alias(\"value\"))\n",
    "\n",
    "light_pdf = pl_df_light.to_pandas()\n",
    "light_duration = time.time() - start_light\n",
    "\n",
    "print(\"Rows processed, approximately count:\", n_rows)\n",
    "print(\"Heavy conversions count, total crossings:\", n_conversions_heavy)\n",
    "print(\"Light conversions count, total crossings:\", n_conversions_light)\n",
    "print(\"Heavy pattern seconds, approximate duration:\", round(heavy_duration, 3))\n",
    "print(\"Light pattern seconds, approximate duration:\", round(light_duration, 3))\n",
    "print(\"Speedup factor, heavy divided by light:\", round(heavy_duration / light_duration, 1))\n",
    "print(\"Final heavy mean value, approximate result:\", round(current_pdf[\"value\"].mean(), 4))\n",
    "print(\"Final light mean value, approximate result:\", round(light_pdf[\"value\"].mean(), 4))\n",
    "print(\"Observation, fewer crossings usually save time.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd38f3",
   "metadata": {},
   "source": [
    "## **2. Testing Crossframe Consistency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69382d57",
   "metadata": {},
   "source": [
    "### **2.1. Golden data baselines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e25f54",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_02_01.jpg?v=1766903844\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Curated datasets define correct results for transformations\n",
    ">* Both Pandas and Polars must match baseline\n",
    "\n",
    ">* Design small, clear datasets covering tricky edge cases\n",
    ">* Lock baselines, reuse them, and expand with discoveries\n",
    "\n",
    ">* Golden baselines anchor automated, versioned crossframe tests\n",
    ">* They expose differences, document changes, preserve business meaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Golden data baselines\n",
    "\n",
    "# Demonstrate golden baseline testing with Pandas and Polars together.\n",
    "# Show how expected results are stored and compared consistently.\n",
    "# Highlight how both libraries must match the same trusted baseline.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create a tiny golden baseline input dataset in memory.\n",
    "# This simulates monthly revenue per customer with simple edge cases.\n",
    "input_data = [\n",
    "    {\"customer_id\": \"A\", \"month\": \"2024-01\", \"amount_usd\": 100.0},\n",
    "    {\"customer_id\": \"A\", \"month\": \"2024-01\", \"amount_usd\": -20.0},\n",
    "    {\"customer_id\": \"B\", \"month\": \"2024-01\", \"amount_usd\": 50.0},\n",
    "]\n",
    "\n",
    "# Create the trusted golden expected output for grouped revenue.\n",
    "# These values would normally be reviewed and version controlled.\n",
    "golden_output = [\n",
    "    {\"customer_id\": \"A\", \"month\": \"2024-01\", \"total_revenue_usd\": 80.0},\n",
    "    {\"customer_id\": \"B\", \"month\": \"2024-01\", \"total_revenue_usd\": 50.0},\n",
    "]\n",
    "\n",
    "# Build Pandas DataFrame from the golden input data.\n",
    "# Then compute grouped totals using Pandas operations.\n",
    "pd_df = pd.DataFrame(input_data)\n",
    "pd_result = (\n",
    "    pd_df.groupby([\"customer_id\", \"month\"], as_index=False)[\"amount_usd\"].sum()\n",
    "    .rename(columns={\"amount_usd\": \"total_revenue_usd\"})\n",
    ")\n",
    "\n",
    "# Build Polars DataFrame from the same golden input data.\n",
    "# Then compute grouped totals using Polars operations.\n",
    "pl_df = pl.DataFrame(input_data)\n",
    "pl_result = (\n",
    "    pl_df.group_by([\"customer_id\", \"month\"]).agg(\n",
    "        pl.col(\"amount_usd\").sum().alias(\"total_revenue_usd\")\n",
    "    ).sort([\"customer_id\", \"month\"])\n",
    ")\n",
    "\n",
    "# Convert golden expected output into Pandas and Polars for comparison.\n",
    "# In practice these would be loaded from stable files.\n",
    "golden_pd = pd.DataFrame(golden_output)\n",
    "golden_pl = pl.DataFrame(golden_output).sort([\"customer_id\", \"month\"])\n",
    "\n",
    "# Compare Pandas result to golden baseline using equality checks.\n",
    "# Any mismatch means the implementation is not trusted yet.\n",
    "pandas_matches = pd_result.equals(golden_pd)\n",
    "\n",
    "# Compare Polars result to golden baseline after conversion.\n",
    "# We convert Polars result into Pandas for simple comparison.\n",
    "polars_matches = pl_result.to_pandas().equals(golden_pd)\n",
    "\n",
    "# Print a short summary showing whether each library matches the baseline.\n",
    "# This mirrors what automated tests would assert in continuous integration.\n",
    "print(\"Golden baseline comparison summary:\")\n",
    "print(\"Pandas matches golden baseline:\", pandas_matches)\n",
    "print(\"Polars matches golden baseline:\", polars_matches)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bfaff",
   "metadata": {},
   "source": [
    "### **2.2. Property Based Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6924af",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_02_02.jpg?v=1766903865\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Define general behaviors that must always hold\n",
    ">* Auto-generate many dataframes to compare library outputs\n",
    "\n",
    ">* Focus on invariants, not exact row matches\n",
    ">* Encode structural and aggregate expectations as properties\n",
    "\n",
    ">* Generated data reveals rare, tricky edge cases\n",
    ">* Shrunk failures become reusable regression test examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Property Based Testing\n",
    "\n",
    "# Demonstrate property based testing comparing Pandas and Polars results.\n",
    "# Use Hypothesis to generate random DataFrames with numeric revenue values.\n",
    "# Check that grouped revenue sums match across both libraries consistently.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from hypothesis import given, settings\n",
    "from hypothesis import strategies as st\n",
    "\n",
    "# Create a Hypothesis strategy that builds random Pandas DataFrames.\n",
    "# DataFrames contain customer ids and revenue values with possible nulls.\n",
    "# This strategy keeps sizes small so tests run quickly.\n",
    "\n",
    "customer_ids_strategy = st.integers(min_value=1, max_value=5)\n",
    "revenue_strategy = st.floats(min_value=-1000.0, max_value=1000.0, allow_nan=False)\n",
    "rows_strategy = st.lists(st.tuples(customer_ids_strategy, revenue_strategy), min_size=1, max_size=8)\n",
    "\n",
    "# Convert generated rows into a simple Pandas DataFrame for testing.\n",
    "# Columns represent customer identifiers and associated revenue amounts.\n",
    "# This function is used inside the property based test.\n",
    "\n",
    "def build_pandas_frame(rows):\n",
    "    df = pd.DataFrame(rows, columns=[\"customer_id\", \"revenue\"])\n",
    "    return df\n",
    "\n",
    "# Define a property that grouped revenue sums must match across libraries.\n",
    "# We group by customer identifier and sum revenue values for each customer.\n",
    "# The property compares numeric results within a small tolerance.\n",
    "\n",
    "@given(rows=rows_strategy)\n",
    "@settings(max_examples=20)\n",
    "def test_groupby_sum_matches(rows):\n",
    "    pdf = build_pandas_frame(rows)\n",
    "    pl_df = pl.from_pandas(pdf)\n",
    "    pandas_result = pdf.groupby(\"customer_id\", as_index=False)[\"revenue\"].sum()\n",
    "\n",
    "    polars_result = (\n",
    "        pl_df.groupby(\"customer_id\")\n",
    "        .agg(pl.col(\"revenue\").sum())\n",
    "        .sort(\"customer_id\")\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    pandas_sorted = pandas_result.sort_values(\"customer_id\").reset_index(drop=True)\n",
    "    polars_sorted = polars_result.sort_values(\"customer_id\").reset_index(drop=True)\n",
    "\n",
    "    assert len(pandas_sorted) == len(polars_sorted)\n",
    "    for idx in range(len(pandas_sorted)):\n",
    "        assert pandas_sorted.loc[idx, \"customer_id\"] == polars_sorted.loc[idx, \"customer_id\"]\n",
    "        diff = abs(pandas_sorted.loc[idx, \"revenue\"] - polars_sorted.loc[idx, \"revenue\"])\n",
    "        assert diff < 1e-9\n",
    "\n",
    "# Run the property based test and print a short confirmation message.\n",
    "# Hypothesis will generate many random inputs behind the scenes.\n",
    "# If no assertion fails, we consider implementations consistent.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_groupby_sum_matches()\n",
    "    print(\"Property based test passed, grouped revenue sums match across libraries.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4d648",
   "metadata": {},
   "source": [
    "### **2.3. Numeric Tolerance Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ab9da",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_02_03.jpg?v=1766903883\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Small numeric differences are normal between frameworks\n",
    ">* Use tolerances to treat close results as equivalent\n",
    "\n",
    ">* Use absolute and relative tolerances for comparisons\n",
    ">* Apply context-aware thresholds at multiple data levels\n",
    "\n",
    ">* Report detailed stats for out-of-tolerance differences\n",
    ">* Use diagnostics to refine thresholds and document quirks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Numeric Tolerance Strategies\n",
    "\n",
    "# Demonstrate numeric tolerance when comparing two calculation results from different implementations.\n",
    "# Show absolute and relative tolerance checks using simple floating point examples.\n",
    "# Print clear messages explaining when values are considered close enough or significantly different.\n",
    "\n",
    "import math\n",
    "\n",
    "# Define two results that should be almost equal but not exactly equal.\n",
    "result_pandas_style = 0.1 + 0.1 + 0.1 + 0.1\n",
    "result_polars_style = 0.4\n",
    "\n",
    "# Define absolute tolerance for values around one dollar or less.\n",
    "abs_tolerance = 0.0001\n",
    "\n",
    "# Define relative tolerance for values that might be much larger.\n",
    "rel_tolerance = 0.001\n",
    "\n",
    "# Compute absolute difference between the two simulated framework results.\n",
    "abs_difference = abs(result_pandas_style - result_polars_style)\n",
    "\n",
    "# Check closeness using only absolute tolerance for small scale values.\n",
    "abs_close = abs_difference <= abs_tolerance\n",
    "\n",
    "# Compute relative difference scaled by the larger magnitude value.\n",
    "max_magnitude = max(abs(result_pandas_style), abs(result_polars_style))\n",
    "\n",
    "rel_difference = abs_difference / max_magnitude if max_magnitude != 0 else 0.0\n",
    "\n",
    "# Check closeness using relative tolerance for potentially large scale values.\n",
    "rel_close = rel_difference <= rel_tolerance\n",
    "\n",
    "# Use math.isclose to combine absolute and relative tolerance checks.\n",
    "combined_close = math.isclose(result_pandas_style, result_polars_style, rel_tol=rel_tolerance, abs_tol=abs_tolerance)\n",
    "\n",
    "# Print numeric values and tolerance decisions for clear comparison understanding.\n",
    "print(\"Pandas style result:\", result_pandas_style)\n",
    "print(\"Polars style result:\", result_polars_style)\n",
    "print(\"Absolute difference value:\", abs_difference)\n",
    "print(\"Absolute close within tolerance:\", abs_close)\n",
    "print(\"Relative difference ratio:\", rel_difference)\n",
    "print(\"Relative close within tolerance:\", rel_close)\n",
    "print(\"Combined tolerance close decision:\", combined_close)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba1274",
   "metadata": {},
   "source": [
    "## **3. Behavioral Differences**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c008e6f",
   "metadata": {},
   "source": [
    "### **3.1. Type Coercion Pitfalls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecd108",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_03_01.jpg?v=1766903909\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Different libraries silently change column data types\n",
    ">* Hidden coercion causes rounding errors and discrepancies\n",
    "\n",
    ">* Mixed-type columns are coerced differently across libraries\n",
    ">* Unaligned coercion affects calculations, comparisons, and decisions\n",
    "\n",
    ">* Type promotion differs in aggregations, joins, booleans\n",
    ">* Make types explicit, validate schemas, cast deliberately\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cde411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Type Coercion Pitfalls\n",
    "\n",
    "# Demonstrate type coercion differences between Pandas and Polars operations.\n",
    "# Show how integer division can silently change column data types unexpectedly.\n",
    "# Encourage explicit casting to keep financial style integer cents precise.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create simple cents amounts representing dollars and cents as integers.\n",
    "amounts_list = [150, 275, 325, 500]\n",
    "print(\"Original integer cents list values:\", amounts_list)\n",
    "\n",
    "# Build Pandas DataFrame and perform division by integer divisor.\n",
    "pd_df = pd.DataFrame({\"cents\": amounts_list})\n",
    "pd_df[\"dollars\"] = pd_df[\"cents\"] / 100\n",
    "print(\"Pandas column types after division:\")\n",
    "print(pd_df.dtypes)\n",
    "\n",
    "# Build Polars DataFrame and perform same division operation similarly.\n",
    "pl_df = pl.DataFrame({\"cents\": amounts_list})\n",
    "pl_df = pl_df.with_columns((pl.col(\"cents\") / 100).alias(\"dollars\"))\n",
    "print(\"Polars schema types after division:\")\n",
    "print(pl_df.schema)\n",
    "\n",
    "# Show explicit casting in Polars to keep integer cents division precise.\n",
    "pl_df_fixed = pl_df.with_columns((pl.col(\"cents\") // 100).alias(\"dollars_int\"))\n",
    "print(\"Polars schema types after integer floor division:\")\n",
    "print(pl_df_fixed.schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1062bb1",
   "metadata": {},
   "source": [
    "### **3.2. Null Handling Differences**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4db07f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_03_02.jpg?v=1766903930\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pandas and Polars treat missing values differently\n",
    ">* Differences affect types, counts, and downstream behavior\n",
    "\n",
    ">* Nulls affect math, grouping, and joins differently\n",
    ">* Define and encode clear null semantics in both\n",
    "\n",
    ">* Create test datasets to compare null behavior\n",
    ">* Derive shared rules and conventions for nulls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b43b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Null Handling Differences\n",
    "\n",
    "# Demonstrate different null handling between Pandas and Polars clearly.\n",
    "# Show how arithmetic and grouping behave with missing values differently.\n",
    "# Help you design consistent null handling rules across both libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create simple customer revenue data with missing values included.\n",
    "# None represents missing revenue, and None user means unknown customer.\n",
    "# Values are small and readable, representing dollars and user identifiers.\n",
    "\n",
    "data = {\"user\": [\"A\", \"B\", None, \"A\"], \"revenue\": [10.0, None, 5.0, None]}\n",
    "\n",
    "# Build a Pandas DataFrame from the shared dictionary data.\n",
    "# Build a Polars DataFrame from the same dictionary data.\n",
    "# These frames look similar but handle nulls differently internally.\n",
    "\n",
    "df_pd = pd.DataFrame(data)\n",
    "df_pl = pl.DataFrame(data)\n",
    "\n",
    "# Show original dataframes to confirm identical starting values visually.\n",
    "# Printing both helps compare structures and missing markers quickly.\n",
    "\n",
    "print(\"Pandas original dataframe:\")\n",
    "print(df_pd)\n",
    "print(\"\\nPolars original dataframe:\")\n",
    "print(df_pl)\n",
    "\n",
    "# Compute revenue per user count in Pandas, ignoring null revenues automatically.\n",
    "# groupby and mean will skip NaN values, affecting averages and counts.\n",
    "\n",
    "pd_group = df_pd.groupby(\"user\", dropna=False)[\"revenue\"].mean()\n",
    "\n",
    "# Compute revenue per user count in Polars, using mean aggregation similarly.\n",
    "# Polars also skips nulls, but output types and formatting may differ.\n",
    "\n",
    "pl_group = df_pl.group_by(\"user\").agg(pl.col(\"revenue\").mean()).sort(\"user\")\n",
    "\n",
    "# Show grouped results side by side for clear comparison.\n",
    "# Notice how missing user keys and null revenues are treated differently.\n",
    "\n",
    "print(\"\\nPandas mean revenue by user:\")\n",
    "print(pd_group)\n",
    "print(\"\\nPolars mean revenue by user:\")\n",
    "print(pl_group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf7ea5",
   "metadata": {},
   "source": [
    "### **3.3. Index and Order Semantics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429be7a2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas to Polars Migration/Module_05/Lecture_B/image_03_03.jpg?v=1766903949\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Row identity and order differ across libraries\n",
    ">* Index versus position affects joins, alignment, comparisons\n",
    "\n",
    ">* Row order can change across different systems\n",
    ">* Always sort and normalize order before comparing\n",
    "\n",
    ">* Indexes can align rows or act positional\n",
    ">* Standardize keys, indexes, and sorting before comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Index and Order Semantics\n",
    "\n",
    "# Demonstrate index and order differences between Pandas and Polars.\n",
    "# Show how joins behave with index labels versus plain columns.\n",
    "# Emphasize sorting and resetting index before comparing results.\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Create simple customer orders dataframe with custom index labels.\n",
    "pd_orders = pd.DataFrame({\"customer_id\": [101, 102], \"amount_usd\": [50, 80]}, index=[\"rowA\", \"rowB\"])\n",
    "\n",
    "# Create payments dataframe with different index labels but matching customer ids.\n",
    "pd_payments = pd.DataFrame({\"customer_id\": [102, 101], \"paid_usd\": [80, 50]}, index=[\"x1\", \"x2\"])\n",
    "\n",
    "# Pandas join using index alignment, which ignores customer_id column order.\n",
    "pd_join_index = pd_orders.join(pd_payments.set_index(pd_orders.index), rsuffix=\"_pay\")\n",
    "\n",
    "# Pandas join using explicit customer_id column, enforcing key based alignment.\n",
    "pd_join_key = pd_orders.reset_index(drop=True).merge(pd_payments, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Convert same dataframes to Polars, which ignores Pandas index semantics.\n",
    "pl_orders = pl.from_pandas(pd_orders.reset_index(drop=True))\n",
    "\n",
    "pl_payments = pl.from_pandas(pd_payments.reset_index(drop=True))\n",
    "\n",
    "# Polars join always uses explicit columns, here customer_id, for alignment.\n",
    "pl_join_key = pl_orders.join(pl_payments, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Print results with clear labels, highlighting index and order behavior.\n",
    "print(\"Pandas join using index alignment order:\")\n",
    "\n",
    "print(pd_join_index)\n",
    "\n",
    "print(\"\\nPandas join using customer_id key:\")\n",
    "\n",
    "print(pd_join_key)\n",
    "\n",
    "print(\"\\nPolars join using customer_id key:\")\n",
    "\n",
    "print(pl_join_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd84d982",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Interoperability and Testing**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d3ead",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Convert data between Pandas and Polars safely when partial migration is required. \n",
    "- Design tests that compare outputs of Pandas and Polars implementations for the same logic. \n",
    "- Detect and handle subtle behavioral differences between Pandas and Polars, such as type coercion or null semantics. \n",
    "\n",
    "<font color='yellow'>Congratulations on completing this course!</font>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
