{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6721c862",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Regression Metrics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d6b89",
   "metadata": {},
   "source": [
    ">Last update: 20260201.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe common regression metrics in intuitive terms. \n",
    "- Compute simple regression metrics on small numeric examples. \n",
    "- Interpret regression metric values in the context of the original problem scale. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741eaf8f",
   "metadata": {},
   "source": [
    "## **1. Summarizing Prediction Errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254ecee",
   "metadata": {},
   "source": [
    "### **1.1. Mean absolute error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc8050",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_01_01.jpg?v=1769961980\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* MAE measures how far predictions miss reality\n",
    ">* Averages absolute errors, ignoring over or under direction\n",
    "\n",
    ">* MAE uses the same units as targets\n",
    ">* Helps judge if typical prediction error is acceptable\n",
    "\n",
    ">* MAE treats all errors proportional and symmetric\n",
    ">* Helps judge typical deviation when overunder equally bad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a22dd",
   "metadata": {},
   "source": [
    "### **1.2. Squared Error Intuition**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc062f7",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_01_02.jpg?v=1769961992\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Squared error measures how far predictions are\n",
    ">* Big mistakes count much more than small ones\n",
    "\n",
    ">* Squared error rewards models with consistent small mistakes\n",
    ">* Rare large errors dominate, signaling serious reliability problems\n",
    "\n",
    ">* Squaring distance makes large prediction gaps dominate\n",
    ">* Helps highlight rare, severe errors in practice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13358ba7",
   "metadata": {},
   "source": [
    "### **1.3. Penalizing Large Errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcae17c",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_01_03.jpg?v=1769962005\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Large prediction mistakes can matter more than averages\n",
    ">* Metrics weight big errors heavily to punish them\n",
    "\n",
    ">* Squaring errors makes big mistakes count much more\n",
    ">* Models with rare extreme errors get worse scores\n",
    "\n",
    ">* Some fields suffer huge, costly rare errors\n",
    ">* Metrics prioritize avoiding catastrophic mistakes over small noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9d10a",
   "metadata": {},
   "source": [
    "## **2. Hands On Regression Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28400373",
   "metadata": {},
   "source": [
    "### **2.1. Tiny Data Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fa92e",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_02_01.jpg?v=1769962018\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use tiny datasets to practice regression metrics\n",
    ">* Hand calculations build intuition for larger problems\n",
    "\n",
    ">* Use tiny blood pressure data to inspect errors\n",
    ">* Manually compute averages to see metric building blocks\n",
    "\n",
    ">* Reuse tiny datasets across many prediction problems\n",
    ">* See how small changes and outliers affect metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec78810",
   "metadata": {},
   "source": [
    "### **2.2. Metric Calculations Walkthrough**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a6161",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_02_02.jpg?v=1769962030\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use a small energy example to practice\n",
    ">* Compute signed errors, then summarize them with metrics\n",
    "\n",
    ">* Compute mean and mean absolute error from residuals\n",
    ">* Use squared errors and RMSE to stress large mistakes\n",
    "\n",
    ">* Compare model squared error to naive baseline\n",
    ">* Express improvement as proportion of baseline error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Metric Calculations Walkthrough\n",
    "\n",
    "# This script walks through simple regression metrics.\n",
    "# It uses tiny energy consumption prediction examples.\n",
    "# Focus on clear calculations and printed metric values.\n",
    "\n",
    "# Required libraries are available in Colab by default.\n",
    "# Uncomment next line only if numpy is missing.\n",
    "# !pip install numpy.\n",
    "\n",
    "# Import numpy for convenient numeric array operations.\n",
    "import numpy as np\n",
    "\n",
    "# Define actual daily energy consumptions in kilowatt hours.\n",
    "actual_values = np.array([10.0, 15.0, 20.0, 25.0])\n",
    "\n",
    "# Define model predictions for the same four buildings.\n",
    "predicted_values = np.array([12.0, 14.0, 18.0, 30.0])\n",
    "\n",
    "# Validate that actual and predicted arrays have equal length.\n",
    "assert actual_values.shape == predicted_values.shape\n",
    "\n",
    "# Compute raw errors as actual minus predicted values.\n",
    "errors = actual_values - predicted_values\n",
    "\n",
    "# Compute mean error to show average prediction bias.\n",
    "mean_error = float(np.mean(errors))\n",
    "\n",
    "# Compute mean absolute error in original kilowatt hour units.\n",
    "mean_absolute_error = float(np.mean(np.abs(errors)))\n",
    "\n",
    "# Compute root mean squared error emphasizing larger mistakes.\n",
    "mean_squared_error = float(np.mean(errors ** 2))\n",
    "\n",
    "# Take square root of mean squared error for final metric.\n",
    "root_mean_squared_error = float(np.sqrt(mean_squared_error))\n",
    "\n",
    "# Build a naive baseline predicting the mean actual consumption.\n",
    "baseline_prediction = float(np.mean(actual_values))\n",
    "\n",
    "# Create baseline prediction array matching actual values length.\n",
    "baseline_predictions = np.full_like(actual_values, baseline_prediction)\n",
    "\n",
    "# Compute total squared error for the naive baseline.\n",
    "baseline_sse = float(np.sum((actual_values - baseline_predictions) ** 2))\n",
    "\n",
    "# Compute total squared error for the trained model predictions.\n",
    "model_sse = float(np.sum((actual_values - predicted_values) ** 2))\n",
    "\n",
    "# Compute proportion of baseline error removed by the model.\n",
    "improvement_ratio = 1.0 - (model_sse / baseline_sse)\n",
    "\n",
    "# Print a short summary of all computed regression metrics.\n",
    "print(\"Mean error bias:\", mean_error,\n",
    "      \"MAE:\", mean_absolute_error,\n",
    "      \"RMSE:\", root_mean_squared_error,\n",
    "      \"Improvement ratio:\", improvement_ratio)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fdd9a",
   "metadata": {},
   "source": [
    "### **2.3. Comparing Model Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a6e64",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_02_03.jpg?v=1769962078\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Compare models using metrics on same data\n",
    ">* Lower average error means predictions closer to truth\n",
    "\n",
    ">* Use multiple metrics to compare model behavior\n",
    ">* Large RMSE warns about rare, huge errors\n",
    "\n",
    ">* Use tiny examples to weigh accuracy versus cost\n",
    ">* Judge if error differences matter in real units\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ea5cc",
   "metadata": {},
   "source": [
    "## **3. Interpreting Error Scale**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcf199",
   "metadata": {},
   "source": [
    "### **3.1. Error Units Explained**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a2bc6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_03_01.jpg?v=1769962092\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Error metrics share units with target values\n",
    ">* Units make errors interpretable and comparisons meaningful\n",
    "\n",
    ">* Express errors using the original measurement units\n",
    ">* Makes performance intuitive for non-technical decision makers\n",
    "\n",
    ">* Some metrics keep original units, others donâ€™t\n",
    ">* Using original units makes errors concrete and comparable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685d1ec",
   "metadata": {},
   "source": [
    "### **3.2. Relative Versus Absolute Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c45688",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_03_02.jpg?v=1769962107\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Absolute error is raw difference in units\n",
    ">* Relative error expresses that difference as a proportion\n",
    "\n",
    ">* Same absolute error can mean very different things\n",
    ">* Relative error normalizes scale, emphasizing proportional accuracy\n",
    "\n",
    ">* Use absolute and relative error together thoughtfully\n",
    ">* Judge errors by real-world units and proportions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf299d4",
   "metadata": {},
   "source": [
    "### **3.3. Error Acceptability Context**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5daa3",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_06/Lecture_A/image_03_03.jpg?v=1769962119\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Judge errors by real-world use and stakes\n",
    ">* Same metric value can be safe or harmful\n",
    "\n",
    ">* Judge errors against domain-specific thresholds or limits\n",
    ">* Same numeric error acceptable or harmful by context\n",
    "\n",
    ">* Acceptable error depends on accuracy, cost, speed\n",
    ">* Judge errors by risk, consequences, and constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f9724",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Regression Metrics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02c770",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe common regression metrics in intuitive terms. \n",
    "- Compute simple regression metrics on small numeric examples. \n",
    "- Interpret regression metric values in the context of the original problem scale. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Classification Metrics'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
