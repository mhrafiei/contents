{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b28acc",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Linear Regression**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761db6aa",
   "metadata": {},
   "source": [
    ">Last update: 20260131.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe linear regression as fitting a line or plane to numeric data. \n",
    "- Interpret the meaning of regression coefficients in simple examples. \n",
    "- Assess the quality of a linear regression fit using visual patterns of errors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a022c6f",
   "metadata": {},
   "source": [
    "## **1. Lines for Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad8ccf",
   "metadata": {},
   "source": [
    "### **1.1. Visualizing Data Relationships**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9003a7",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_01_01.jpg?v=1769920529\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Plot paired numbers as points on graphs\n",
    ">* Patterns in the point cloud reveal relationships\n",
    "\n",
    ">* Scatterplots show how two numeric variables move\n",
    ">* Point patterns reveal strength and direction of relationships\n",
    "\n",
    ">* Scatterplots reveal trends, curves, clusters, and outliers\n",
    ">* These patterns show when a straight line works\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a19527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Visualizing Data Relationships\n",
    "\n",
    "# This script visualizes simple numeric relationships clearly.\n",
    "# We use synthetic study hours and exam scores.\n",
    "# Focus on understanding scatter plots and visible trends.\n",
    "\n",
    "# import required plotting and numeric libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set a deterministic random seed for reproducibility.\n",
    "np.random.seed(42)\n",
    "\n",
    "# create small array of study hours values.\n",
    "study_hours = np.linspace(0, 10, 20)\n",
    "\n",
    "# create exam scores with simple upward trend.\n",
    "exam_scores = (50 + 5 * study_hours + np.random.normal(\n",
    "    loc=0,\n",
    "    scale=5,\n",
    "    size=study_hours.shape,\n",
    "))\n",
    "\n",
    "# print short description of the created data.\n",
    "print(\"We created\", study_hours.size, \"students with hours and scores.\")\n",
    "\n",
    "# check that both arrays have matching shapes.\n",
    "assert study_hours.shape == exam_scores.shape\n",
    "\n",
    "# create a scatter plot showing the relationship.\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# plot each student as one point on the graph.\n",
    "plt.scatter(study_hours, exam_scores, color=\"tab:blue\", label=\"Students\")\n",
    "\n",
    "# label axes to explain what each direction means.\n",
    "plt.xlabel(\"Hours studied\")\n",
    "plt.ylabel(\"Exam score\")\n",
    "\n",
    "# add a helpful title describing the relationship.\n",
    "plt.title(\"Visualizing relationship between study hours and exam scores\")\n",
    "\n",
    "# add a light grid and legend for readability.\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend()\n",
    "\n",
    "# display the final scatter plot figure.\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae01d0",
   "metadata": {},
   "source": [
    "### **1.2. Line as simple summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b11ab",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_01_02.jpg?v=1769920557\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Line summarizes messy scatter of data points\n",
    ">* It shows average trend between two numeric variables\n",
    "\n",
    ">* Line highlights the main, predictable data trend\n",
    ">* Distances from line show random, unexplained variation\n",
    "\n",
    ">* Lines turn data patterns into predictions\n",
    ">* They give practical estimates while acknowledging uncertainty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0badf796",
   "metadata": {},
   "source": [
    "### **1.3. Many Inputs One Line**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3fea8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_01_03.jpg?v=1769920568\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Real predictions often use many numeric inputs\n",
    ">* Linear regression fits one plane through multidimensional data\n",
    "\n",
    ">* Each data point has coordinates for every input\n",
    ">* One flat surface combines inputs for one prediction\n",
    "\n",
    ">* Each input adds steady, additive influence on outcomes\n",
    ">* One geometric surface summarizes multi-dimensional prediction patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0b038",
   "metadata": {},
   "source": [
    "## **2. Interpreting Regression Coefficients**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5a575",
   "metadata": {},
   "source": [
    "### **2.1. Single Feature Effect**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2c091",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_02_01.jpg?v=1769920581\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Coefficient shows outcome change per feature unit\n",
    ">* Sign and size show direction and strength\n",
    "\n",
    ">* Coefficients link feature units to outcome changes\n",
    ">* Sign shows whether outcome increases or decreases\n",
    "\n",
    ">* Coefficients describe average trends, not exact outcomes\n",
    ">* They guide decisions while allowing individual differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Single Feature Effect\n",
    "\n",
    "# This script shows single feature regression coefficients simply.\n",
    "# We use a tiny dataset about study hours and scores.\n",
    "# Focus on interpreting slope as single feature effect.\n",
    "\n",
    "# import required numerical and plotting libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create small synthetic data for hours and scores.\n",
    "hours = np.array([1, 2, 3, 4, 5, 6], dtype=float)\n",
    "\n",
    "# create exam scores with roughly linear relationship.\n",
    "scores = np.array([52, 57, 63, 68, 74, 79], dtype=float)\n",
    "\n",
    "# check shapes to ensure matching lengths.\n",
    "assert hours.shape == scores.shape\n",
    "\n",
    "# build design matrix with column of ones and hours.\n",
    "X = np.column_stack((np.ones_like(hours), hours))\n",
    "\n",
    "# compute coefficients using normal equation formula.\n",
    "XtX = X.T @ X\n",
    "XtX_inv = np.linalg.inv(XtX)\n",
    "\n",
    "# compute final coefficient vector for intercept and slope.\n",
    "coef = XtX_inv @ (X.T @ scores)\n",
    "\n",
    "# unpack intercept and slope for easier interpretation.\n",
    "intercept, slope = coef\n",
    "\n",
    "# print interpretation of slope as single feature effect.\n",
    "print(\"Hours feature slope:\", round(float(slope), 2))\n",
    "print(\"Each extra study hour adds about\", round(float(slope), 2), \"score points.\")\n",
    "\n",
    "# create predictions for plotting fitted line.\n",
    "hours_line = np.linspace(hours.min(), hours.max(), 50)\n",
    "\n",
    "# compute predicted scores along the fitted line.\n",
    "pred_line = intercept + slope * hours_line\n",
    "\n",
    "# start a simple scatter plot of data points.\n",
    "plt.scatter(hours, scores, color=\"blue\", label=\"Observed scores\")\n",
    "\n",
    "# plot the fitted regression line for interpretation.\n",
    "plt.plot(hours_line, pred_line, color=\"red\", label=\"Fitted line\")\n",
    "\n",
    "# label axes to show feature and outcome clearly.\n",
    "plt.xlabel(\"Study hours per week\")\n",
    "plt.ylabel(\"Exam score\")\n",
    "\n",
    "# add title explaining single feature effect meaning.\n",
    "plt.title(\"Single Feature Effect of Study Hours on Exam Score\")\n",
    "\n",
    "# show legend to distinguish data and fitted line.\n",
    "plt.legend()\n",
    "\n",
    "# display the final plot window for learners.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e64f12",
   "metadata": {},
   "source": [
    "### **2.2. Understanding the Intercept**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ed054",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_02_02.jpg?v=1769920598\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Intercept predicts outcome when inputs equal zero\n",
    ">* Acts as vertical anchor ensuring best line fit\n",
    "\n",
    ">* Intercept often represents a baseline outcome level\n",
    ">* Shows expected result when inputs are zero\n",
    "\n",
    ">* Intercept meaning depends on predictor zero and range\n",
    ">* Centering predictors makes intercept describe average case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c7b03",
   "metadata": {},
   "source": [
    "### **2.3. Units and Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27d62a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_02_03.jpg?v=1769920609\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Coefficient meaning depends on variable measurement units\n",
    ">* Changing units changes coefficient size, not relationship\n",
    "\n",
    ">* Coefficient sizes depend on variable measurement units\n",
    ">* Rescaling changes numbers, not predictions; state units\n",
    "\n",
    ">* Rescaling variables makes coefficients clearer and comparable\n",
    ">* Coefficient meaning depends on chosen units or standardization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c5ab9",
   "metadata": {},
   "source": [
    "## **3. Visual Error Patterns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ef1b0",
   "metadata": {},
   "source": [
    "### **3.1. Prediction Versus Actual**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3904ca0",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_03_01.jpg?v=1769920621\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Plot predicted values against actual outcomes visually\n",
    ">* Good models show points close to reference line\n",
    "\n",
    ">* Use the plot to spot systematic bias\n",
    ">* See where predictions are reliable or misleading\n",
    "\n",
    ">* Curved or widening point patterns suggest nonlinearity, issues\n",
    ">* Reading these patterns builds intuition about model limits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38da36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Prediction Versus Actual\n",
    "\n",
    "# This script visualizes prediction versus actual values simply.\n",
    "# It supports understanding linear regression error patterns visually.\n",
    "# It uses tiny synthetic data for clear illustration.\n",
    "\n",
    "# import required numerical and plotting libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set a deterministic random seed for reproducibility.\n",
    "np.random.seed(42)\n",
    "\n",
    "# create simple feature values representing input data points.\n",
    "x_values = np.linspace(0, 10, 30)\n",
    "\n",
    "# generate actual outcomes using a linear rule plus noise.\n",
    "actual_values = (2.0 * x_values) + 3.0 + (\n",
    "    np.random.normal(loc=0.0, scale=2.0, size=x_values.shape)\n",
    ")\n",
    "\n",
    "# compute simple predicted values using an imperfect model.\n",
    "predicted_values = (1.7 * x_values) + 4.0\n",
    "\n",
    "# validate that actual and predicted arrays share the same shape.\n",
    "if actual_values.shape != predicted_values.shape:\n",
    "    raise ValueError(\"Actual and predicted shapes must match exactly.\")\n",
    "\n",
    "# print a short header describing the numeric comparison.\n",
    "print(\"Showing first five actual and predicted value pairs.\")\n",
    "\n",
    "# loop through first five points and print rounded comparison.\n",
    "for index in range(5):\n",
    "    print(\n",
    "        f\"Point {index}: actual={actual_values[index]:.1f}, \"\n",
    "        f\"predicted={predicted_values[index]:.1f}\"\n",
    "    )\n",
    "\n",
    "# create a new figure with a clear size for readability.\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# plot actual versus predicted points as blue circles.\n",
    "plt.scatter(\n",
    "    actual_values,\n",
    "    predicted_values,\n",
    "    color=\"blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Data points\",\n",
    ")\n",
    "\n",
    "# plot the ideal reference line where prediction equals actual.\n",
    "min_value = float(min(actual_values.min(), predicted_values.min()))\n",
    "max_value = float(max(actual_values.max(), predicted_values.max()))\n",
    "\n",
    "# create line values spanning the observed range.\n",
    "line_values = np.linspace(min_value, max_value, 50)\n",
    "\n",
    "# draw the reference diagonal line for perfect predictions.\n",
    "plt.plot(\n",
    "    line_values,\n",
    "    line_values,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Perfect prediction\",\n",
    ")\n",
    "\n",
    "# label axes to highlight actual and predicted meanings.\n",
    "plt.xlabel(\"Actual values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "\n",
    "# add a title emphasizing prediction versus actual comparison.\n",
    "plt.title(\"Prediction Versus Actual Values With Simple Linear Model\")\n",
    "\n",
    "# show legend to distinguish points and reference line.\n",
    "plt.legend()\n",
    "\n",
    "# enforce equal aspect ratio for easier visual comparison.\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# display the final plot window for visual inspection.\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae0e8f",
   "metadata": {},
   "source": [
    "### **3.2. Residuals as differences**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5beffa",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_03_02.jpg?v=1769920663\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Residuals equal actual value minus prediction\n",
    ">* They measure model error for each observation\n",
    "\n",
    ">* Residuals show error size and direction\n",
    ">* Positive means underprediction; negative means overprediction\n",
    "\n",
    ">* Plot residuals to check model performance visually\n",
    ">* Patterns reveal systematic under or overestimation problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd6c02",
   "metadata": {},
   "source": [
    "### **3.3. Warning Signs in Residuals**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06779079",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Machine Learning for Beginners/Module_04/Lecture_A/image_03_03.jpg?v=1769920674\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Patterns in residuals mean poor linear fit\n",
    ">* Curved or wavy residuals suggest missing nonlinearity\n",
    "\n",
    ">* Changing residual spread indicates non-constant variance\n",
    ">* Funnel-shaped residuals mean unreliable predictions for extremes\n",
    "\n",
    ">* Clusters, streaks, or huge residuals signal problems\n",
    ">* They reveal missing factors, dependence, or bad data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Warning Signs in Residuals\n",
    "\n",
    "# This script visualizes residual warning patterns simply.\n",
    "# It shows curvature and changing spread clearly.\n",
    "# It helps beginners judge linear regression fits.\n",
    "\n",
    "# Required libraries are available in Colab already.\n",
    "# !pip install numpy pandas matplotlib seaborn.\n",
    "\n",
    "# Import required numerical and plotting libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set deterministic random seed for reproducibility.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create simple predictor values for our example.\n",
    "x_values = np.linspace(0.0, 10.0, 60)\n",
    "\n",
    "# Define a simple linear relationship for predictions.\n",
    "y_pred_linear = 2.0 * x_values + 3.0\n",
    "\n",
    "# Create curved true relationship to break linearity.\n",
    "y_true_curved = 2.0 * x_values + 3.0 + 0.5 * (x_values - 5.0) ** 2\n",
    "\n",
    "# Add small random noise to curved true values.\n",
    "noise_values = np.random.normal(loc=0.0, scale=2.0, size=x_values.shape)\n",
    "\n",
    "# Compute observed values by adding noise to truth.\n",
    "y_observed = y_true_curved + noise_values\n",
    "\n",
    "# Compute residuals as observed minus predicted.\n",
    "residuals = y_observed - y_pred_linear\n",
    "\n",
    "# Validate shapes before plotting residuals safely.\n",
    "assert residuals.shape == x_values.shape\n",
    "\n",
    "# Create a figure with one residual scatter plot.\n",
    "fig, ax = plt.subplots(figsize=(6.0, 4.0))\n",
    "\n",
    "# Plot residuals against predicted values to see patterns.\n",
    "ax.scatter(y_pred_linear, residuals, color=\"tab:blue\", alpha=0.8)\n",
    "\n",
    "# Draw horizontal zero line to highlight systematic bias.\n",
    "ax.axhline(0.0, color=\"black\", linewidth=1.0, linestyle=\"--\")\n",
    "\n",
    "# Label axes to explain what the plot shows.\n",
    "ax.set_xlabel(\"Predicted value from linear model\")\n",
    "\n",
    "# Add y label describing residual definition clearly.\n",
    "ax.set_ylabel(\"Residual = observed value minus predicted value\")\n",
    "\n",
    "# Add title mentioning curvature warning sign pattern.\n",
    "ax.set_title(\"Residual plot showing curvature warning sign\")\n",
    "\n",
    "# Adjust layout so labels and title are clearly visible.\n",
    "fig.tight_layout()\n",
    "\n",
    "# Print short textual summary of visible warning signs.\n",
    "print(\"Residuals show curved pattern, suggesting missing nonlinearity.\")\n",
    "\n",
    "# Display the residual plot for visual inspection.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb708565",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Linear Regression**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c9f13",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe linear regression as fitting a line or plane to numeric data. \n",
    "- Interpret the meaning of regression coefficients in simple examples. \n",
    "- Assess the quality of a linear regression fit using visual patterns of errors. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Linear Classification'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
