{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eadf2ba",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Building Llama 3 Agents**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4be0d",
   "metadata": {},
   "source": [
    ">Last update: 20260118.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe how LangChain agents orchestrate Llama 3 reasoning and tool use. \n",
    "- Configure a LangChain agent that uses Llama 3 with tools and memory to solve multi-step tasks. \n",
    "- Analyze agent traces to debug reasoning errors and refine prompts, tools, or configurations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0db32",
   "metadata": {},
   "source": [
    "## **1. Agent Planning Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01019d",
   "metadata": {},
   "source": [
    "### **1.1. Planner Executor Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa6f2e",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_01_01.jpg?v=1768770217\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Planner designs step-by-step plan using tools\n",
    ">* Executor runs the plan, tools, and updates\n",
    "\n",
    ">* Planner designs structured, multi-step approach to tasks\n",
    ">* Executor runs tools, Llama 3 refines plan iteratively\n",
    "\n",
    ">* Planner and executor adapt plans as information changes\n",
    ">* Dynamic loop handles uncertainty and keeps progress clear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Planner Executor Workflow\n",
    "\n",
    "# Demonstrate simple planner executor workflow using plain Python structures.\n",
    "# Show planner creating steps and executor running those steps sequentially.\n",
    "# Print trace showing planning, execution, and final summarized result.\n",
    "\n",
    "# pip install commands are unnecessary because this script uses standard libraries only.\n",
    "\n",
    "# Define a simple planner that creates ordered task steps.\n",
    "def planner_create_plan(user_goal_description, available_tools_list):\n",
    "    # Build a high level plan using the described tools.\n",
    "    plan_steps_list = []\n",
    "    plan_steps_list.append(f\"Understand goal: {user_goal_description}.\")\n",
    "    plan_steps_list.append(f\"Collect data using: {available_tools_list}.\")\n",
    "    plan_steps_list.append(\"Analyze collected data for important patterns.\")\n",
    "    plan_steps_list.append(\"Summarize findings into clear recommendations.\")\n",
    "    return plan_steps_list\n",
    "\n",
    "# Define fake tools that the executor can call during execution.\n",
    "def tool_market_search(topic_description):\n",
    "    # Pretend to search markets and return short descriptive text.\n",
    "    return f\"Found strong demand for {topic_description} in urban United States regions.\"\n",
    "\n",
    "# Define another fake tool for cost estimation using simple arithmetic.\n",
    "def tool_cost_estimate(units_integer, unit_cost_dollars):\n",
    "    # Compute total cost using units and unit cost values.\n",
    "    total_cost_value = units_integer * unit_cost_dollars\n",
    "    return f\"Estimated marketing cost is ${total_cost_value} for {units_integer} units.\"\n",
    "\n",
    "# Define the executor that follows the plan and calls tools.\n",
    "def executor_run_plan(plan_steps_list, user_topic_description):\n",
    "    # Store intermediate results for later summarization.\n",
    "    results_dictionary = {}\n",
    "    print(\"--- Planning and execution trace start ---\")\n",
    "    print(\"Plan created by planner:\")\n",
    "    for index_value, step_text in enumerate(plan_steps_list, start=1):\n",
    "        print(f\"Step {index_value}: {step_text}\")\n",
    "\n",
    "    # Execute step two using the market search tool.\n",
    "    print(\"Executing step two using market search tool.\")\n",
    "    market_info_text = tool_market_search(user_topic_description)\n",
    "    results_dictionary[\"market_info\"] = market_info_text\n",
    "\n",
    "    # Execute step three using the cost estimate tool.\n",
    "    print(\"Executing step three using cost estimate tool.\")\n",
    "    cost_info_text = tool_cost_estimate(units_integer=1000, unit_cost_dollars=2)\n",
    "    results_dictionary[\"cost_info\"] = cost_info_text\n",
    "\n",
    "    # Simulate Llama reasoning that summarizes the collected information.\n",
    "    print(\"Executing final step summarizing collected information.\")\n",
    "    summary_text = (\n",
    "        f\"For product '{user_topic_description}', {market_info_text} \"\n",
    "        f\"Additionally, {cost_info_text}\"\n",
    "    )\n",
    "    results_dictionary[\"summary\"] = summary_text\n",
    "\n",
    "    print(\"--- Final agent answer ---\")\n",
    "    print(summary_text)\n",
    "    return results_dictionary\n",
    "\n",
    "# Main block that connects planner and executor for demonstration.\n",
    "if __name__ == \"__main__\":\n",
    "    # Define user goal and available tools for the planner.\n",
    "    user_goal_description = \"launching a new fitness tracker in major cities\"\n",
    "    available_tools_list = [\"market_search\", \"cost_estimate\"]\n",
    "\n",
    "    # Planner creates a plan using the goal and tools list.\n",
    "    plan_steps_list = planner_create_plan(user_goal_description, available_tools_list)\n",
    "\n",
    "    # Executor runs the plan and prints the trace and final answer.\n",
    "    executor_results_dictionary = executor_run_plan(plan_steps_list, \"fitness tracker\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139fc93",
   "metadata": {},
   "source": [
    "### **1.2. Tracing Thoughts and Actions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c516f2f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_01_02.jpg?v=1768770250\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tracing reveals the agentâ€™s hidden reasoning steps\n",
    ">* Shows tools used, inputs, outputs, and decisions\n",
    "\n",
    ">* Trace alternates between reasoning text and tool calls\n",
    ">* Tool results feed next steps until final answer\n",
    "\n",
    ">* Tracing reveals reasoning gaps and tool misuse\n",
    ">* Insights from traces guide refinements for reliability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tracing Thoughts and Actions\n",
    "\n",
    "# Demonstrate simple agent thoughts and actions tracing conceptually.\n",
    "# Show alternating thinking steps and tool actions clearly.\n",
    "# Help beginners visualize invisible reasoning sequences.\n",
    "# pip install langchain-openai langchain-community.\n",
    "\n",
    "# Define a simple tool that converts miles to kilometers.\n",
    "def convert_miles_to_km(miles_value):\n",
    "    km_value = miles_value * 1.60934\n",
    "    return km_value\n",
    "\n",
    "# Define a function that simulates agent reasoning steps.\n",
    "def plan_road_trip(distance_miles, fuel_mpg):\n",
    "    thoughts_and_actions = []\n",
    "    thoughts_and_actions.append(\"Thought: I need total fuel gallons.\")\n",
    "\n",
    "    gallons_needed = distance_miles / fuel_mpg\n",
    "    thoughts_and_actions.append(f\"Action: Calculated gallons needed: {gallons_needed:.2f}.\")\n",
    "\n",
    "    thoughts_and_actions.append(\"Thought: I want distance kilometers also.\")\n",
    "    km_distance = convert_miles_to_km(distance_miles)\n",
    "    thoughts_and_actions.append(f\"Action: Tool converted miles to kilometers: {km_distance:.1f}.\")\n",
    "\n",
    "    summary = f\"Final: Drive {distance_miles} miles using {gallons_needed:.1f} gallons.\"\n",
    "    thoughts_and_actions.append(summary)\n",
    "    return thoughts_and_actions\n",
    "\n",
    "# Run the simulated agent and print traced steps.\n",
    "trace_steps = plan_road_trip(distance_miles=300, fuel_mpg=25)\n",
    "for step in trace_steps:\n",
    "    print(step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce8a20",
   "metadata": {},
   "source": [
    "### **1.3. When to use agents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ee581",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_01_03.jpg?v=1768770273\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use agents when models must choose tools autonomously\n",
    ">* Skip agents for simple, single-step Llama tasks\n",
    "\n",
    ">* Use agents for branching, exploratory, data-gathering tasks\n",
    ">* Agent iteratively chooses tools and stops when confident\n",
    "\n",
    ">* Use simple workflows for fixed, predictable tasks\n",
    ">* Use agents when autonomy and adaptability add value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d824a4fa",
   "metadata": {},
   "source": [
    "## **2. Configuring Llama Agents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09634167",
   "metadata": {},
   "source": [
    "### **2.1. Choosing Agent Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a9fbd",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_02_01.jpg?v=1768770296\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Chosen tools define what the agent can do\n",
    ">* Start from tasks and pick minimal, purposeful tools\n",
    "\n",
    ">* Choose between coarse and fine-grained tools\n",
    ">* Balance simplicity, flexibility, cost, and reliability\n",
    "\n",
    ">* Prioritize safe, reliable, clearly described agent tools\n",
    ">* Use structure, sandboxes, and humans for risky actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881204a",
   "metadata": {},
   "source": [
    "### **2.2. Adding conversational memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dada5",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_02_02.jpg?v=1768770318\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Conversational memory lets agents keep ongoing context\n",
    ">* Decide what to store, retain, and summarize\n",
    "\n",
    ">* Memory component retrieves, compresses, and injects context\n",
    ">* Keeps user constraints for coherent, personalized multi-step tasks\n",
    "\n",
    ">* Store only relevant, necessary conversation details\n",
    ">* Segment, summarize, and control memory for safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Adding conversational memory\n",
    "\n",
    "# Demonstrate simple conversational memory with a tiny mock Llama agent.\n",
    "# Show difference between no memory and basic summary style memory.\n",
    "# Keep everything beginner friendly and runnable inside Google Colab.\n",
    "# pip install langchain llama-cpp-python sentence-transformers transformers.\n",
    "\n",
    "# Import required standard library modules for simple data handling.\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Define a simple class representing conversational memory storage.\n",
    "class SimpleMemory:\n",
    "\n",
    "    # Initialize memory with empty conversation history and user facts.\n",
    "    def __init__(self) -> None:\n",
    "        self.turn_history: List[Dict[str, str]] = []\n",
    "        self.user_facts: Dict[str, str] = {}\n",
    "\n",
    "    # Store a new conversation turn with role and content text.\n",
    "    def add_turn(self, role: str, content: str) -> None:\n",
    "        self.turn_history.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    # Update long term user facts based on simple keyword rules.\n",
    "    def update_facts(self, user_message: str) -> None:\n",
    "        lower = user_message.lower()\n",
    "        if \"morning\" in lower:\n",
    "            self.user_facts[\"preferred_time\"] = \"morning classes preferred\"\n",
    "        if \"part-time\" in lower:\n",
    "            self.user_facts[\"work_status\"] = \"works part-time during semester\"\n",
    "        if \"statistics\" in lower:\n",
    "            self.user_facts[\"weak_subject\"] = \"needs extra help with statistics\"\n",
    "\n",
    "    # Build a short memory summary string for the model context.\n",
    "    def build_summary(self) -> str:\n",
    "        facts_parts = [f\"- {k}: {v}\" for k, v in self.user_facts.items()]\n",
    "        if not facts_parts:\n",
    "            return \"No stable user preferences remembered yet.\"\n",
    "        joined = \"\\n\".join(facts_parts)\n",
    "        return f\"Known user preferences and constraints so far:\\n{joined}\"\n",
    "\n",
    "\n",
    "# Define a tiny mock Llama model that uses context strings.\n",
    "class MockLlamaModel:\n",
    "\n",
    "    # Initialize model with a simple name for identification.\n",
    "    def __init__(self, name: str = \"MockLlama\") -> None:\n",
    "        self.name = name\n",
    "\n",
    "    # Generate a reply using current message and memory summary.\n",
    "    def generate(self, message: str, memory_summary: str) -> str:\n",
    "        if \"schedule\" in message.lower():\n",
    "            return \"I will design a schedule using remembered preferences and constraints.\"\n",
    "        if \"remind\" in message.lower():\n",
    "            return f\"Here are preferences I remember now:\\n{memory_summary}\"\n",
    "        return \"I noted your message and updated my remembered preferences.\"\n",
    "\n",
    "\n",
    "# Define an agent that connects user messages, memory, and mock model.\n",
    "class LlamaAgentWithMemory:\n",
    "\n",
    "    # Initialize agent with memory component and mock model instance.\n",
    "    def __init__(self) -> None:\n",
    "        self.memory = SimpleMemory()\n",
    "        self.model = MockLlamaModel()\n",
    "\n",
    "    # Handle a user message, updating memory and generating response.\n",
    "    def handle_message(self, user_message: str) -> str:\n",
    "        self.memory.add_turn(\"user\", user_message)\n",
    "        self.memory.update_facts(user_message)\n",
    "        summary = self.memory.build_summary()\n",
    "        reply = self.model.generate(user_message, summary)\n",
    "        self.memory.add_turn(\"assistant\", reply)\n",
    "        return reply\n",
    "\n",
    "\n",
    "# Demonstrate conversation without memory by ignoring previous messages.\n",
    "def conversation_without_memory(messages: List[str]) -> None:\n",
    "    model = MockLlamaModel()\n",
    "    for msg in messages:\n",
    "        reply = model.generate(msg, memory_summary=\"No previous context used here.\")\n",
    "        print(f\"User: {msg}\")\n",
    "        print(f\"Agent: {reply}\")\n",
    "\n",
    "\n",
    "# Demonstrate conversation with memory using the LlamaAgentWithMemory.\n",
    "def conversation_with_memory(messages: List[str]) -> None:\n",
    "    agent = LlamaAgentWithMemory()\n",
    "    for msg in messages:\n",
    "        reply = agent.handle_message(msg)\n",
    "        print(f\"User: {msg}\")\n",
    "        print(f\"Agent: {reply}\")\n",
    "\n",
    "\n",
    "# Prepare a short scenario about planning a semester schedule.\n",
    "messages_sequence = [\n",
    "    \"I work part-time and prefer morning classes if possible.\",\n",
    "    \"I usually struggle with statistics and heavy math courses.\",\n",
    "    \"Can you suggest a weekly schedule for my semester now?\",\n",
    "    \"Please remind me what preferences you are using today.\",\n",
    "]\n",
    "\n",
    "# Run both conversations and clearly separate their printed outputs.\n",
    "print(\"--- Conversation without conversational memory enabled ---\")\n",
    "conversation_without_memory(messages_sequence)\n",
    "print(\"--- Conversation with conversational memory enabled ---\")\n",
    "conversation_with_memory(messages_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f483f9",
   "metadata": {},
   "source": [
    "### **2.3. Effective Agent Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a903471",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_02_03.jpg?v=1768770353\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Define clear role, goal, and behavior instructions\n",
    ">* Require tool use for facts, forbid making up data\n",
    "\n",
    ">* Tell the agent when and how to use tools\n",
    ">* Guide memory use to connect steps into plans\n",
    "\n",
    ">* Prompt agents to show structured, checkable reasoning steps\n",
    ">* Use reflective prompts to improve traces and robustness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Effective Agent Prompting\n",
    "\n",
    "# Demonstrate effective agent prompting using simple rule based reasoning simulation.\n",
    "# Show how role, goals, and steps change reasoning behavior clearly.\n",
    "# Compare vague prompt versus structured prompt for a planning style assistant.\n",
    "\n",
    "# pip install langchain llama3 hypothetical packages if actually using them.\n",
    "\n",
    "# Define a function simulating an agent following vague instructions.\n",
    "def vague_agent_response(user_request, tools_available, memory_notes):\n",
    "    # Build a loose style response ignoring tools and memory mostly.\n",
    "    response = \"I will try something quickly without checking details carefully. \"\n",
    "    response += f\"Request: {user_request}. \"\n",
    "    response += \"I guess things based on general knowledge and imagination. \"\n",
    "    response += \"I might forget earlier constraints or user preferences.\"\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define a function simulating an agent following structured instructions.\n",
    "def structured_agent_response(user_request, tools_available, memory_notes):\n",
    "    # Start with explicit role and goal description.\n",
    "    role = \"You are a careful academic planning assistant.\"\n",
    "    goal = \"Your goal is building a feasible weekly study plan.\"\n",
    "    # Describe explicit tool usage expectations clearly.\n",
    "    tool_instruction = \"Use tools whenever information seems missing or uncertain.\"\n",
    "    # Describe memory usage expectations clearly and explicitly.\n",
    "    memory_instruction = \"Always restate important preferences from memory before deciding.\"\n",
    "    # Simulate tool usage by referencing provided tool names.\n",
    "    used_tools = f\"Tools consulted: {', '.join(tools_available)}.\"\n",
    "    # Simulate memory recall by summarizing memory notes briefly.\n",
    "    memory_summary = f\"Key remembered preferences: {memory_notes}.\"\n",
    "    # Simulate stepwise reasoning with clear ordered steps.\n",
    "    steps = [\n",
    "        \"Step 1: Restate user goal and constraints clearly.\",\n",
    "        \"Step 2: Call schedule_lookup tool for available time slots.\",\n",
    "        \"Step 3: Call prerequisite_checker tool for course requirements.\",\n",
    "        \"Step 4: Combine tool results with remembered preferences.\",\n",
    "        \"Step 5: Propose schedule and verify no conflicts remain.\"\n",
    "    ]\n",
    "    # Join everything into one coherent explanation string.\n",
    "    response_parts = [role, goal, tool_instruction, memory_instruction, used_tools, memory_summary]\n",
    "    response_parts.extend(steps)\n",
    "    response = \" \\n\".join(response_parts)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define a simple scenario representing a multi step planning request.\n",
    "user_request = \"Plan a weekly study schedule for physics and history courses.\"\n",
    "# Define available tools names representing external information sources.\n",
    "tools_available = [\"schedule_lookup\", \"prerequisite_checker\"]\n",
    "# Define conversational memory notes representing user preferences.\n",
    "memory_notes = \"Prefers evenings, avoids weekends, needs two hours daily minimum.\"\n",
    "\n",
    "# Generate responses from both vague and structured simulated agents.\n",
    "vague_output = vague_agent_response(user_request, tools_available, memory_notes)\n",
    "structured_output = structured_agent_response(user_request, tools_available, memory_notes)\n",
    "\n",
    "# Print both outputs to compare prompting effects clearly and concisely.\n",
    "print(\"VAGUE PROMPT STYLE OUTPUT:\\n\")\n",
    "print(vague_output)\n",
    "print(\"\\nSTRUCTURED PROMPT STYLE OUTPUT:\\n\")\n",
    "print(structured_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01327928",
   "metadata": {},
   "source": [
    "## **3. Debugging Llama Agents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0b0b4",
   "metadata": {},
   "source": [
    "### **3.1. Tracing Agent Reasoning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cc088",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_03_01.jpg?v=1768770394\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tracing reveals each step of agent reasoning\n",
    ">* Chronological events explain what the agent did\n",
    "\n",
    ">* Check intent, tool choice, and parameters carefully\n",
    ">* Compare tool outputs to responses to spot divergences\n",
    "\n",
    ">* Link recurring trace patterns to design changes\n",
    ">* Use traces as diagnostics to refine agents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tracing Agent Reasoning\n",
    "\n",
    "# Demonstrate simple agent reasoning trace with printed steps.\n",
    "# Show how an agent chooses tools and explains decisions.\n",
    "# Help beginners connect traces with debugging agent behavior.\n",
    "\n",
    "# pip install langchain-openai langchain-community.\n",
    "# pip install langchain-core langchain-text-splitters.\n",
    "\n",
    "# Import required standard modules for this simple trace simulation.\n",
    "import random\n",
    "\n",
    "# Define a simple user request representing a customer support question.\n",
    "user_request = \"Where is my package and when will it arrive?\"\n",
    "\n",
    "# Define two simple tools with names and short descriptions.\n",
    "tools = [\n",
    "    {\"name\": \"order_lookup\", \"description\": \"Find order status using order id.\"},\n",
    "    {\"name\": \"faq_search\", \"description\": \"Search common shipping questions database.\"},\n",
    "]\n",
    "\n",
    "# Define a function that simulates an agent reasoning trace.\n",
    "def run_agent_with_trace(request_text):\n",
    "    trace_events = []\n",
    "    trace_events.append({\"event\": \"user_message\", \"content\": request_text})\n",
    "    intent = \"track_package_and_eta\"\n",
    "    trace_events.append({\"event\": \"model_plan\", \"content\": f\"Identify intent as {intent}.\"})\n",
    "\n",
    "    chosen_tool = tools[0]\n",
    "    tool_input = {\"order_id\": \"12345\"}\n",
    "    trace_events.append({\"event\": \"tool_call\", \"content\": f\"Call {chosen_tool['name']} with {tool_input}.\"})\n",
    "\n",
    "    tool_output = {\"status\": \"In transit\", \"eta_days\": 3}\n",
    "    trace_events.append({\"event\": \"tool_result\", \"content\": str(tool_output)})\n",
    "\n",
    "    final_answer = \"Your package is in transit and should arrive within three days.\" \n",
    "    trace_events.append({\"event\": \"final_answer\", \"content\": final_answer})\n",
    "    return trace_events\n",
    "\n",
    "# Run the simulated agent and capture the reasoning trace.\n",
    "trace = run_agent_with_trace(user_request)\n",
    "\n",
    "# Print the trace in chronological order with clear labels.\n",
    "print(\"AGENT REASONING TRACE:\\n\")\n",
    "for step_number, event in enumerate(trace, start=1):\n",
    "    print(f\"Step {step_number}: {event['event']} -> {event['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddf495",
   "metadata": {},
   "source": [
    "### **3.2. Common Agent Failures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffd39a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_03_02.jpg?v=1768770434\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Agents often misuse tools or loop without progress\n",
    ">* Fix by clarifying tool descriptions and usage rules\n",
    "\n",
    ">* Reasoning can seem correct but hide subtle errors\n",
    ">* These errors mislead actions and require instruction tweaks\n",
    "\n",
    ">* Agents often mishandle memory and long-term context\n",
    ">* Spot anomalies in traces to tune memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81f077",
   "metadata": {},
   "source": [
    "### **3.3. Iterative refinement cycles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78622707",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_05/Lecture_A/image_03_03.jpg?v=1768770453\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Start from a specific failure in traces\n",
    ">* Change one configuration element per refinement cycle\n",
    "\n",
    ">* Re-test the agent on similar scenarios\n",
    ">* Compare traces, watch tradeoffs, plan next tweaks\n",
    "\n",
    ">* Iterative feedback cycles create reliable, predictable agents\n",
    ">* Use trace patterns to apply targeted refinements\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d648c",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Building Llama 3 Agents**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91897c8d",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe how LangChain agents orchestrate Llama 3 reasoning and tool use. \n",
    "- Configure a LangChain agent that uses Llama 3 with tools and memory to solve multi-step tasks. \n",
    "- Analyze agent traces to debug reasoning errors and refine prompts, tools, or configurations. \n",
    "\n",
    "<font color='yellow'>Congratulations on completing this course!</font>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
