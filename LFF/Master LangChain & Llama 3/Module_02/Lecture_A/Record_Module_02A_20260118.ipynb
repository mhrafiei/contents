{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e47078c",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Prompt Design Essentials**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253eed68",
   "metadata": {},
   "source": [
    ">Last update: 20260118.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe key principles of effective prompts for Llama 3. \n",
    "- Create LangChain prompt templates that parameterize instructions and context. \n",
    "- Specify output formats in prompts to make Llama 3 responses easier to parse and use downstream. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a57f7",
   "metadata": {},
   "source": [
    "## **1. Core Prompt Principles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7447d62",
   "metadata": {},
   "source": [
    "### **1.1. Writing Clear Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce4e859",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_01_01.jpg?v=1768763788\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* State the task, role, and detail level\n",
    ">* Define jargon and meanings, especially across fields\n",
    "\n",
    ">* State desired length, structure, and focus clearly\n",
    ">* Set boundaries so responses avoid irrelevant territory\n",
    "\n",
    ">* State if you want reasoning or just answers\n",
    ">* Explain how to handle uncertainty, gaps, conflicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba6816",
   "metadata": {},
   "source": [
    "### **1.2. Context Rich Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244234d7",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_01_02.jpg?v=1768763803\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Give the model detailed, relevant task context\n",
    ">* Explain goals, audience, constraints to avoid guesswork\n",
    "\n",
    ">* Give the model expert-level background and details\n",
    ">* Include domain, audience, constraints, and workflow specifics\n",
    "\n",
    ">* Share only focused, high-signal context details\n",
    ">* Prioritize goals, constraints, and key definitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd5b2d",
   "metadata": {},
   "source": [
    "### **1.3. Eliminating Prompt Ambiguity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac414b48",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_01_03.jpg?v=1768763819\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Models guess when prompts are vague or open\n",
    ">* Be explicit about task, audience, detail, boundaries\n",
    "\n",
    ">* Everyday words can be vague for models\n",
    ">* Replace fuzzy terms with concrete, specific instructions\n",
    "\n",
    ">* Specify the modelâ€™s role, focus, and priorities\n",
    ">* Clarify goals and constraints to avoid misinterpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679c154",
   "metadata": {},
   "source": [
    "## **2. LangChain Prompt Templates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a7ef7",
   "metadata": {},
   "source": [
    "### **2.1. PromptTemplate Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db75ac9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_02_01.jpg?v=1768763835\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use templates as reusable blueprints for prompts\n",
    ">* Separate fixed instructions from changing topic details\n",
    "\n",
    ">* Templates define content, behavior, tone, and structure\n",
    ">* They ensure consistent, complete, and reliable model responses\n",
    "\n",
    ">* Design templates by separating fixed and changing parts\n",
    ">* Reuse and refine patterns for efficient, consistent outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6993d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - PromptTemplate Basics\n",
    "\n",
    "# Demonstrate simple prompt template blueprint for consistent model style.\n",
    "# Show stable instruction parts and changing topic parts clearly.\n",
    "# Print example prompts that follow the same reusable structure.\n",
    "\n",
    "# pip install langchain langchain-community langchain-openai.\n",
    "\n",
    "# Define a stable template blueprint for explanations.\n",
    "prompt_template = (\n",
    "    \"You are a patient teacher explaining clearly. \"\n",
    "    \"Explain the following topic for beginners: {topic}. \"\n",
    "    \"Use simple language and one short paragraph.\"\n",
    ")\n",
    "\n",
    "# Define two different topics that will change inside the template.\n",
    "topics = [\"gravity in everyday life\", \"how refrigerators keep food cold\"]\n",
    "\n",
    "# Function builds a full prompt by inserting topic into template.\n",
    "def build_prompt(template, topic):\n",
    "    return template.format(topic=topic)\n",
    "\n",
    "# Loop through topics and show resulting prompts clearly.\n",
    "for topic in topics:\n",
    "    full_prompt = build_prompt(prompt_template, topic)\n",
    "    print(\"TEMPLATE BASED PROMPT:\\n\", full_prompt, \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009f35a",
   "metadata": {},
   "source": [
    "### **2.2. Dynamic Variables in Templates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499c6c3",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_02_02.jpg?v=1768763860\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use text patterns with fill-in-the-blank slots\n",
    ">* Reuse stable instructions while swapping changing details\n",
    "\n",
    ">* Keep intent and tone stable across prompts\n",
    ">* Swap in changing user data and context\n",
    "\n",
    ">* Use clear variable names to show meaning\n",
    ">* Combine labeled inputs to build rich, flexible prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Dynamic Variables in Templates\n",
    "\n",
    "# Demonstrate dynamic variables inside simple text templates.\n",
    "# Show how stable instructions combine with changing details.\n",
    "# Print filled templates for different customer support situations.\n",
    "# pip install langchain langchain-community langchain-openai.\n",
    "\n",
    "# Define a stable instruction template with changeable placeholders.\n",
    "template_text = (\n",
    "    \"You are a helpful support agent.\",\n",
    ")\n",
    "\n",
    "# Create a dictionary holding dynamic customer specific information.\n",
    "customer_case_one = {\n",
    "    \"customer_name\": \"Alex Johnson\",\n",
    "    \"device_type\": \"laptop\",\n",
    "    \"issue_description\": \"screen flickers after ten minutes\",\n",
    "}\n",
    "\n",
    "# Create another dictionary representing a different customer situation.\n",
    "customer_case_two = {\n",
    "    \"customer_name\": \"Maria Lopez\",\n",
    "    \"device_type\": \"smartphone\",\n",
    "    \"issue_description\": \"battery drains within two hours\",\n",
    "}\n",
    "\n",
    "# Define a function that builds a full prompt using dynamic variables.\n",
    "def build_prompt(customer_name, device_type, issue_description):\n",
    "    base_instruction = \"You are a calm, clear support agent.\"\n",
    "    situation_line = f\" Customer {customer_name} reports a problem.\"\n",
    "    device_line = f\" Their device is a {device_type} used daily.\"\n",
    "    issue_line = f\" The described issue is: {issue_description}.\"\n",
    "    return base_instruction + situation_line + device_line + issue_line\n",
    "\n",
    "# Build prompts for the first customer using dynamic values.\n",
    "prompt_one = build_prompt(\n",
    "    customer_case_one[\"customer_name\"],\n",
    "    customer_case_one[\"device_type\"],\n",
    "    customer_case_one[\"issue_description\"],\n",
    ")\n",
    "\n",
    "# Build prompts for the second customer using different values.\n",
    "prompt_two = build_prompt(\n",
    "    customer_case_two[\"customer_name\"],\n",
    "    customer_case_two[\"device_type\"],\n",
    "    customer_case_two[\"issue_description\"],\n",
    ")\n",
    "\n",
    "# Print both prompts to compare stable and changing parts.\n",
    "print(\"Prompt for first customer case:\\n\")\n",
    "print(prompt_one)\n",
    "\n",
    "# Print a separator line for readability between prompt outputs.\n",
    "print(\"\\n------------------------------\\n\")\n",
    "\n",
    "# Print the second prompt showing reused structure with new details.\n",
    "print(\"Prompt for second customer case:\\n\")\n",
    "print(prompt_two)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc0582",
   "metadata": {},
   "source": [
    "### **2.3. Reusable Prompt Patterns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7b0df",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_02_03.jpg?v=1768763884\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Create stable prompt roles reusable across tasks\n",
    ">* Patterns cut ad-hoc design and keep consistency\n",
    "\n",
    ">* Turn recurring tasks into flexible prompt templates\n",
    ">* Reuse patterns across domains to save time\n",
    "\n",
    ">* Shared pattern libraries standardize work across teams\n",
    ">* Reusable patterns enable testing, refinement, reliable integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ffd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Reusable Prompt Patterns\n",
    "\n",
    "# Demonstrate reusable prompt patterns using simple Python dictionaries and functions.\n",
    "# Show how one pattern handles different subjects with consistent structure.\n",
    "# Print example outputs to illustrate pattern reuse across multiple tasks.\n",
    "# pip install langchain llama-index transformers accelerate bitsandbytes.\n",
    "\n",
    "# Define a reusable explainer pattern with placeholders for subject and audience.\n",
    "explainer_pattern = {\n",
    "    \"role\": \"You are a patient helpful explainer.\",\n",
    "    \"task\": \"Explain the topic clearly using simple language.\",\n",
    "    \"audience\": \"Audience is {audience_description}.\",\n",
    "    \"topic\": \"Topic to explain is: {topic_name}.\",\n",
    "}\n",
    "\n",
    "# Define a reusable reviewer pattern with placeholders for criteria and item.\n",
    "reviewer_pattern = {\n",
    "    \"role\": \"You are a careful constructive reviewer.\",\n",
    "    \"task\": \"Review the item using the given criteria.\",\n",
    "    \"criteria\": \"Use these criteria: {criteria_list}.\",\n",
    "    \"item\": \"Item to review is: {item_description}.\",\n",
    "}\n",
    "\n",
    "# Define a function that fills a pattern dictionary with specific values.\n",
    "def fill_pattern(pattern_dict, replacements_dict):\n",
    "    filled_parts = []\n",
    "    for key, template_text in pattern_dict.items():\n",
    "        filled_text = template_text.format(**replacements_dict)\n",
    "        filled_parts.append(f\"{key.upper()}: {filled_text}\")\n",
    "    return \"\\n\".join(filled_parts)\n",
    "\n",
    "# Create specific explainer prompts for different topics using the same pattern.\n",
    "explainer_climate = fill_pattern(\n",
    "    explainer_pattern,\n",
    "    {\n",
    "        \"audience_description\": \"high school students with limited background\",\n",
    "        \"topic_name\": \"climate change and carbon emissions\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create another explainer prompt for a different topic and audience.\n",
    "explainer_finance = fill_pattern(\n",
    "    explainer_pattern,\n",
    "    {\n",
    "        \"audience_description\": \"working adults new to budgeting\",\n",
    "        \"topic_name\": \"basic personal budgeting over one month\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create a reviewer prompt for a marketing email using shared criteria.\n",
    "reviewer_email = fill_pattern(\n",
    "    reviewer_pattern,\n",
    "    {\n",
    "        \"criteria_list\": \"clarity, persuasiveness, and respectful tone\",\n",
    "        \"item_description\": \"draft marketing email about a weekend sale\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the filled prompts to show consistent reusable structures.\n",
    "print(\"EXPLAINER PATTERN FOR CLIMATE TOPIC:\\n\")\n",
    "print(explainer_climate)\n",
    "print(\"\\nEXPLAINER PATTERN FOR FINANCE TOPIC:\\n\")\n",
    "print(explainer_finance)\n",
    "print(\"\\nREVIEWER PATTERN FOR MARKETING EMAIL:\\n\")\n",
    "print(reviewer_email)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348ec6d",
   "metadata": {},
   "source": [
    "## **3. Controlling Output Format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bb595",
   "metadata": {},
   "source": [
    "### **3.1. Structured Bullet Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98081088",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_03_01.jpg?v=1768763921\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Ask for structured bullets to organize information\n",
    ">* Bullets aid comparison and downstream tool integration\n",
    "\n",
    ">* Define a consistent structure for every bullet\n",
    ">* Structured bullets simplify parsing, comparison, and reuse\n",
    "\n",
    ">* Bullets connect messy text to structured workflows\n",
    ">* Consistent bullet patterns enable easy comparison and reuse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cceb2",
   "metadata": {},
   "source": [
    "### **3.2. Structured JSON Like Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc9663",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_03_02.jpg?v=1768763937\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Ask for specific, named fields in outputs\n",
    ">* Structured fields make automation and parsing much easier\n",
    "\n",
    ">* Design outputs like structured data records\n",
    ">* Predefined fields make results predictable and machine-friendly\n",
    "\n",
    ">* Define field content, data types, and labels\n",
    ">* Clear structure enables automated, reliable downstream processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Structured JSON Like Outputs\n",
    "\n",
    "# Demonstrate requesting structured JSON like outputs from a language model simulation.\n",
    "# Show how predictable fields simplify downstream automated processing workflows.\n",
    "# Parse and use the structured response inside a simple Python data pipeline.\n",
    "\n",
    "# pip install langchain-openai llama-cpp-python or other external libraries if needed.\n",
    "\n",
    "# Import json module for handling structured JSON like strings.\n",
    "import json\n",
    "\n",
    "# Define a fake model response string shaped like JSON data record.\n",
    "fake_model_response = '{\"title\": \"Leaky faucet issue\", \"urgency\": \"high\", \"category\": \"plumbing\", \"confidence\": 0.92}'\n",
    "\n",
    "# Print raw response to show predictable field based structure clearly.\n",
    "print(\"Raw model response string:\")\n",
    "print(fake_model_response)\n",
    "\n",
    "# Parse JSON string into Python dictionary for easier downstream processing.\n",
    "parsed = json.loads(fake_model_response)\n",
    "\n",
    "# Access individual fields for routing or dashboard style usage.\n",
    "issue_title = parsed[\"title\"]\n",
    "urgency_level = parsed[\"urgency\"]\n",
    "category_label = parsed[\"category\"]\n",
    "confidence_score = parsed[\"confidence\"]\n",
    "\n",
    "# Print selected fields to demonstrate reliable machine friendly access.\n",
    "print(\"\\nParsed fields for workflow:\")\n",
    "print(\"Title:\", issue_title)\n",
    "print(\"Urgency:\", urgency_level)\n",
    "print(\"Category:\", category_label)\n",
    "print(\"Confidence:\", confidence_score)\n",
    "\n",
    "# Use structured fields to decide simple automated routing action branch.\n",
    "if urgency_level == \"high\" and confidence_score > 0.8:\n",
    "    action = \"Send technician within twenty four hours.\"\n",
    "else:\n",
    "    action = \"Schedule standard visit within three business days.\"\n",
    "\n",
    "# Print final action showing benefit of consistent structured JSON like outputs.\n",
    "print(\"\\nRecommended action:\", action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd66592",
   "metadata": {},
   "source": [
    "### **3.3. Shaping Style And Tone**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe4814",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_A/image_03_03.jpg?v=1768763965\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Control structure, style, and tone together\n",
    ">* Match language to audience, domain, and use\n",
    "\n",
    ">* Tie style and tone to specific audience\n",
    ">* State formality and detail to reduce ambiguity\n",
    "\n",
    ">* Keep style and tone consistent across outputs\n",
    ">* Consistency supports trust, branding, and easy reuse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdbc99",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Prompt Design Essentials**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e4b50",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe key principles of effective prompts for Llama 3. \n",
    "- Create LangChain prompt templates that parameterize instructions and context. \n",
    "- Specify output formats in prompts to make Llama 3 responses easier to parse and use downstream. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Task Specific Prompts'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
