{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa8df8f",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Task Specific Prompts**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176da8a",
   "metadata": {},
   "source": [
    ">Last update: 20260118.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Design prompts optimized for summarization, classification, and Q&A with Llama 3. \n",
    "- Implement LangChain chains that encapsulate task-specific prompts and Llama 3 calls. \n",
    "- Evaluate and iterate on prompts based on qualitative and simple quantitative feedback. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf715e",
   "metadata": {},
   "source": [
    "## **1. Effective Summarization Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10230574",
   "metadata": {},
   "source": [
    "### **1.1. Controlling Summary Length**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bdc48d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_01_01.jpg?v=1768764756\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Specify clear target length for summaries\n",
    ">* Concrete length helps balance brevity and detail\n",
    "\n",
    ">* Match summary length to purpose and detail\n",
    ">* Explain use case so model prioritizes information\n",
    "\n",
    ">* Adjust summary length iteratively based on outputs\n",
    ">* Tailor length instructions to different audience needs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a396f22",
   "metadata": {},
   "source": [
    "### **1.2. Key Point Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cbdff5",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_01_02.jpg?v=1768764776\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Ask for core ideas, not short summaries\n",
    ">* Guide model to decisions, changes, key outcomes\n",
    "\n",
    ">* Importance depends on reader role and goal\n",
    ">* Role-based instructions yield targeted, useful key points\n",
    "\n",
    ">* Aim for mid-level, actionable key point detail\n",
    ">* Balanced granularity supports decisions and quick understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3f95f",
   "metadata": {},
   "source": [
    "### **1.3. Robust Summaries From Noise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a1091",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_01_03.jpg?v=1768764791\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tell the model what matters and not\n",
    ">* Have it ignore chatter, duplicates, and formatting\n",
    "\n",
    ">* Flag contradictions, uncertainty, and missing information clearly\n",
    ">* Report multiple views, separating facts from opinions\n",
    "\n",
    ">* Tell the model which noisy parts to ignore\n",
    ">* Prioritize real content so summaries stay accurate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff383b",
   "metadata": {},
   "source": [
    "## **2. Robust Classification Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fe919",
   "metadata": {},
   "source": [
    "### **2.1. Defining Classification Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9bf382",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_02_01.jpg?v=1768764812\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Define few, clear, non-overlapping classification labels\n",
    ">* Base labels on observable text, not intent\n",
    "\n",
    ">* Labels act as a contract driving actions\n",
    ">* Define labels precisely to ensure consistent classification\n",
    "\n",
    ">* Define labels for edge cases and ambiguity\n",
    ">* Consistent definitions stabilize outputs and downstream decisions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1868c6",
   "metadata": {},
   "source": [
    "### **2.2. Designing Few Shot Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4d1ab",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_02_02.jpg?v=1768764827\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use few-shot examples to teach classification behavior\n",
    ">* Embed examples in chains to guide ambiguous inputs\n",
    "\n",
    ">* Pick clear, realistic, diverse examples per label\n",
    ">* Embedded examples act like a portable training set\n",
    "\n",
    ">* Continuously update examples based on misclassifications\n",
    ">* Iterative refinement makes the chain robust, aligned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90767ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Designing Few Shot Labels\n",
    "\n",
    "# Demonstrate few shot labels for simple message classification chain.\n",
    "# Show how examples guide model style and label predictions.\n",
    "# Use a tiny rule based mock model instead of real Llama three.\n",
    "# pip install langchain-openai langchain-community.\n",
    "\n",
    "# Define few shot examples for customer support classification labels.\n",
    "few_shot_examples = [\n",
    "    {\"message\": \"My bill this month is higher than expected.\", \"label\": \"billing\"},\n",
    "    {\"message\": \"Why was my credit card charged twice yesterday night?\", \"label\": \"billing\"},\n",
    "    {\"message\": \"The app crashes whenever I try uploading photos.\", \"label\": \"technical_issue\"},\n",
    "    {\"message\": \"Videos keep buffering on my home WiFi connection.\", \"label\": \"technical_issue\"},\n",
    "    {\"message\": \"I cannot log into my account from my laptop.\", \"label\": \"account_access\"},\n",
    "]\n",
    "\n",
    "# Define a simple rule based classifier using few shot patterns.\n",
    "def classify_message(message, examples):\n",
    "    message_lower = message.lower()\n",
    "    billing_keywords = [\"bill\", \"charged\", \"invoice\", \"payment\"]\n",
    "    technical_keywords = [\"crash\", \"error\", \"bug\", \"buffer\", \"wifi\"]\n",
    "    access_keywords = [\"login\", \"log in\", \"password\", \"account\"]\n",
    "\n",
    "    # Check billing related keywords using simple containment checks.\n",
    "    if any(word in message_lower for word in billing_keywords):\n",
    "        return \"billing\"\n",
    "\n",
    "    # Check technical issue related keywords using simple containment checks.\n",
    "    if any(word in message_lower for word in technical_keywords):\n",
    "        return \"technical_issue\"\n",
    "\n",
    "    # Check account access related keywords using simple containment checks.\n",
    "    if any(word in message_lower for word in access_keywords):\n",
    "        return \"account_access\"\n",
    "\n",
    "    # Fall back to most common label from few shot examples.\n",
    "    labels = [example[\"label\"] for example in examples]\n",
    "    most_common_label = max(set(labels), key=labels.count)\n",
    "    return most_common_label\n",
    "\n",
    "# Show how different few shot sets change classification behavior.\n",
    "def run_demo():\n",
    "    test_message = \"Why did my payment fail when I used my new card?\"\n",
    "    original_label = classify_message(test_message, few_shot_examples)\n",
    "\n",
    "    # Print original classification result using initial few shot examples.\n",
    "    print(\"Original label with initial few shots:\", original_label)\n",
    "\n",
    "    # Add new sarcastic style example labeled as billing category.\n",
    "    updated_examples = few_shot_examples + [\n",
    "        {\"message\": \"Love being charged twice for nothing, thanks a lot.\", \"label\": \"billing\"}\n",
    "    ]\n",
    "\n",
    "    # Classify same message again using updated few shot examples.\n",
    "    updated_label = classify_message(test_message, updated_examples)\n",
    "    print(\"Updated label with sarcasm example:\", updated_label)\n",
    "\n",
    "    # Show both example sets sizes to emphasize maintainability concept.\n",
    "    print(\"Initial examples count:\", len(few_shot_examples))\n",
    "    print(\"Updated examples count:\", len(updated_examples))\n",
    "\n",
    "run_demo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed1329",
   "metadata": {},
   "source": [
    "### **2.3. Handling uncertain cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35fafa",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_02_03.jpg?v=1768764862\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Ambiguous inputs canâ€™t always match existing labels\n",
    ">* Define and encode clear behavior for model uncertainty\n",
    "\n",
    ">* Add special labels for uncertain or unusual inputs\n",
    ">* Route uncertain cases to humans or extra processing\n",
    "\n",
    ">* Use model explanations to detect low confidence\n",
    ">* Route doubtful cases to humans and refine rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Handling uncertain cases\n",
    "\n",
    "# Demonstrate handling uncertain classifications using simple rule based logic.\n",
    "# Show how a special uncertain label can route inputs for human review.\n",
    "# Simulate model explanations and detect low confidence using keyword based checks.\n",
    "\n",
    "# pip install langchain-openai langchain-community.\n",
    "\n",
    "# Define possible classification labels including uncertain fallback.\n",
    "labels = [\"billing\", \"technical\", \"general\", \"needs_human_review\"]\n",
    "\n",
    "# Define example customer messages with simulated model explanations.\n",
    "examples = [\n",
    "    {\n",
    "        \"message\": \"My internet is down since yesterday evening.\",\n",
    "        \"label\": \"technical\",\n",
    "        \"explanation\": \"Clearly a technical connectivity issue with internet service.\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"I think I was double charged but not totally sure.\",\n",
    "        \"label\": \"billing\",\n",
    "        \"explanation\": \"Possibly billing related but information seems incomplete and uncertain.\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"Your service is kind of weird, maybe broken or maybe just slow.\",\n",
    "        \"label\": \"technical\",\n",
    "        \"explanation\": \"Description is vague, could be normal slowness or actual outage, not clear.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define keywords that suggest low confidence or missing information.\n",
    "uncertain_keywords = [\"uncertain\", \"not clear\", \"possibly\", \"incomplete\", \"vague\"]\n",
    "\n",
    "# Define function that upgrades label to human review when explanation seems uncertain.\n",
    "def route_with_uncertainty(original_label, explanation):\n",
    "    lowered = explanation.lower()\n",
    "    for word in uncertain_keywords:\n",
    "        if word in lowered:\n",
    "            return \"needs_human_review\"\n",
    "    return original_label\n",
    "\n",
    "# Process each example and print routing decisions with explanations.\n",
    "for item in examples:\n",
    "    final_label = route_with_uncertainty(item[\"label\"], item[\"explanation\"])\n",
    "    print(\"Message:\", item[\"message\"])\n",
    "    print(\"Model label:\", item[\"label\"], \"| Final route:\", final_label)\n",
    "    print(\"Explanation:\", item[\"explanation\"])\n",
    "    print(\"-\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715b73e",
   "metadata": {},
   "source": [
    "## **3. Effective QA Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c00b5d",
   "metadata": {},
   "source": [
    "### **3.1. Clarifying User Questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dce0e1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_03_01.jpg?v=1768764887\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Clarify vague or ambiguous questions before answering\n",
    ">* Evaluate if the model requests missing details\n",
    "\n",
    ">* Use qualitative reviews to spot ambiguity failures\n",
    ">* Track simple metrics and refine clarification instructions\n",
    "\n",
    ">* Balance when to infer versus clarify questions\n",
    ">* Use reviewer ratings to tune clarification behavior\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de48e75",
   "metadata": {},
   "source": [
    "### **3.2. Controlled Answer Formatting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebf8f0",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_03_02.jpg?v=1768764902\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Control answer structure, detail, and style explicitly\n",
    ">* Consistent formats simplify scanning, comparison, and evaluation\n",
    "\n",
    ">* Review sample answers for structure, clarity, tone\n",
    ">* Track simple metrics to measure consistency and improvement\n",
    "\n",
    ">* Adjust formatting rules based on real user feedback\n",
    ">* Iterate until answers are consistent and user-aligned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Controlled Answer Formatting\n",
    "\n",
    "# Demonstrate controlled answer formatting using simple template prompts.\n",
    "# Compare freeform answers versus structured formatted answers from a fake model.\n",
    "# Show how structure helps evaluation and consistency for question answering.\n",
    "# pip install langchain openai tiktoken if external libraries were actually required.\n",
    "\n",
    "# Define a simple fake model function that returns canned responses.\n",
    "def fake_model_response(prompt_text, style_label):\n",
    "    if style_label == \"freeform\":\n",
    "        return \"I think the best way is probably to add more insulation and maybe check windows. That usually helps keep houses warmer during winter and can lower bills.\"\n",
    "    if style_label == \"structured\":\n",
    "        return \"Direct answer: Add attic insulation and seal window drafts to reduce heat loss.\\nExplanation: Extra insulation slows heat escaping through the roof, and sealing window gaps reduces cold air leaks, which together lower heating costs.\"\n",
    "    return \"Unknown style requested, please check style label and try again.\"\n",
    "\n",
    "# Define a user question about reducing winter heating costs in a small house.\n",
    "user_question = \"How can I reduce my winter heating bill in a small house?\"\n",
    "\n",
    "# Build a freeform prompt without any formatting instructions for the fake model.\n",
    "freeform_prompt = f\"Question: {user_question} Answer in any style you like without constraints.\"\n",
    "\n",
    "# Build a controlled formatting prompt with explicit structure and style instructions.\n",
    "structured_prompt = (\n",
    "    \"You are a home energy assistant. \"\n",
    "    \"First give one short direct answer sentence labeled 'Direct answer:'. \"\n",
    "    \"Then give one short explanation sentence labeled 'Explanation:'. \"\n",
    "    f\"Question: {user_question}\"\n",
    ")\n",
    "\n",
    "# Get the freeform style answer from the fake model using the first prompt.\n",
    "freeform_answer = fake_model_response(freeform_prompt, \"freeform\")\n",
    "\n",
    "# Get the structured style answer from the fake model using the second prompt.\n",
    "structured_answer = fake_model_response(structured_prompt, \"structured\")\n",
    "\n",
    "# Print both prompts and answers to compare formatting and clarity side by side.\n",
    "print(\"FREEFORM PROMPT AND ANSWER:\\n\")\n",
    "print(freeform_prompt)\n",
    "print(\"\\nAnswer:\")\n",
    "print(freeform_answer)\n",
    "\n",
    "# Print a separator line to clearly distinguish the two different prompting approaches.\n",
    "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "# Print the structured prompt and answer showing controlled answer formatting.\n",
    "print(\"STRUCTURED PROMPT AND ANSWER:\\n\")\n",
    "print(structured_prompt)\n",
    "print(\"\\nAnswer:\")\n",
    "print(structured_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63052643",
   "metadata": {},
   "source": [
    "### **3.3. Grounded Context Citations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e4c81",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_02/Lecture_B/image_03_03.jpg?v=1768764933\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Answers must cite specific parts of sources\n",
    ">* Citations reduce hallucinations and enable easy verification\n",
    "\n",
    ">* Check if each citation truly supports claims\n",
    ">* Track simple metrics to spot citation problems\n",
    "\n",
    ">* Refine instructions so citations are specific, accurate\n",
    ">* Continuously review outputs, crucial in high-stakes domains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb48740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Grounded Context Citations\n",
    "\n",
    "# Demonstrate grounded context citations using simple question answering example.\n",
    "# Show how answers reference specific supporting context snippets clearly.\n",
    "# Evaluate citation quality using simple correctness checks and printed feedback.\n",
    "# pip install langchain llama-cpp-python sentence-transformers transformers.\n",
    "\n",
    "# Define a small context knowledge base with labeled snippets.\n",
    "context_snippets = {\n",
    "    \"A\": \"Warranty covers manufacturing defects for one year from purchase date in most states.\",\n",
    "    \"B\": \"Warranty does not cover damage from misuse, accidents, or unauthorized repairs by users.\",\n",
    "    \"C\": \"Customers must provide original receipt and product serial number for warranty service eligibility.\",\n",
    "}\n",
    "\n",
    "# Define a user question about warranty coverage details and limitations.\n",
    "question = \"Does the warranty cover accidental damage and what proof is required?\"\n",
    "\n",
    "# Define a simple model answer that includes grounded citation labels.\n",
    "model_answer = (\n",
    "    \"Accidental damage is not covered by the warranty [B]. \"\n",
    "    \"You must provide the original receipt and serial number as proof [C].\"\n",
    ")\n",
    "\n",
    "# Define expected supporting snippet labels for each important answer statement.\n",
    "expected_citations = {\n",
    "    \"accidental damage not covered\": \"B\",\n",
    "    \"proof required receipt serial\": \"C\",\n",
    "}\n",
    "\n",
    "# Evaluate whether each expected citation label appears correctly inside the answer.\n",
    "correct_citations = []\n",
    "for description, label in expected_citations.items():\n",
    "    is_present = f\"[{label}]\" in model_answer\n",
    "    correct_citations.append((description, label, is_present))\n",
    "\n",
    "# Print the question, answer, and evaluation of citation correctness.\n",
    "print(\"Question:\", question)\n",
    "print(\"\\nModel answer with citations:\")\n",
    "print(model_answer)\n",
    "print(\"\\nCitation evaluation results:\")\n",
    "for description, label, is_present in correct_citations:\n",
    "    status = \"OK\" if is_present else \"MISSING\"\n",
    "    print(f\"Claim '{description}' should cite [{label}]: {status}\")\n",
    "\n",
    "# Print one cited context snippet to show how users can verify grounding.\n",
    "label_to_show = \"B\"\n",
    "print(\"\\nCited context for label B:\")\n",
    "print(f\"[{label_to_show}] {context_snippets[label_to_show]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca3aec",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Task Specific Prompts**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3651f",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Design prompts optimized for summarization, classification, and Q&A with Llama 3. \n",
    "- Implement LangChain chains that encapsulate task-specific prompts and Llama 3 calls. \n",
    "- Evaluate and iterate on prompts based on qualitative and simple quantitative feedback. \n",
    "\n",
    "In the next Module (Module 3), we will go over 'Chains And Memory'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
