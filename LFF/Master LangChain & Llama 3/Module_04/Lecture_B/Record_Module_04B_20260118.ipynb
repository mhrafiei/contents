{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7064b20b",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Tool Calling Basics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1585280",
   "metadata": {},
   "source": [
    ">Last update: 20260118.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Explain how LangChain exposes tools for Llama 3 to call during reasoning. \n",
    "- Define and register simple tools in LangChain and connect them to a Llama 3 model. \n",
    "- Test and debug tool-using interactions to ensure correct tool selection and safe outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4151b8d",
   "metadata": {},
   "source": [
    "## **1. Core Tool Use Concepts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f07c78",
   "metadata": {},
   "source": [
    "### **1.1. When Llama 3 needs tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2064c",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_01_01.jpg?v=1768769323\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Model handles text reasoning using learned knowledge\n",
    ">* Needs tools for live data and exact operations\n",
    "\n",
    ">* Model decides on tools during stepwise reasoning\n",
    ">* Uses tools for fresh data and specialized tasks\n",
    "\n",
    ">* Complex planning questions often trigger helpful tool use\n",
    ">* Model leads reasoning while tools handle precise operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82569d6",
   "metadata": {},
   "source": [
    "### **1.2. Tool Call Schema Essentials**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800820ac",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_01_02.jpg?v=1768769340\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Schemas describe each toolâ€™s purpose and inputs\n",
    ">* Clear schemas let Llama 3 choose tools reliably\n",
    "\n",
    ">* Schema defines tool purpose and input parameters\n",
    ">* Standardized schema lets Llama 3 call tools reliably\n",
    "\n",
    ">* Schemas guide multi-step tool choices and calls\n",
    ">* LangChain runs tools and returns results as context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f28f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tool Call Schema Essentials\n",
    "\n",
    "# Demonstrate simple tool schema as shared contract between model and tools.\n",
    "# Show how schema describes tool name, description, and input parameters.\n",
    "# Simulate model reading schema and building structured tool call arguments.\n",
    "\n",
    "# pip install langchain-openai langchain-community langchain.\n",
    "\n",
    "# Define a simple tool schema as a Python dictionary.\n",
    "weather_tool_schema = {\n",
    "    \"name\": \"get_weather_fahrenheit\",\n",
    "    \"description\": \"Get current weather in Fahrenheit for a given US city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the US city to check.\",\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Temperature unit, use Fahrenheit only.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"city\", \"unit\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Print the schema so we can see the shared contract.\n",
    "print(\"Tool schema contract:\")\n",
    "print({\"name\": weather_tool_schema[\"name\"], \"parameters\": weather_tool_schema[\"parameters\"][\"properties\"]})\n",
    "\n",
    "# Define a simple user request that needs weather information.\n",
    "user_request = \"What is the temperature in Boston right now in Fahrenheit?\"\n",
    "\n",
    "# Simulate model reasoning by matching request words with schema description.\n",
    "if \"Fahrenheit\" in user_request and \"temperature\" in user_request:\n",
    "    chosen_tool_name = weather_tool_schema[\"name\"]\n",
    "    tool_arguments = {\"city\": \"Boston\", \"unit\": \"Fahrenheit\"}\n",
    "else:\n",
    "    chosen_tool_name = None\n",
    "    tool_arguments = {}\n",
    "\n",
    "# Show the structured tool call that follows the schema exactly.\n",
    "print(\"\\nStructured tool call:\")\n",
    "print({\"tool\": chosen_tool_name, \"arguments\": tool_arguments})\n",
    "\n",
    "# Simulate tool execution using the structured arguments from the schema.\n",
    "def fake_get_weather_fahrenheit(city, unit):\n",
    "    return f\"Weather in {city} is 72 degrees {unit} right now.\"\n",
    "\n",
    "# Execute the fake tool only if a tool was chosen.\n",
    "if chosen_tool_name:\n",
    "    result = fake_get_weather_fahrenheit(**tool_arguments)\n",
    "else:\n",
    "    result = \"No matching tool was selected by the reasoning process.\"\n",
    "\n",
    "# Show final answer that the model could return to the user.\n",
    "print(\"\\nFinal answer using tool:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6a2aa",
   "metadata": {},
   "source": [
    "### **1.3. Safe Tool Usage**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796abfc8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_01_03.jpg?v=1768769384\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Each tool adds power but also risk\n",
    ">* Grant tools like you grant employee permissions\n",
    "\n",
    ">* Careful tool descriptions teach correct, safe usage\n",
    ">* Schemas and validation guard against risky tool calls\n",
    "\n",
    ">* Monitor and log tool calls to spot misuse\n",
    ">* Use feedback to refine tools, balancing safety\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3870602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Safe Tool Usage\n",
    "\n",
    "# Demonstrate safe tool usage concepts with simple Python functions and validation.\n",
    "# Show difference between safe read tools and risky write tools clearly.\n",
    "# Log and block unsafe requests before executing risky operations safely.\n",
    "# !pip install some_required_library_here if external libraries were actually needed.\n",
    "\n",
    "# Define a simple read only tool that is always safe.\n",
    "def safe_lookup(zip_code, miles_radius):\n",
    "    return f\"Searching public stores within {miles_radius} miles of ZIP {zip_code}.\"\n",
    "\n",
    "# Define a risky write tool that can place real orders.\n",
    "def risky_place_order(user_id, item_name, quantity):\n",
    "    return f\"ORDER PLACED for {quantity} {item_name} for user {user_id}.\"\n",
    "\n",
    "# Define a safety checker that validates risky tool arguments.\n",
    "def validate_order_request(user_authenticated, quantity):\n",
    "    if not user_authenticated:\n",
    "        return False, \"Blocked: user not authenticated for placing orders.\"\n",
    "    if quantity <= 0 or quantity > 5:\n",
    "        return False, \"Blocked: quantity must be between one and five units.\"\n",
    "    return True, \"Order request passed safety checks.\"\n",
    "\n",
    "# Simulate a model deciding which tool to call unsafely.\n",
    "def model_decision_simulation(user_message):\n",
    "    if \"buy\" in user_message.lower():\n",
    "        return \"risky_place_order\"\n",
    "    return \"safe_lookup\"\n",
    "\n",
    "# Simulate a safe orchestrator that wraps tool calls with checks.\n",
    "def safe_orchestrator(user_message, user_authenticated):\n",
    "    print(\"User message:\", user_message)\n",
    "    chosen_tool = model_decision_simulation(user_message)\n",
    "    print(\"Model chose tool:\", chosen_tool)\n",
    "    if chosen_tool == \"safe_lookup\":\n",
    "        result = safe_lookup(\"10001\", 10)\n",
    "        print(\"Tool result:\", result)\n",
    "        return\n",
    "    is_ok, reason = validate_order_request(user_authenticated, quantity=10)\n",
    "    print(\"Safety check:\", reason)\n",
    "    if not is_ok:\n",
    "        print(\"Final action: risky tool call blocked safely.\")\n",
    "        return\n",
    "    result = risky_place_order(\"user_123\", \"flashlight\", 10)\n",
    "    print(\"Tool result:\", result)\n",
    "\n",
    "# Run two scenarios showing unsafe model choice but safe wrapper behavior.\n",
    "print(\"Scenario one: unauthenticated user tries large purchase.\")\n",
    "safe_orchestrator(\"Please buy ten flashlights for me.\", user_authenticated=False)\n",
    "print(\"\\nScenario two: simple store lookup request.\")\n",
    "safe_orchestrator(\"Where can I buy a flashlight near me?\", user_authenticated=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8c0bb",
   "metadata": {},
   "source": [
    "## **2. Defining LangChain Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8a579",
   "metadata": {},
   "source": [
    "### **2.1. Python Function Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162b541",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_02_01.jpg?v=1768769418\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tools are just focused Python functions for tasks\n",
    ">* LangChain lets Llama 3 call these functions\n",
    "\n",
    ">* Design single-purpose functions with clear, structured inputs\n",
    ">* Model selects tools, functions hold domain logic\n",
    "\n",
    ">* Give tools clear names and concise descriptions\n",
    ">* Good documentation improves tool choice and reasoning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Python Function Tools\n",
    "\n",
    "# Demonstrate simple Python function tools for LangChain style usage.\n",
    "# Show clear inputs and outputs for predictable tool behavior.\n",
    "# Print example tool calls and their structured results.\n",
    "# pip install langchain-openai langchain-community langchain.\n",
    "\n",
    "# Define a simple temperature conversion tool function.\n",
    "def convert_fahrenheit_to_celsius(fahrenheit_value: float) -> float:\n",
    "    \"\"\"Convert Fahrenheit temperature to Celsius temperature value.\"\"\"\n",
    "    celsius_value = (fahrenheit_value - 32.0) * 5.0 / 9.0\n",
    "    return round(celsius_value, 2)\n",
    "\n",
    "# Define a simple loan payment estimation tool function.\n",
    "def estimate_monthly_payment(principal_dollars: float, annual_rate_percent: float, years_term: int) -> float:\n",
    "    \"\"\"Estimate fixed monthly payment for simple loan.\"\"\"\n",
    "    monthly_rate = annual_rate_percent / 100.0 / 12.0\n",
    "    months_total = years_term * 12\n",
    "    if monthly_rate == 0:\n",
    "        payment_value = principal_dollars / months_total\n",
    "    else:\n",
    "        factor_value = (1 + monthly_rate) ** months_total\n",
    "        payment_value = principal_dollars * monthly_rate * factor_value / (factor_value - 1)\n",
    "    return round(payment_value, 2)\n",
    "\n",
    "# Define a dispatcher that mimics a language model choosing tools.\n",
    "def call_tool(tool_name: str, **kwargs) -> dict:\n",
    "    \"\"\"Call selected tool function using keyword arguments.\"\"\"\n",
    "    if tool_name == \"convert_fahrenheit_to_celsius\":\n",
    "        result_value = convert_fahrenheit_to_celsius(kwargs[\"fahrenheit_value\"])\n",
    "    elif tool_name == \"estimate_monthly_payment\":\n",
    "        result_value = estimate_monthly_payment(\n",
    "            kwargs[\"principal_dollars\"], kwargs[\"annual_rate_percent\"], kwargs[\"years_term\"]\n",
    "        )\n",
    "    else:\n",
    "        result_value = \"Unknown tool requested by caller.\"\n",
    "    return {\"tool\": tool_name, \"inputs\": kwargs, \"result\": result_value}\n",
    "\n",
    "# Demonstrate calling the temperature conversion tool.\n",
    "weather_tool_call = call_tool(\"convert_fahrenheit_to_celsius\", fahrenheit_value=77.0)\n",
    "print(\"Weather tool call result:\", weather_tool_call)\n",
    "\n",
    "# Demonstrate calling the loan payment estimation tool.\n",
    "loan_tool_call = call_tool(\n",
    "    \"estimate_monthly_payment\", principal_dollars=20000.0, annual_rate_percent=5.0, years_term=5\n",
    ")\n",
    "print(\"Loan tool call result:\", loan_tool_call)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b680cd0",
   "metadata": {},
   "source": [
    "### **2.2. Tool Input Schemas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0eca8b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_02_02.jpg?v=1768769444\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tool input schemas clearly define expected arguments\n",
    ">* They reduce ambiguity and simplify debugging tool calls\n",
    "\n",
    ">* Schemas guide model choices and document tools\n",
    ">* They ensure complete, coherent, valid tool calls\n",
    "\n",
    ">* Schemas restrict inputs to safe, sensible values\n",
    ">* Framework validation catches errors and improves reliability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1faeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tool Input Schemas\n",
    "\n",
    "# Demonstrate simple tool input schemas using Python dictionaries and validation logic.\n",
    "# Show how required and optional fields can be checked before tool execution.\n",
    "# Print validation results to illustrate correct and incorrect tool calls.\n",
    "\n",
    "# pip install pydantic langchain-openai langchain-community langchain.\n",
    "\n",
    "# Define a simple weather tool input schema using a dictionary template.\n",
    "weather_schema = {\n",
    "    \"city\": {\"type\": \"string\", \"required\": True},\n",
    "    \"date\": {\"type\": \"string\", \"required\": False},\n",
    "}\n",
    "\n",
    "# Define a simple distance tool input schema using another dictionary template.\n",
    "distance_schema = {\n",
    "    \"from_city\": {\"type\": \"string\", \"required\": True},\n",
    "    \"to_city\": {\"type\": \"string\", \"required\": True},\n",
    "}\n",
    "\n",
    "# Define a function that validates arguments against a provided schema dictionary.\n",
    "def validate_inputs(schema, arguments):\n",
    "    errors = []\n",
    "    for field_name, field_rules in schema.items():\n",
    "        if field_rules[\"required\"] and field_name not in arguments:\n",
    "            errors.append(f\"Missing required field: {field_name}\")\n",
    "        if field_name in arguments and not isinstance(arguments[field_name], str):\n",
    "            errors.append(f\"Field {field_name} must be string type\")\n",
    "    for provided_name in arguments.keys():\n",
    "        if provided_name not in schema:\n",
    "            errors.append(f\"Unexpected field provided: {provided_name}\")\n",
    "    return errors\n",
    "\n",
    "# Define a function that simulates calling a weather tool after validation.\n",
    "def call_weather_tool(arguments):\n",
    "    errors = validate_inputs(weather_schema, arguments)\n",
    "    if errors:\n",
    "        print(\"Weather tool call invalid due to these issues:\")\n",
    "        for issue in errors:\n",
    "            print(\"-\", issue)\n",
    "    else:\n",
    "        city = arguments.get(\"city\")\n",
    "        date = arguments.get(\"date\", \"today\")\n",
    "        print(f\"Weather tool called successfully for {city} on {date}.\")\n",
    "\n",
    "# Define a function that simulates calling a distance tool after validation.\n",
    "def call_distance_tool(arguments):\n",
    "    errors = validate_inputs(distance_schema, arguments)\n",
    "    if errors:\n",
    "        print(\"Distance tool call invalid due to these issues:\")\n",
    "        for issue in errors:\n",
    "            print(\"-\", issue)\n",
    "    else:\n",
    "        start = arguments.get(\"from_city\")\n",
    "        end = arguments.get(\"to_city\")\n",
    "        print(f\"Distance tool called successfully from {start} to {end}.\")\n",
    "\n",
    "# Prepare a valid weather tool call with required and optional fields included.\n",
    "valid_weather_call = {\"city\": \"Chicago\", \"date\": \"2026-07-04\"}\n",
    "\n",
    "# Prepare an invalid weather tool call missing the required city field.\n",
    "invalid_weather_call = {\"date\": \"2026-07-04\"}\n",
    "\n",
    "# Prepare a valid distance tool call with both required cities provided.\n",
    "valid_distance_call = {\"from_city\": \"Boston\", \"to_city\": \"New York\"}\n",
    "\n",
    "# Prepare an invalid distance tool call with an unexpected extra argument.\n",
    "invalid_distance_call = {\"from_city\": \"Dallas\", \"to_city\": \"Houston\", \"miles\": 250}\n",
    "\n",
    "# Execute all tool calls and observe how schemas guide validation behavior.\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Valid weather call result:\")\n",
    "    call_weather_tool(valid_weather_call)\n",
    "    print(\"\\nInvalid weather call result:\")\n",
    "    call_weather_tool(invalid_weather_call)\n",
    "    print(\"\\nValid distance call result:\")\n",
    "    call_distance_tool(valid_distance_call)\n",
    "    print(\"\\nInvalid distance call result:\")\n",
    "    call_distance_tool(invalid_distance_call)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382b246",
   "metadata": {},
   "source": [
    "### **2.3. Registering Tools in Chains**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77680d33",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_02_03.jpg?v=1768769475\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Register tools in a chain for use\n",
    ">* Chain lets Llama 3 choose and sequence tools\n",
    "\n",
    ">* Shape system instructions to describe tools and constraints\n",
    ">* Clear guidance ensures safe, predictable tool use\n",
    "\n",
    ">* Chains coordinate multiple tools for complex workflows\n",
    ">* Unified interface scales as you add tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd226b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Registering Tools in Chains\n",
    "\n",
    "# Demonstrate registering simple tools inside a LangChain style conversation chain.\n",
    "# Show how a model chooses between registered tools during reasoning steps.\n",
    "# Print final answer plus which tools were selected and called.\n",
    "\n",
    "# pip install langchain langchain-openai langchain-community.\n",
    "# pip install python-dotenv.\n",
    "\n",
    "# Import required standard and external libraries.\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Define a simple fake language model that decides tool usage.\n",
    "@dataclass\n",
    "class FakeLlamaModel:\n",
    "    name: str\n",
    "\n",
    "# Define a simple tool interface holding name and callable function.\n",
    "@dataclass\n",
    "class SimpleTool:\n",
    "    name: str\n",
    "    description: str\n",
    "    func: Any\n",
    "\n",
    "# Define a chain that holds model, tools, and system instructions.\n",
    "@dataclass\n",
    "class ToolEnabledChain:\n",
    "    model: FakeLlamaModel\n",
    "    tools: List[SimpleTool]\n",
    "    system_instructions: str\n",
    "\n",
    "# Define a method that routes user questions to appropriate tools.\n",
    "    def run(self, user_message: str) -> Dict[str, Any]:\n",
    "        chosen_tools: List[str] = []\n",
    "        answer_parts: List[str] = []\n",
    "\n",
    "        if \"inventory\" in user_message.lower() or \"stock\" in user_message.lower():\n",
    "            inventory_tool = self._get_tool_by_name(\"inventory_lookup\")\n",
    "            if inventory_tool is not None:\n",
    "                chosen_tools.append(inventory_tool.name)\n",
    "                answer_parts.append(inventory_tool.func(\"flashlight\"))\n",
    "\n",
    "        if \"shipping\" in user_message.lower() or \"delivery\" in user_message.lower():\n",
    "            shipping_tool = self._get_tool_by_name(\"shipping_estimate\")\n",
    "            if shipping_tool is not None:\n",
    "                chosen_tools.append(shipping_tool.name)\n",
    "                answer_parts.append(shipping_tool.func(\"90210\"))\n",
    "\n",
    "        if not answer_parts:\n",
    "            answer_parts.append(\"I can answer without calling any registered tools.\")\n",
    "\n",
    "        final_answer = \" \".join(answer_parts)\n",
    "        return {\"answer\": final_answer, \"used_tools\": chosen_tools}\n",
    "\n",
    "# Helper method that finds a tool by its registered name.\n",
    "    def _get_tool_by_name(self, name: str) -> Any:\n",
    "        for tool in self.tools:\n",
    "            if tool.name == name:\n",
    "                return tool\n",
    "        return None\n",
    "\n",
    "# Define a simple inventory lookup tool function.\n",
    "def inventory_lookup_tool(item_name: str) -> str:\n",
    "    inventory_data = {\"flashlight\": 12, \"tent\": 5, \"compass\": 0}\n",
    "    quantity = inventory_data.get(item_name, 0)\n",
    "    if quantity > 0:\n",
    "        return f\"Inventory tool reports {quantity} units of {item_name} currently in stock.\"\n",
    "    return f\"Inventory tool reports {item_name} currently out of stock at all warehouses.\"\n",
    "\n",
    "# Define a simple shipping estimate tool function using miles distance.\n",
    "def shipping_estimate_tool(zip_code: str) -> str:\n",
    "    base_distance_miles = 1200\n",
    "    days = 3 if zip_code.startswith(\"9\") else 5\n",
    "    return f\"Shipping tool estimates delivery in {days} days over approximately {base_distance_miles} miles.\"\n",
    "\n",
    "# Create tool objects that wrap the Python functions and descriptions.\n",
    "inventory_tool = SimpleTool(\n",
    "    name=\"inventory_lookup\",\n",
    "    description=\"Check current warehouse inventory for a specific camping product.\",\n",
    "    func=inventory_lookup_tool,\n",
    ")\n",
    "\n",
    "# Create a second tool for shipping estimates and register description.\n",
    "shipping_tool = SimpleTool(\n",
    "    name=\"shipping_estimate\",\n",
    "    description=\"Estimate shipping time in days for a given United States zip code.\",\n",
    "    func=shipping_estimate_tool,\n",
    ")\n",
    "\n",
    "# Create a fake Llama model instance representing our reasoning engine.\n",
    "model = FakeLlamaModel(name=\"FakeLlama-Tool-Demo\")\n",
    "\n",
    "# Define system instructions that explain how tools should be used.\n",
    "system_message = (\n",
    "    \"You are a helpful store assistant. Use inventory_lookup for stock questions, \"\n",
    "    \"and shipping_estimate for delivery questions. Avoid tools for casual chit chat.\"\n",
    ")\n",
    "\n",
    "# Register tools and model together inside a single tool enabled chain.\n",
    "chain = ToolEnabledChain(model=model, tools=[inventory_tool, shipping_tool], system_instructions=system_message)\n",
    "\n",
    "# Define a user question that naturally requires both registered tools.\n",
    "user_question = \"Is the flashlight in stock and how long is shipping to zip 90210?\"\n",
    "\n",
    "# Run the chain, letting it decide which tools to call and in which order.\n",
    "result = chain.run(user_question)\n",
    "\n",
    "# Print the final answer plus which tools were actually used.\n",
    "print(\"User question:\", user_question)\n",
    "print(\"Final answer:\", result[\"answer\"])\n",
    "print(\"Tools used:\", \", \".join(result[\"used_tools\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac710b3",
   "metadata": {},
   "source": [
    "## **3. Testing LangChain Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec870c1d",
   "metadata": {},
   "source": [
    "### **3.1. Tracing Tool Calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f1bf3",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_03_01.jpg?v=1768769514\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tracing reveals each step of tool usage\n",
    ">* Helps diagnose wrong tools, bad arguments, ignored outputs\n",
    "\n",
    ">* Run realistic chats, then inspect every tool step\n",
    ">* Use traces to catch bad chaining or hallucinations\n",
    "\n",
    ">* Use traces to monitor safety, cost, latency\n",
    ">* Detect data leaks, regressions, and unhealthy tool usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tracing Tool Calls\n",
    "\n",
    "# Demonstrate simple LangChain style tool tracing behavior clearly.\n",
    "# Show how a model might decide and call tools stepwise.\n",
    "# Print a compact trace for easy beginner friendly understanding.\n",
    "\n",
    "# pip install langchain-openai langchain-community langchain.\n",
    "\n",
    "# Import required standard libraries for simple tracing simulation.\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Define a simple tool registry with two example tools available.\n",
    "tools = {\n",
    "    \"get_weather\": \"Fetches current weather for a given city.\",\n",
    "    \"get_time\": \"Fetches current local time for a given city.\"\n",
    "}\n",
    "\n",
    "# Define a function that simulates model tool selection decisions.\n",
    "def choose_tool(user_message):\n",
    "    if \"weather\" in user_message.lower():\n",
    "        return \"get_weather\"\n",
    "    if \"time\" in user_message.lower():\n",
    "        return \"get_time\"\n",
    "    return None\n",
    "\n",
    "# Define a function that simulates calling a selected tool safely.\n",
    "def call_tool(tool_name, city):\n",
    "    if tool_name == \"get_weather\":\n",
    "        return {\"city\": city, \"temperature_f\": 72, \"condition\": \"sunny\"}\n",
    "    if tool_name == \"get_time\":\n",
    "        return {\"city\": city, \"local_time\": \"03:15 PM\"}\n",
    "    return {\"error\": \"unknown tool\"}\n",
    "\n",
    "# Define a function that runs conversation and records detailed trace.\n",
    "def run_with_trace(user_message, city):\n",
    "    trace = []\n",
    "    trace.append({\"event\": \"user_message\", \"content\": user_message})\n",
    "    tool_name = choose_tool(user_message)\n",
    "    trace.append({\"event\": \"tool_chosen\", \"tool\": tool_name})\n",
    "    if tool_name is not None:\n",
    "        args = {\"city\": city}\n",
    "        trace.append({\"event\": \"tool_call\", \"tool\": tool_name, \"args\": args})\n",
    "        result = call_tool(tool_name, city)\n",
    "        trace.append({\"event\": \"tool_result\", \"tool\": tool_name, \"result\": result})\n",
    "        final_answer = f\"In {city}, here is the tool based information: {result}.\"\n",
    "    else:\n",
    "        final_answer = \"I will answer directly without using any tools here.\"\n",
    "    trace.append({\"event\": \"final_answer\", \"content\": final_answer})\n",
    "    return trace\n",
    "\n",
    "# Run example conversation and print compact human readable trace.\n",
    "user_message = \"What is the weather like today in Denver?\"\n",
    "city = \"Denver\"\n",
    "trace = run_with_trace(user_message, city)\n",
    "for step in trace:\n",
    "    print(json.dumps(step, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e5f22",
   "metadata": {},
   "source": [
    "### **3.2. Handling tool failures**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d775f2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_03_02.jpg?v=1768769544\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Tools can fail; make failures visible and safe\n",
    ">* Intentionally trigger edge cases and check error handling\n",
    "\n",
    ">* Design tools to validate inputs and categorize errors\n",
    ">* Guide the model to interpret errors and respond safely\n",
    "\n",
    ">* Use failures to improve multi-step tool workflows\n",
    ">* Trace cascades, refine rules, and guide recovery\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71817d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Handling tool failures\n",
    "\n",
    "# Demonstrate simple tool failures and safe handling in plain Python.\n",
    "# Show input validation, exception catching, and structured error dictionaries.\n",
    "# Simulate a model reacting to tool errors with honest user friendly messages.\n",
    "\n",
    "# !pip install some_required_library_here if external libraries were needed.\n",
    "\n",
    "# Define a simple weather tool that sometimes fails on purpose.\n",
    "def weather_tool(city_name, temperature_unit):\n",
    "    # Validate city name type and length before proceeding.\n",
    "    if not isinstance(city_name, str) or len(city_name.strip()) < 3:\n",
    "        return {\"ok\": False, \"error_type\": \"invalid_city\", \"message\": \"City name seems invalid.\"}\n",
    "\n",
    "    # Validate temperature unit to accept only Fahrenheit or Celsius.\n",
    "    if temperature_unit not in [\"F\", \"C\"]:\n",
    "        return {\"ok\": False, \"error_type\": \"invalid_unit\", \"message\": \"Temperature unit must be F or C.\"}\n",
    "\n",
    "    # Simulate external system outage for a specific city keyword.\n",
    "    if city_name.lower().strip() == \"atlantis\":\n",
    "        return {\"ok\": False, \"error_type\": \"not_found\", \"message\": \"Requested city data was not found.\"}\n",
    "\n",
    "    # Simulate random network failure using simple deterministic condition.\n",
    "    if len(city_name) % 2 == 0:\n",
    "        return {\"ok\": False, \"error_type\": \"network\", \"message\": \"Weather service is temporarily unavailable.\"}\n",
    "\n",
    "    # Return successful fake temperature when no failure conditions are triggered.\n",
    "    fake_temperature_fahrenheit = 72\n",
    "    if temperature_unit == \"C\":\n",
    "        fake_temperature_fahrenheit = int((fake_temperature_fahrenheit - 32) * 5 / 9)\n",
    "    return {\"ok\": True, \"temperature\": fake_temperature_fahrenheit, \"unit\": temperature_unit}\n",
    "\n",
    "# Define a simple model like wrapper that interprets tool responses.\n",
    "def model_handle_weather_request(city_name, temperature_unit):\n",
    "    # Call the weather tool and capture its structured response.\n",
    "    tool_result = weather_tool(city_name, temperature_unit)\n",
    "\n",
    "    # If tool succeeded, return a friendly success message.\n",
    "    if tool_result.get(\"ok\"):\n",
    "        return f\"The temperature in {city_name} is {tool_result['temperature']} degrees {tool_result['unit']}.\"\n",
    "\n",
    "    # Handle invalid city error with clarification request.\n",
    "    if tool_result.get(\"error_type\") == \"invalid_city\":\n",
    "        return \"I could not understand that city name, please provide a longer valid name.\"\n",
    "\n",
    "    # Handle invalid unit error with suggestion for allowed units.\n",
    "    if tool_result.get(\"error_type\") == \"invalid_unit\":\n",
    "        return \"That temperature unit is unsupported, please use F for Fahrenheit or C for Celsius.\"\n",
    "\n",
    "    # Handle not found error with honest explanation and alternative suggestion.\n",
    "    if tool_result.get(\"error_type\") == \"not_found\":\n",
    "        return \"I could not find weather data for that location, please try a nearby real city.\"\n",
    "\n",
    "    # Handle network or unknown errors with apology and transparent message.\n",
    "    return \"I am sorry, the weather service failed, please try again later or ask something else.\"\n",
    "\n",
    "# Prepare several test scenarios that deliberately trigger different failures.\n",
    "scenarios = [\n",
    "    (\"NY\", \"F\"),\n",
    "    (\"Atlantis\", \"F\"),\n",
    "    (\"New York\", \"X\"),\n",
    "    (\"Miami\", \"F\"),\n",
    "    (\"LA\", \"C\"),\n",
    "]\n",
    "\n",
    "# Run each scenario and print how the model handles tool failures.\n",
    "for city, unit in scenarios:\n",
    "    response = model_handle_weather_request(city, unit)\n",
    "    print(f\"User asked weather for {city} in {unit}, model replied: {response}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b6c11",
   "metadata": {},
   "source": [
    "### **3.3. Refining Tool Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53b1a7",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_04/Lecture_B/image_03_03.jpg?v=1768769579\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Write precise tool names and descriptions for models\n",
    ">* Clarify when each tool is preferred or avoided\n",
    "\n",
    ">* Specify when, how, and why tools run\n",
    ">* Test edge cases, refine prompts for safe behavior\n",
    "\n",
    ">* Set strict rules for sensitive tool usage\n",
    ">* Test edge cases and refine safety instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dfef6",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Tool Calling Basics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbab33a",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Explain how LangChain exposes tools for Llama 3 to call during reasoning. \n",
    "- Define and register simple tools in LangChain and connect them to a Llama 3 model. \n",
    "- Test and debug tool-using interactions to ensure correct tool selection and safe outputs. \n",
    "\n",
    "In the next Module (Module 5), we will go over 'Agents And Deployment'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
