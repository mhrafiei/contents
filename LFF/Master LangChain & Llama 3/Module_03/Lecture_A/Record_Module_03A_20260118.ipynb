{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773bc17c",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Building Multi Step Chains**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f41a16",
   "metadata": {},
   "source": [
    ">Last update: 20260118.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe the difference between simple and multi-step LangChain chains. \n",
    "- Implement a multi-step chain that orchestrates several Llama 3 calls for a composite task. \n",
    "- Handle intermediate outputs with basic parsing and validation before passing them to subsequent steps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddc503",
   "metadata": {},
   "source": [
    "## **1. Multi Step Chain Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c3400",
   "metadata": {},
   "source": [
    "### **1.1. Sequential Chain Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046bba2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_01_01.jpg?v=1768765754\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Sequential chains run ordered, assembly-line style steps\n",
    ">* Break complex tasks into controllable, inspectable stages\n",
    "\n",
    ">* Sequential chains mirror real-world staged workflows\n",
    ">* Each step passes needed info, enabling focused oversight\n",
    "\n",
    ">* Sequential chains turn vague outcomes into explicit steps\n",
    ">* They control intermediates, improving transparency and debugging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Sequential Chain Basics\n",
    "\n",
    "# This script shows a simple sequential text processing pipeline example.\n",
    "# Each step transforms text and passes results to the next step.\n",
    "# It illustrates how sequential chains differ from single one-shot calls.\n",
    "\n",
    "# Example requires only standard Python libraries available in Google Colab.\n",
    "# No external installations are needed for running this simple demonstration.\n",
    "\n",
    "# Define a first step that extracts market segments from a short description.\n",
    "def step_one_extract_segments(problem_description):\n",
    "    \"\"\"Return a list of simple market segments from description text.\"\"\"\n",
    "    words = problem_description.lower().split()\n",
    "    segments = []\n",
    "    if \"students\" in words:\n",
    "        segments.append(\"college students in large cities\")\n",
    "    if \"parents\" in words:\n",
    "        segments.append(\"busy parents with young children\")\n",
    "    if \"freelancers\" in words:\n",
    "        segments.append(\"remote freelancers working from home\")\n",
    "    if not segments:\n",
    "        segments.append(\"general adult consumers in urban areas\")\n",
    "    return segments\n",
    "\n",
    "# Define a second step that summarizes needs for each discovered segment.\n",
    "def step_two_summarize_needs(segments):\n",
    "    \"\"\"Return bullet style need summaries for each provided segment.\"\"\"\n",
    "    summaries = []\n",
    "    for segment in segments:\n",
    "        summary = f\"Segment: {segment} | Needs: quick information, clear pricing, trustworthy reviews.\"\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "# Define a third step that combines summaries into a short final report.\n",
    "def step_three_build_report(need_summaries):\n",
    "    \"\"\"Return a short report that synthesizes previous need summaries.\"\"\"\n",
    "    header = \"Mini Market Analysis Report for New Online Service\"\n",
    "    body_lines = []\n",
    "    for summary in need_summaries:\n",
    "        body_lines.append(f\"- {summary}\")\n",
    "    body = \"\\n\".join(body_lines)\n",
    "    conclusion = \"Overall, focus on convenience, transparency, and reliable customer support across segments.\"\n",
    "    report = f\"{header}\\n\\n{body}\\n\\n{conclusion}\"\n",
    "    return report\n",
    "\n",
    "# Define a helper that runs all steps sequentially, passing outputs forward.\n",
    "def run_sequential_chain(problem_description):\n",
    "    \"\"\"Run three ordered steps and return intermediate plus final results.\"\"\"\n",
    "    segments = step_one_extract_segments(problem_description)\n",
    "    need_summaries = step_two_summarize_needs(segments)\n",
    "    report = step_three_build_report(need_summaries)\n",
    "    return segments, need_summaries, report\n",
    "\n",
    "# Provide a simple problem description similar to lecture examples.\n",
    "problem_description = \"We are launching a new budgeting app for students, parents, and freelancers.\"\n",
    "\n",
    "# Run the sequential chain and capture intermediate outputs for inspection.\n",
    "segments, need_summaries, final_report = run_sequential_chain(problem_description)\n",
    "\n",
    "# Print intermediate results to show transparent multi step processing.\n",
    "print(\"Step 1 - Extracted segments:\")\n",
    "print(segments)\n",
    "print(\"\\nStep 2 - Need summaries:\")\n",
    "for summary in need_summaries:\n",
    "    print(summary)\n",
    "print(\"\\nStep 3 - Final combined report:\")\n",
    "print(final_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79f298",
   "metadata": {},
   "source": [
    "### **1.2. Branching and Routing Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef6982",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_01_02.jpg?v=1768765782\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Chains can follow different paths based on context\n",
    ">* Router chooses the best sub-chain or tool\n",
    "\n",
    ">* Branching classifies user intent, then selects sub-chain\n",
    ">* Like specialists, routes tasks to best workflow\n",
    "\n",
    ">* Chains change path based on intermediate results\n",
    ">* Enables adaptive workflows for feedback and tutoring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Branching and Routing Basics\n",
    "\n",
    "# Demonstrate simple branching and routing decisions with plain Python functions.\n",
    "# Show how different inputs follow different processing paths dynamically.\n",
    "# Mimic LangChain style routing without external libraries or complex setup.\n",
    "# pip install langchain llama-index transformers accelerate bitsandbytes.\n",
    "\n",
    "# Define a simple router that decides processing path based on user intent.\n",
    "intent_keywords = {\"weather\": [\"weather\", \"rain\", \"sunny\"], \"email\": [\"email\", \"invite\", \"meeting\"], \"code\": [\"bug\", \"error\", \"function\"]}\n",
    "\n",
    "# Define a function that classifies intent using keyword matching logic.\n",
    "def classify_intent(user_text):\n",
    "    for intent, keywords in intent_keywords.items():\n",
    "        for word in keywords:\n",
    "            if word in user_text.lower():\n",
    "                return intent\n",
    "    return \"general\"\n",
    "\n",
    "# Define a handler for weather related questions or conversational requests.\n",
    "def handle_weather(user_text):\n",
    "    return \"Weather branch chosen: Expect mild temperatures around seventy degrees Fahrenheit.\"\n",
    "\n",
    "# Define a handler for email drafting or professional writing tasks.\n",
    "def handle_email(user_text):\n",
    "    return \"Email branch chosen: Drafting a polite invitation for your upcoming meeting.\"\n",
    "\n",
    "# Define a handler for code explanation or debugging style questions.\n",
    "def handle_code(user_text):\n",
    "    return \"Code branch chosen: Explaining the function step by step in plain language.\"\n",
    "\n",
    "# Define a handler for general small talk or uncategorized user requests.\n",
    "def handle_general(user_text):\n",
    "    return \"General branch chosen: Having a friendly conversation about your question today.\"\n",
    "\n",
    "# Define the router that selects which branch function should run next.\n",
    "def route_request(user_text):\n",
    "    intent = classify_intent(user_text)\n",
    "    if intent == \"weather\":\n",
    "        return handle_weather(user_text)\n",
    "    if intent == \"email\":\n",
    "        return handle_email(user_text)\n",
    "    if intent == \"code\":\n",
    "        return handle_code(user_text)\n",
    "    return handle_general(user_text)\n",
    "\n",
    "# Prepare several example requests that will follow different branches.\n",
    "examples = [\"Will it rain tomorrow in my city?\", \"Please write an email meeting invite.\", \"Why does this Python function show an error?\", \"Tell me something interesting about space exploration.\"]\n",
    "\n",
    "# Run the router for each example and print chosen branch results.\n",
    "for text in examples:\n",
    "    result = route_request(text)\n",
    "    print(f\"Input: {text} -> {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a8609",
   "metadata": {},
   "source": [
    "### **1.3. When to Chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64718800",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_01_03.jpg?v=1768765809\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use chains when tasks split into stages\n",
    ">* Separate stages simplify prompts, debugging, and improvement\n",
    "\n",
    ">* Use chains when checking intermediate model outputs\n",
    ">* Chaining enables validation, enrichment, and safer decisions\n",
    "\n",
    ">* Use single calls for short, simple tasks\n",
    ">* Choose chains when modular control outweighs complexity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427556d",
   "metadata": {},
   "source": [
    "## **2. Composite LLM Workflows**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66936ae0",
   "metadata": {},
   "source": [
    "### **2.1. Layered Extraction Summaries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd1fc4",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_02_01.jpg?v=1768765827\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Break complex understanding into sequential focused passes\n",
    ">* Each layer extracts, groups, then summarizes information\n",
    "\n",
    ">* Each layer does a focused, specific task\n",
    ">* Structured intermediate outputs improve reasoning and debugging\n",
    "\n",
    ">* Useful for long, messy, real-world documents\n",
    ">* Multiple layers transform text into decision-ready summaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08424c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Layered Extraction Summaries\n",
    "\n",
    "# Demonstrate layered extraction summaries using simple Python lists and dictionaries.\n",
    "# Show three processing layers transforming messy support logs into structured summaries.\n",
    "# Keep everything beginner friendly and runnable directly inside Google Colab.\n",
    "\n",
    "# pip install libraries here if needed, but standard Colab Python is sufficient.\n",
    "\n",
    "# Define a messy multi line customer support transcript string example.\n",
    "raw_transcript = \"\"\"Customer: My internet speed is very slow since yesterday night.\n",
    "Agent: When did the slowdown start exactly, and which city are you in now.\n",
    "Customer: I am in Dallas, Texas, and it started around 9 PM yesterday.\n",
    "Agent: I see similar complaints from your area about slow download speeds.\n",
    "Customer: Also my video calls keep freezing during important business meetings.\n",
    "Agent: Thanks, I will escalate this performance issue to our network engineering team.\n",
    "Customer: Last month I had a billing error where I was double charged.\n",
    "Agent: I refunded that extra charge and noted the billing problem in your account.\n",
    "Customer: Overall I feel frustrated because issues keep returning every few weeks.\n",
    "Agent: I understand your frustration and will monitor your connection for several days.\"\"\"\n",
    "\n",
    "# First layer extracts simple problem statements from the raw transcript text.\n",
    "first_layer_problems = [\n",
    "    {\n",
    "        \"problem\": \"Slow internet speed since yesterday night.\",\n",
    "        \"category\": \"performance\",\n",
    "        \"speaker\": \"customer\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Extend first layer with additional structured problem dictionaries for variety.\n",
    "first_layer_problems.append(\n",
    "    {\n",
    "        \"problem\": \"Video calls freezing during important business meetings.\",\n",
    "        \"category\": \"performance\",\n",
    "        \"speaker\": \"customer\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add a billing related problem entry to the first layer list.\n",
    "first_layer_problems.append(\n",
    "    {\n",
    "        \"problem\": \"Billing error with double charge last month.\",\n",
    "        \"category\": \"billing\",\n",
    "        \"speaker\": \"customer\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Second layer groups problems by category into a new dictionary structure.\n",
    "layer_two_grouped = {}\n",
    "for item in first_layer_problems:\n",
    "    category = item[\"category\"]\n",
    "    if category not in layer_two_grouped:\n",
    "        layer_two_grouped[category] = []\n",
    "    layer_two_grouped[category].append(item[\"problem\"])\n",
    "\n",
    "# Third layer builds concise summaries for each category using simple string joins.\n",
    "layer_three_summaries = {}\n",
    "for category, problems in layer_two_grouped.items():\n",
    "    joined = \"; \".join(problems)\n",
    "    summary = f\"Category {category} includes issues like: {joined}\"\n",
    "    layer_three_summaries[category] = summary\n",
    "\n",
    "# Print a short view of first layer structured extraction results.\n",
    "print(\"First layer extracted problems:\")\n",
    "for item in first_layer_problems:\n",
    "    print(f\"- {item['category']} problem: {item['problem']}\")\n",
    "\n",
    "# Print grouped categories from the second processing layer dictionary.\n",
    "print(\"\\nSecond layer grouped by category:\")\n",
    "for category, problems in layer_two_grouped.items():\n",
    "    print(f\"- {category} has {len(problems)} problems recorded\")\n",
    "\n",
    "# Print final layered summaries that resemble decision ready overviews.\n",
    "print(\"\\nThird layer concise summaries:\")\n",
    "for category, summary in layer_three_summaries.items():\n",
    "    print(f\"- {summary}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c94a3d",
   "metadata": {},
   "source": [
    "### **2.2. Turning Summaries Into Actions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f156af",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_02_02.jpg?v=1768765860\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Summaries become inputs for planning-focused Llama calls\n",
    ">* Model turns summaries into detailed, executable action plans\n",
    "\n",
    ">* Define clear action types and output format\n",
    ">* Second call reasons on summaries to plan work\n",
    "\n",
    ">* Summaries feed automated tools and downstream systems\n",
    ">* Second Llama call outputs structured, executable instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Turning Summaries Into Actions\n",
    "\n",
    "# Demonstrate turning summaries into concrete action plans using simple Python structures.\n",
    "# Simulate two Llama 3 style steps without external APIs or complex setup.\n",
    "# Show how a summary feeds an action planner that prints a clear checklist.\n",
    "\n",
    "# pip install langchain-openai llama-index transformers accelerate bitsandbytes.\n",
    "\n",
    "# Define a function that simulates a previous Llama summary step.\n",
    "def summarize_issue(long_email_text):\n",
    "    # Return a compact structured summary dictionary with key details extracted.\n",
    "    summary = {\n",
    "        \"problem\": \"User cannot log into account after password reset attempt.\",\n",
    "        \"tone\": \"frustrated but still polite and open to help.\",\n",
    "        \"constraints\": \"Needs resolution within twenty four hours due to travel.\",\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# Define a function that turns the summary into concrete action steps.\n",
    "def plan_actions_from_summary(summary):\n",
    "    # Build a list of ordered actions based on summary fields content.\n",
    "    actions = []\n",
    "    actions.append(\"Acknowledge frustration and thank user for clear explanation.\")\n",
    "    actions.append(\"Verify account ownership and recent password reset activity logs.\")\n",
    "    actions.append(\"Check for account locks or suspicious login attempts flags.\")\n",
    "    actions.append(\"Prioritize resolution within twenty four hours due to travel.\")\n",
    "    actions.append(\"Send reply matching polite tone with clear next steps.\")\n",
    "    return actions\n",
    "\n",
    "# Example long email text that would normally be summarized by Llama.\n",
    "long_email = (\n",
    "    \"Hi, I tried resetting my password last night and now I cannot log in. \"\n",
    "    \"I am flying tomorrow morning and really need access to my boarding \"\n",
    "    \"passes and travel documents. I am pretty frustrated but I know these \"\n",
    "    \"things happen. Please help me get back into my account as soon as possible.\"\n",
    ")\n",
    "\n",
    "# First step simulates Llama summary call using the helper function.\n",
    "summary_result = summarize_issue(long_email)\n",
    "\n",
    "# Second step simulates Llama planning call using the summary result.\n",
    "action_plan = plan_actions_from_summary(summary_result)\n",
    "\n",
    "# Print the summary to show compact understanding before planning actions.\n",
    "print(\"Summary used for planning:\")\n",
    "print(f\"Problem: {summary_result['problem']}\")\n",
    "print(f\"Tone: {summary_result['tone']}\")\n",
    "print(f\"Constraints: {summary_result['constraints']}\")\n",
    "\n",
    "# Print the resulting action checklist that could drive downstream tools.\n",
    "print(\"\\nPlanned support actions checklist:\")\n",
    "for index, step in enumerate(action_plan, start=1):\n",
    "    print(f\"Step {index}: {step}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6531e",
   "metadata": {},
   "source": [
    "### **2.3. Coordinating Multiple Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fdab9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_02_03.jpg?v=1768765890\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Define each stepâ€™s role and needed inputs\n",
    ">* Sequence outputs like a relay for coherent workflows\n",
    "\n",
    ">* Limit and structure information passed between steps\n",
    ">* Use concise, formatted outputs for reliable handoffs\n",
    "\n",
    ">* Choose sequential, parallel, or iterative task steps\n",
    ">* Manage dependencies and merge results into workflows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d92d6",
   "metadata": {},
   "source": [
    "## **3. Intermediate Output Handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15847a",
   "metadata": {},
   "source": [
    "### **3.1. Parsing structured text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0bf93",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_03_01.jpg?v=1768766192\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Parse model outputs into clear, labeled fields\n",
    ">* Use markers to separate sections for later steps\n",
    "\n",
    ">* Plan expected structure and parse around headings\n",
    ">* Convert messy text into consistent, named fields\n",
    "\n",
    ">* Plan for messy, inconsistent model outputs\n",
    ">* Use flexible parsing, defaults, and validation checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Parsing structured text\n",
    "\n",
    "# Demonstrate parsing structured text into useful Python fields.\n",
    "# Show simple extraction using predictable labels and separators.\n",
    "# Handle minor format variations with forgiving parsing logic.\n",
    "# pip install some_required_library_if_needed.\n",
    "\n",
    "# Define a fake model response with labeled structured sections.\n",
    "model_response = (\n",
    "    \"Issue Description: Laptop overheats after twenty minutes of gaming. \"\n",
    "    \"Urgency Level: High. \"\n",
    "    \"Recommended Action: Clean vents and reduce graphics settings.\"\n",
    ")\n",
    "\n",
    "# Define a second response with slightly different labels and extra text.\n",
    "alt_response = (\n",
    "    \"Customer says: fan is very loud. \"\n",
    "    \"Problem: Fan noise during normal browsing. \"\n",
    "    \"Priority: Medium. \"\n",
    "    \"Suggested Fix: Update drivers and check dust buildup.\"\n",
    ")\n",
    "\n",
    "# Create a list of possible label variants for each desired field.\n",
    "label_variants = {\n",
    "    \"issue\": [\"Issue Description\", \"Problem\"],\n",
    "    \"urgency\": [\"Urgency Level\", \"Priority\"],\n",
    "    \"action\": [\"Recommended Action\", \"Suggested Fix\"],\n",
    "}\n",
    "\n",
    "# Define a function that extracts field text following any matching label.\n",
    "def extract_field(text, labels):\n",
    "    for label in labels:\n",
    "        search = label + \":\"\n",
    "        if search in text:\n",
    "            start = text.index(search) + len(search)\n",
    "            end = text.find(\".\", start)\n",
    "            if end == -1:\n",
    "                end = len(text)\n",
    "            return text[start:end].strip()\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "# Parse both responses into structured dictionaries using the helper function.\n",
    "parsed_one = {\n",
    "    \"issue\": extract_field(model_response, label_variants[\"issue\"]),\n",
    "    \"urgency\": extract_field(model_response, label_variants[\"urgency\"]),\n",
    "    \"action\": extract_field(model_response, label_variants[\"action\"]),\n",
    "}\n",
    "\n",
    "# Parse the alternative response that uses different labels and extra commentary.\n",
    "parsed_two = {\n",
    "    \"issue\": extract_field(alt_response, label_variants[\"issue\"]),\n",
    "    \"urgency\": extract_field(alt_response, label_variants[\"urgency\"]),\n",
    "    \"action\": extract_field(alt_response, label_variants[\"action\"]),\n",
    "}\n",
    "\n",
    "# Print the original responses and the parsed structured representations.\n",
    "print(\"Original response one:\")\n",
    "print(model_response)\n",
    "print(\"\\nParsed fields one:\")\n",
    "print(parsed_one)\n",
    "print(\"\\nOriginal response two:\")\n",
    "print(alt_response)\n",
    "print(\"\\nParsed fields two:\")\n",
    "print(parsed_two)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1809e6",
   "metadata": {},
   "source": [
    "### **3.2. Validation Essentials**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0533c1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_03_02.jpg?v=1768766225\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Validation checks structure and task-appropriate content\n",
    ">* Prevents early errors from corrupting later steps\n",
    "\n",
    ">* Layer checks from basic to domain-specific rules\n",
    ">* Apply structural and business rules to outputs\n",
    "\n",
    ">* Design chains with validation as a core feature\n",
    ">* Define rules, auto-correct or reject, log issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Validation Essentials\n",
    "\n",
    "# Demonstrate simple validation for intermediate chain outputs before next processing step.\n",
    "# Show structural checks and domain rules for a travel planning style intermediate result.\n",
    "# Print whether each intermediate output is safe to pass to the next chain step.\n",
    "\n",
    "# pip install langchain llama-index sentence-transformers transformers accelerate bitsandbytes.\n",
    "\n",
    "# Define allowed cities and allowed travel classes for validation.\n",
    "ALLOWED_CITIES = {\"New York\", \"Chicago\", \"Los Angeles\", \"Houston\"}\n",
    "ALLOWED_CLASSES = {\"economy\", \"business\", \"first\"}\n",
    "\n",
    "# Define a function that validates structure and domain specific rules.\n",
    "def validate_trip(candidate):\n",
    "    # Check required keys exist and candidate is a dictionary structure.\n",
    "    required_keys = {\"from_city\", \"to_city\", \"date\", \"travel_class\"}\n",
    "    if not isinstance(candidate, dict):\n",
    "        return False, \"Output is not dictionary structure.\"\n",
    "\n",
    "    # Check all required keys are present inside the candidate dictionary.\n",
    "    if not required_keys.issubset(candidate.keys()):\n",
    "        return False, \"Missing required travel fields detected.\"\n",
    "\n",
    "    # Extract fields and normalize travel class for consistent comparison.\n",
    "    from_city = candidate[\"from_city\"]\n",
    "    to_city = candidate[\"to_city\"]\n",
    "    date_text = candidate[\"date\"]\n",
    "    travel_class = str(candidate[\"travel_class\"]).lower()\n",
    "\n",
    "    # Check cities are allowed and not identical for sensible travel.\n",
    "    if from_city not in ALLOWED_CITIES or to_city not in ALLOWED_CITIES:\n",
    "        return False, \"City not allowed within configured list.\"\n",
    "\n",
    "    # Ensure departure and arrival cities are different locations.\n",
    "    if from_city == to_city:\n",
    "        return False, \"Departure and arrival cities identical.\"\n",
    "\n",
    "    # Check travel class is one of the allowed categories.\n",
    "    if travel_class not in ALLOWED_CLASSES:\n",
    "        return False, \"Travel class not within allowed categories.\"\n",
    "\n",
    "    # Perform simple date pattern check for basic structural correctness.\n",
    "    if len(date_text) != 10 or date_text[4] != \"-\" or date_text[7] != \"-\":\n",
    "        return False, \"Date format not matching expected pattern.\"\n",
    "\n",
    "    # If all checks pass then candidate is considered valid for next step.\n",
    "    return True, \"Trip data valid for next chain step.\"\n",
    "\n",
    "# Simulate three model outputs representing intermediate chain results.\n",
    "model_outputs = [\n",
    "    {\"from_city\": \"New York\", \"to_city\": \"Chicago\", \"date\": \"2026-07-04\", \"travel_class\": \"Economy\"},\n",
    "    {\"from_city\": \"Houston\", \"to_city\": \"Houston\", \"date\": \"2026-07-04\", \"travel_class\": \"business\"},\n",
    "    {\"from_city\": \"Boston\", \"to_city\": \"Chicago\", \"date\": \"July fourth\", \"travel_class\": \"economy\"},\n",
    "]\n",
    "\n",
    "# Loop through outputs, validate each, and decide next action.\n",
    "for index, output in enumerate(model_outputs, start=1):\n",
    "    is_valid, message = validate_trip(output)\n",
    "    status = \"ACCEPTED\" if is_valid else \"REJECTED\"\n",
    "    print(f\"Output {index} status {status}: {message}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e90c3e",
   "metadata": {},
   "source": [
    "### **3.3. Robust Error Handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941fe41",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master LangChain & Llama 3/Module_03/Lecture_A/image_03_03.jpg?v=1768766258\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Expect imperfect intermediate outputs and validate them\n",
    ">* Use checks and controlled fallbacks instead of crashing\n",
    "\n",
    ">* Separate minor, fixable issues from critical failures\n",
    ">* Use retries, escalation, or flags for problems\n",
    "\n",
    ">* Log intermediate outputs, validations, and errors consistently\n",
    ">* Use trends to refine prompts and safeguards\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Robust Error Handling\n",
    "\n",
    "# Demonstrate robust error handling for multi step text processing chain outputs.\n",
    "# Show validation, recovery, and escalation when intermediate fields are problematic.\n",
    "# Keep everything simple, beginner friendly, and clearly printed for inspection.\n",
    "\n",
    "# pip install langchain llama-index transformers accelerate bitsandbytes.\n",
    "\n",
    "# Define a fake model step that sometimes returns bad structured data.\n",
    "import random\n",
    "\n",
    "def fake_model_step(email_text):\n",
    "    # Randomly decide which error scenario to simulate.\n",
    "    scenario = random.choice([\"ok\", \"missing\", \"bad_urgency\", \"empty_issue\"])\n",
    "\n",
    "    # Start with a reasonable default structured dictionary output.\n",
    "    result = {\"name\": \"Alex Smith\", \"issue\": \"Laptop overheating\", \"urgency\": \"medium\"}\n",
    "\n",
    "    # Simulate missing field scenario by deleting urgency key entirely.\n",
    "    if scenario == \"missing\":\n",
    "        result.pop(\"urgency\", None)\n",
    "\n",
    "    # Simulate bad urgency scenario using unexpected category string value.\n",
    "    if scenario == \"bad_urgency\":\n",
    "        result[\"urgency\"] = \"super_critical_level_five\"\n",
    "\n",
    "    # Simulate empty issue scenario using whitespace only description string.\n",
    "    if scenario == \"empty_issue\":\n",
    "        result[\"issue\"] = \"   \"\n",
    "\n",
    "    # Return both result and scenario for easier demonstration printing.\n",
    "    return result, scenario\n",
    "\n",
    "# Define validation function that checks fields and returns status plus cleaned data.\n",
    "def validate_intermediate_output(raw_dict):\n",
    "    # Define allowed urgency categories for downstream chain steps.\n",
    "    allowed_urgencies = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "    # Initialize cleaned dictionary and list for accumulating error messages.\n",
    "    cleaned = {}\n",
    "    errors = []\n",
    "\n",
    "    # Validate name presence and basic non empty content.\n",
    "    name = raw_dict.get(\"name\", \"\").strip()\n",
    "    if not name:\n",
    "        errors.append(\"Missing customer name field value.\")\n",
    "    else:\n",
    "        cleaned[\"name\"] = name\n",
    "\n",
    "    # Validate issue presence and non whitespace content.\n",
    "    issue = raw_dict.get(\"issue\", \"\").strip()\n",
    "    if not issue:\n",
    "        errors.append(\"Missing or empty issue description field.\")\n",
    "    else:\n",
    "        cleaned[\"issue\"] = issue\n",
    "\n",
    "    # Validate urgency presence and membership within allowed categories.\n",
    "    urgency = raw_dict.get(\"urgency\", \"\").strip().lower()\n",
    "    if not urgency:\n",
    "        errors.append(\"Missing urgency field value entirely.\")\n",
    "    elif urgency not in allowed_urgencies:\n",
    "        errors.append(\"Urgency value outside allowed categories list.\")\n",
    "    else:\n",
    "        cleaned[\"urgency\"] = urgency\n",
    "\n",
    "    # Decide severity based on number and type of accumulated errors.\n",
    "    if not errors:\n",
    "        status = \"ok\"\n",
    "    elif len(errors) == 1 and \"urgency\" in errors[0].lower():\n",
    "        status = \"recoverable\"\n",
    "    else:\n",
    "        status = \"critical\"\n",
    "\n",
    "    # Return status, cleaned dictionary, and list of error messages.\n",
    "    return status, cleaned, errors\n",
    "\n",
    "# Define handler that decides recovery, fallback, or escalation behavior.\n",
    "def handle_output(status, cleaned, errors):\n",
    "    # If everything validated correctly, continue chain normally.\n",
    "    if status == \"ok\":\n",
    "        message = \"Proceeding normally with validated fields dictionary.\"\n",
    "        return message, cleaned\n",
    "\n",
    "    # If recoverable, apply simple fallback default urgency value.\n",
    "    if status == \"recoverable\":\n",
    "        cleaned[\"urgency\"] = \"medium\"\n",
    "        message = \"Applied default urgency after minor validation problem.\"\n",
    "        return message, cleaned\n",
    "\n",
    "    # For critical issues, stop chain and escalate with clear explanation.\n",
    "    escalation_note = \"Stopping chain, logging errors, requesting human review escalation.\"\n",
    "    return escalation_note, None\n",
    "\n",
    "# Run demonstration once to keep printed output short and readable.\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate upstream model step producing possibly flawed intermediate output.\n",
    "    raw_output, scenario = fake_model_step(\"Customer support email text placeholder.\")\n",
    "\n",
    "    # Validate intermediate output before passing into next chain step.\n",
    "    status, cleaned, errors = validate_intermediate_output(raw_output)\n",
    "\n",
    "    # Decide how to respond based on validation status and error severity.\n",
    "    action_message, final_payload = handle_output(status, cleaned, errors)\n",
    "\n",
    "    # Print concise observability information for debugging and monitoring.\n",
    "    print(\"Simulated scenario:\", scenario)\n",
    "    print(\"Raw model output:\", raw_output)\n",
    "    print(\"Validation status:\", status)\n",
    "    print(\"Validation errors:\", errors)\n",
    "    print(\"Action decision:\", action_message)\n",
    "    print(\"Payload forwarded downstream:\", final_payload)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d82b2",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Building Multi Step Chains**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856b1ea",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe the difference between simple and multi-step LangChain chains. \n",
    "- Implement a multi-step chain that orchestrates several Llama 3 calls for a composite task. \n",
    "- Handle intermediate outputs with basic parsing and validation before passing them to subsequent steps. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Conversational Memory'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
