{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9090a08",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Cleaning Columns**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63413b2a",
   "metadata": {},
   "source": [
    ">Last update: 20251225.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Handle missing values in DataFrames using strategies such as dropping, filling, and interpolation with Pandas 2.3.1 methods. \n",
    "- Standardize text and categorical columns by trimming, case-normalizing, and mapping inconsistent labels. \n",
    "- Convert column dtypes to appropriate numeric, datetime, and categorical types to support accurate computations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aee7b8",
   "metadata": {},
   "source": [
    "## **1. Handling Missing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53522d73",
   "metadata": {},
   "source": [
    "### **1.1. Finding Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e833d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_01_01.jpg?v=1766709096\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Identify how missing values are encoded and stored\n",
    ">* Treat missing values as unknowns, not real data\n",
    "\n",
    ">* Use column summaries to spot missing data patterns\n",
    ">* Inspect specific rows to see systematic missingness\n",
    "\n",
    ">* Detect disguised placeholders and treat them as missing\n",
    ">* Profile columns, flag invalid values, then clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7231487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Finding Missing Values\n",
    "\n",
    "# Show how pandas marks missing values clearly.\n",
    "# Create a tiny DataFrame with different missing markers.\n",
    "# Summarize missing values counts for each column.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small example dataset with different missing styles.\n",
    "data = {\n",
    "    \"height_inches\": [70, None, 65, -1],\n",
    "    \"weight_pounds\": [180, 150, \"N/A\", 200],\n",
    "    \"city\": [\"New York\", \"\", \"unknown\", \"Chicago\"],\n",
    "}\n",
    "\n",
    "# Build a DataFrame from the dictionary data.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Replace placeholder codes with proper missing values markers.\n",
    "df_clean = df.replace({\"N/A\": pd.NA, \"\": pd.NA, -1: pd.NA, \"unknown\": pd.NA})\n",
    "\n",
    "# Show the cleaned DataFrame to inspect missing markers visually.\n",
    "print(\"Cleaned DataFrame with standardized missing markers:\")\n",
    "print(df_clean)\n",
    "\n",
    "# Use isna with sum to count missing values per column.\n",
    "missing_counts = df_clean.isna().sum()\n",
    "\n",
    "# Print missing counts to understand missingness pattern quickly.\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f23ede",
   "metadata": {},
   "source": [
    "### **1.2. Choosing Dropna Or Fillna**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba19679",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_01_02.jpg?v=1766709244\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Choose between dropping or filling missing entries\n",
    ">* Dropping works for rare, random gaps; beware bias\n",
    "\n",
    ">* Fill gaps to keep all valuable observations\n",
    ">* Choose constants or statistics, acknowledging strong assumptions\n",
    "\n",
    ">* Weigh data loss, missingness pattern, and assumptions\n",
    ">* Mix drop, fill, and documentation to manage bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Choosing Dropna Or Fillna\n",
    "\n",
    "# Demonstrate choosing dropna or fillna for missing values in columns.\n",
    "# Show how dropping removes rows and filling keeps all observations.\n",
    "# Compare effects on a tiny sales DataFrame with missing discounts.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create small sales DataFrame with some missing discount values.\n",
    "data = {\"order_id\": [1, 2, 3, 4], \"amount_dollars\": [50, 80, 40, 60], \"discount_dollars\": [0, None, 5, None]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Show original data with missing discount values clearly visible.\n",
    "print(\"Original DataFrame with missing discounts:\")\n",
    "print(df)\n",
    "\n",
    "# Drop rows where discount is missing, keep only complete discount information.\n",
    "dropped = df.dropna(subset=[\"discount_dollars\"])\n",
    "\n",
    "print(\"\\nAfter dropping rows with missing discounts:\")\n",
    "print(dropped)\n",
    "\n",
    "# Fill missing discounts with zero dollars, assuming no discount was applied.\n",
    "filled = df.fillna({\"discount_dollars\": 0})\n",
    "\n",
    "print(\"\\nAfter filling missing discounts with zero dollars:\")\n",
    "print(filled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7d417",
   "metadata": {},
   "source": [
    "### **1.3. Interpolation For Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46599cf2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_01_03.jpg?v=1766709270\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Interpolation estimates ordered missing values using neighbors\n",
    ">* Preserves series continuity with methods matching data behavior\n",
    "\n",
    ">* Linear interpolation estimates values between nearby points\n",
    ">* Pandas offers time-based and forward/backward interpolation\n",
    "\n",
    ">* Use interpolation carefully; values are only estimates\n",
    ">* Limit to short gaps and combine with other methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Interpolation For Missing Values\n",
    "\n",
    "# Demonstrate simple interpolation for missing numeric values in ordered data.\n",
    "# Show differences between raw data and interpolated temperature readings.\n",
    "# Use pandas interpolate methods with a small time indexed DataFrame.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create hourly temperature data with some missing values in degrees Fahrenheit.\n",
    "times = pd.date_range(start=\"2024-01-01 08:00\", periods=6, freq=\"H\")\n",
    "values = [68.0, np.nan, np.nan, 74.0, 75.0, np.nan]\n",
    "\n",
    "df = pd.DataFrame({\"temperature_F\": values}, index=times)\n",
    "\n",
    "# Show original data with missing values clearly visible for comparison.\n",
    "print(\"Original temperature data with missing values:\")\n",
    "print(df)\n",
    "\n",
    "# Apply simple linear interpolation based on position between known values.\n",
    "df_linear = df.interpolate(method=\"linear\", limit_direction=\"forward\")\n",
    "\n",
    "# Apply time based interpolation using actual timestamp distances.\n",
    "df_time = df.interpolate(method=\"time\", limit_direction=\"forward\")\n",
    "\n",
    "# Combine original and interpolated values into one comparison DataFrame.\n",
    "combined = pd.concat([df, df_linear, df_time], axis=1)\n",
    "combined.columns = [\"original_F\", \"linear_F\", \"time_based_F\"]\n",
    "\n",
    "# Print comparison to see how interpolation filled missing temperature values.\n",
    "print(\"\\nComparison of original and interpolated temperatures:\")\n",
    "print(combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e3985",
   "metadata": {},
   "source": [
    "## **2. Text Cleaning Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5aac55",
   "metadata": {},
   "source": [
    "### **2.1. Trimming And Lowercasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd272c1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_02_01.jpg?v=1766709297\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Trim spaces and lowercase to standardize text\n",
    ">* Prevents identical values being counted as different\n",
    "\n",
    ">* Different spellings create separate, incorrect categories\n",
    ">* Trim and lowercase text to unify values\n",
    "\n",
    ">* Use trimming and lowercasing, but think first\n",
    ">* Protect codes where case or spaces matter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0818226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Trimming And Lowercasing\n",
    "\n",
    "# Demonstrate trimming spaces in text columns using pandas string methods.\n",
    "# Demonstrate converting text to lowercase for consistent comparisons.\n",
    "# Show before and after cleaning for a small example DataFrame.\n",
    "\n",
    "import pandas as pandas_library\n",
    "\n",
    "# Create a small DataFrame with messy city and country text values.\n",
    "raw_data = {\"city\": [\" New York \", \"los angeles\", \"Chicago  \"], \"country\": [\" USA\", \"usa \", \"UsA\"]}\n",
    "\n",
    "# Build the DataFrame from the raw_data dictionary using pandas.\n",
    "df = pandas_library.DataFrame(raw_data)\n",
    "\n",
    "# Show the original messy text values before any cleaning operations.\n",
    "print(\"Original DataFrame with messy text values:\\n\", df)\n",
    "\n",
    "# Trim spaces from both ends of each string in city and country columns.\n",
    "df[\"city\"] = df[\"city\"].str.strip()\n",
    "\n",
    "df[\"country\"] = df[\"country\"].str.strip()\n",
    "\n",
    "# Convert all letters in city and country columns to lowercase consistently.\n",
    "df[\"city\"] = df[\"city\"].str.lower()\n",
    "\n",
    "df[\"country\"] = df[\"country\"].str.lower()\n",
    "\n",
    "# Show the cleaned DataFrame after trimming and lowercasing operations.\n",
    "print(\"\\nCleaned DataFrame with trimmed lowercase text:\\n\", df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb2390",
   "metadata": {},
   "source": [
    "### **2.2. Standardizing Category Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721e5b8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_02_02.jpg?v=1766709318\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Standardize categories so each concept has one label\n",
    ">* Map all label variations to chosen canonical forms\n",
    "\n",
    ">* Inspect unique values, find variants of same category\n",
    ">* Map variants to canonical labels and document choices\n",
    "\n",
    ">* Balance merging categories with keeping important distinctions\n",
    ">* Create clear rules for unknowns and edge cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb60303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Standardizing Category Labels\n",
    "\n",
    "# Demonstrate standardizing messy category labels using simple Pandas mapping.\n",
    "# Show how different text variants become one consistent canonical category label.\n",
    "# Help beginners see why label standardization improves clean analysis results.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame with messy country labels and product categories.\n",
    "data = {\n",
    "    \"country\": [\"USA\", \"U.S.A.\", \"US\", \"United States\", \"usa\"],\n",
    "    \"product\": [\"Electronics\", \"electronics\", \"Elec.\", \"Elec\", \"ELECTRONICS\"],\n",
    "}\n",
    "\n",
    "# Build the DataFrame from the dictionary using Pandas DataFrame constructor.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Show the original messy categories before any cleaning or standardization.\n",
    "print(\"Original categories table before standardization:\\n\", df)\n",
    "\n",
    "# Define canonical mapping for country labels using a simple Python dictionary.\n",
    "country_map = {\n",
    "    \"usa\": \"United States\",\n",
    "    \"u.s.a.\": \"United States\",\n",
    "    \"us\": \"United States\",\n",
    "}\n",
    "\n",
    "# Convert country text to lowercase then map variants to the canonical label.\n",
    "df[\"country_clean\"] = df[\"country\"].str.lower().map(country_map).fillna(\"United States\")\n",
    "\n",
    "# Define canonical mapping for product labels using lowercase keys and full names.\n",
    "product_map = {\n",
    "    \"electronics\": \"Electronics\",\n",
    "    \"elec.\": \"Electronics\",\n",
    "    \"elec\": \"Electronics\",\n",
    "}\n",
    "\n",
    "# Convert product text to lowercase then map variants to the canonical label.\n",
    "df[\"product_clean\"] = df[\"product\"].str.lower().map(product_map).fillna(\"Electronics\")\n",
    "\n",
    "# Show the cleaned categories and compare them with the original messy values.\n",
    "print(\"\\nStandardized categories table after mapping variants:\\n\", df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b95bb",
   "metadata": {},
   "source": [
    "### **2.3. Whitespace and symbol cleanup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b2fc8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_02_03.jpg?v=1766709347\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Messy whitespace and symbols distort text columns\n",
    ">* Uncleaned issues create fake categories and confusion\n",
    "\n",
    ">* Hidden whitespace and symbols create fake differences\n",
    ">* Normalize spaces and dashes to unify categories\n",
    "\n",
    ">* Decide which symbols are meaningful or noise\n",
    ">* Strip unwanted symbols and standardize remaining characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Whitespace and symbol cleanup\n",
    "\n",
    "# Demonstrate cleaning messy whitespace and symbols in Pandas text columns.\n",
    "# Show how different looking similar strings become consistent categories.\n",
    "# Use simple replacements for spaces, dashes, and decorative symbols.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame with messy city and department text values.\n",
    "data = {\n",
    "    \"city\": [\"New York\", \"New  York\", \"New\\u00a0York\", \"New York.\"],\n",
    "    \"department\": [\"Sales\", \"Sales!\", \"Sales \", \"Salesâœ…\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original messy text values for both columns.\n",
    "print(\"Original values with messy whitespace and symbols:\\n\")\n",
    "print(df)\n",
    "\n",
    "# Replace non breaking spaces and tabs with normal spaces in city column.\n",
    "df[\"city_clean\"] = df[\"city\"].str.replace(\"\\u00a0\", \" \", regex=False).str.replace(\"\\t\", \" \", regex=False)\n",
    "\n",
    "# Remove trailing punctuation like periods and commas from city values.\n",
    "df[\"city_clean\"] = df[\"city_clean\"].str.replace(r\"[.,]+$\", \"\", regex=True)\n",
    "\n",
    "# Collapse multiple spaces into a single space and strip edges in city values.\n",
    "df[\"city_clean\"] = df[\"city_clean\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Remove decorative symbols and emojis from department values.\n",
    "df[\"dept_clean\"] = df[\"department\"].str.replace(r\"[^A-Za-z ]\", \"\", regex=True)\n",
    "\n",
    "# Collapse spaces and strip edges in department cleaned values.\n",
    "df[\"dept_clean\"] = df[\"dept_clean\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Show cleaned columns and compare unique category counts before and after.\n",
    "print(\"\\nCleaned values with normalized whitespace and symbols:\\n\")\n",
    "print(df[[\"city_clean\", \"dept_clean\"]])\n",
    "\n",
    "print(\"\\nUnique city values before and after cleaning:\")\n",
    "print(len(df[\"city\"].unique()), \"before,\", len(df[\"city_clean\"].unique()), \"after\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ce450",
   "metadata": {},
   "source": [
    "## **3. Converting Column Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01137a",
   "metadata": {},
   "source": [
    "### **3.1. Numeric Conversion Errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217a0e1",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_03_01.jpg?v=1766709375\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Messy nonnumeric entries often break numeric conversion\n",
    ">* These errors reveal data quality issues and risks\n",
    "\n",
    ">* Different locales write numbers with varying separators\n",
    ">* Mismatched formats cause failed conversions and bias\n",
    "\n",
    ">* Text-like numbers break sorting and calculations\n",
    ">* Consistent error handling keeps numeric columns reliable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Numeric Conversion Errors\n",
    "\n",
    "# Demonstrate numeric conversion errors with messy column values.\n",
    "# Show how invalid strings become missing numeric values using Pandas.\n",
    "# Compare original strings and converted numeric column side by side.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame with messy numeric looking strings.\n",
    "data = {\"sales_dollars\": [\"1200\", \"2,500\", \"N/A\", \"?\", \"3500\"]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Show the original column values before any numeric conversion attempt.\n",
    "print(\"Original sales_dollars column values:\")\n",
    "print(df[\"sales_dollars\"].tolist())\n",
    "\n",
    "# Convert to numeric with errors coerced into missing values using NaN.\n",
    "df[\"sales_numeric\"] = pd.to_numeric(df[\"sales_dollars\"], errors=\"coerce\")\n",
    "\n",
    "# Show the converted numeric column and highlight missing conversion results.\n",
    "print(\"\\nConverted sales_numeric column values:\")\n",
    "print(df[\"sales_numeric\"].tolist())\n",
    "\n",
    "# Count how many values failed conversion and became missing numeric entries.\n",
    "failed_count = df[\"sales_numeric\"].isna().sum()\n",
    "print(\"\\nNumber of failed numeric conversions:\", int(failed_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b5d24",
   "metadata": {},
   "source": [
    "### **3.2. Datetime Parsing Formats**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0862f71",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_03_02.jpg?v=1766709399\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Correctly parse date strings into datetime objects\n",
    ">* Avoid ambiguous formats that distort time-based analysis\n",
    "\n",
    ">* Recognize different date, time, and timezone patterns\n",
    ">* Specify formats to reduce ambiguity and ensure consistency\n",
    "\n",
    ">* Standardize messy datetime strings before parsing them\n",
    ">* Define supported formats, review failures, protect analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b184f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Datetime Parsing Formats\n",
    "\n",
    "# Demonstrate parsing different datetime string formats with pandas to_datetime function.\n",
    "# Show how specifying exact format removes ambiguity between similar date patterns.\n",
    "# Compare automatic parsing with explicit format strings for safer datetime conversions.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame containing several differently formatted date strings.\n",
    "raw_dates = [\"03-04-2024\", \"2024/03/04\", \"04-03-2024\", \"December 31, 2024\"]\n",
    "\n",
    "df = pd.DataFrame({\"raw_date\": raw_dates})\n",
    "\n",
    "# Show the original raw strings so we can compare before and after parsing.\n",
    "print(\"Original raw_date column values:\")\n",
    "print(df[\"raw_date\"].to_string(index=False))\n",
    "\n",
    "# Let pandas guess formats automatically, which may misinterpret ambiguous patterns.\n",
    "df[\"auto_parsed\"] = pd.to_datetime(df[\"raw_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "# Parse using an explicit month-day-year format for clearly defined numeric patterns.\n",
    "mask_numeric = df[\"raw_date\"].str.contains(\"-\", regex=False)\n",
    "\n",
    "format_mdy = \"%m-%d-%Y\"\n",
    "\n",
    "# Apply explicit format only to matching rows, leave others as missing for now.\n",
    "df.loc[mask_numeric, \"explicit_mdy\"] = pd.to_datetime(\n",
    "    df.loc[mask_numeric, \"raw_date\"], format=format_mdy, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Finally, display the DataFrame to compare automatic and explicit parsing results.\n",
    "print(\"\\nDataFrame with automatic and explicit parsed columns:\")\n",
    "print(df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b5ec8",
   "metadata": {},
   "source": [
    "### **3.3. Efficient Categorical Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd353ae6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Pandas (2.3.1) A-Z/Module_02/Lecture_B/image_03_03.jpg?v=1766709416\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Categorical dtypes store repeated labels more efficiently\n",
    ">* They reduce memory, speed analysis, clarify group structure\n",
    "\n",
    ">* Define categories and order to reflect meaning\n",
    ">* Catch unexpected or misspelled labels as errors\n",
    "\n",
    ">* Categorical columns improve grouping, summaries, and visuals\n",
    ">* They guide modeling choices and prevent misleading calculations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a28f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Efficient Categorical Types\n",
    "\n",
    "# Demonstrate converting text columns into efficient categorical types.\n",
    "# Show memory usage difference between object and categorical columns.\n",
    "# Show ordered categories enabling meaningful sorting for ordinal responses.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame with repeated text categories.\n",
    "data = {\n",
    "    \"payment_method\": [\"card\", \"cash\", \"card\", \"card\", \"cash\", \"check\", \"card\", \"cash\"],\n",
    "    \"satisfaction\": [\"very dissatisfied\", \"dissatisfied\", \"satisfied\", \"very satisfied\", \"neutral\", \"satisfied\", \"neutral\", \"very satisfied\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Show original dtypes and memory usage for the DataFrame.\n",
    "print(\"Original dtypes and memory usage:\")\n",
    "print(df.dtypes)\n",
    "print(\"Memory usage bytes:\", df.memory_usage(deep=True).sum())\n",
    "\n",
    "# Convert payment_method to categorical type for efficiency.\n",
    "df[\"payment_method_cat\"] = df[\"payment_method\"].astype(\"category\")\n",
    "\n",
    "# Define ordered categories for satisfaction, representing an ordinal scale.\n",
    "order = [\"very dissatisfied\", \"dissatisfied\", \"neutral\", \"satisfied\", \"very satisfied\"]\n",
    "\n",
    "df[\"satisfaction_cat\"] = pd.Categorical(df[\"satisfaction\"], categories=order, ordered=True)\n",
    "\n",
    "# Show new dtypes and memory usage after categorical conversion.\n",
    "print(\"\\nWith categorical columns dtypes and memory usage:\")\n",
    "print(df.dtypes)\n",
    "print(\"Memory usage bytes:\", df.memory_usage(deep=True).sum())\n",
    "\n",
    "# Sort by ordered satisfaction categories to show meaningful ordering.\n",
    "sorted_df = df.sort_values(\"satisfaction_cat\")\n",
    "\n",
    "print(\"\\nSorted by ordered satisfaction category:\")\n",
    "print(sorted_df[[\"satisfaction_cat\", \"payment_method_cat\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23b931",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Cleaning Columns**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4393df2",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Handle missing values in DataFrames using strategies such as dropping, filling, and interpolation with Pandas 2.3.1 methods. \n",
    "- Standardize text and categorical columns by trimming, case-normalizing, and mapping inconsistent labels. \n",
    "- Convert column dtypes to appropriate numeric, datetime, and categorical types to support accurate computations. \n",
    "\n",
    "In the next Module (Module 3), we will go over 'Transforming Data'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
