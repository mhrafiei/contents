{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f230c4da",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Functional API**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218327d",
   "metadata": {},
   "source": [
    ">Last update: 20260126.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Define Keras models using the Functional API with explicit Input and Output tensors. \n",
    "- Implement models with branching or skip connections using the Functional API graph structure. \n",
    "- Visualize and debug Functional models to ensure correct tensor shapes and connections. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350b43c",
   "metadata": {},
   "source": [
    "## **1. Functional Model Inputs Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439cbd9",
   "metadata": {},
   "source": [
    "### **1.1. Using Keras Input**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15c90f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_01_01.jpg?v=1769435324\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Define a symbolic Input describing data shape\n",
    ">* Explicit Input clarifies tensor flow and model expectations\n",
    "\n",
    ">* Input objects describe each example’s structure\n",
    ">* Clear shapes keep later layers compatible\n",
    "\n",
    ">* Explicit inputs anchor and clarify computation flow\n",
    ">* They ease shape reasoning, debugging, and collaboration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Using Keras Input\n",
    "\n",
    "# This script demonstrates Keras functional inputs.\n",
    "# It focuses on using the keras Input object.\n",
    "# Run cells sequentially to follow the explanation.\n",
    "\n",
    "# TensorFlow is available by default in Google Colab.\n",
    "# Uncomment the next line if running outside Colab.\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras functional utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Set a deterministic random seed for reproducibility.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print TensorFlow version in a single concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define the expected shape of one image example.\n",
    "image_height, image_width, channels = 28, 28, 1\n",
    "\n",
    "# Create an explicit Input tensor for grayscale images.\n",
    "inputs = tf.keras.Input(shape=(image_height, image_width, channels))\n",
    "\n",
    "# Confirm that the input tensor has the right shape.\n",
    "print(\"Input tensor shape:\", inputs.shape)\n",
    "\n",
    "# Add a small Conv2D layer on top of the input.\n",
    "x = layers.Conv2D(filters=8, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "\n",
    "# Downsample using MaxPooling to reduce spatial dimensions.\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Flatten the feature maps into a single vector.\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Add a Dense hidden layer for further processing.\n",
    "x = layers.Dense(units=16, activation=\"relu\")(x)\n",
    "\n",
    "# Create the final output layer with ten units.\n",
    "outputs = layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "\n",
    "# Build the functional model from inputs and outputs.\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"simple_functional_model\")\n",
    "\n",
    "# Display a short summary to inspect shapes.\n",
    "model.summary(expand_nested=False, show_trainable=True)\n",
    "\n",
    "# Create a small batch of dummy image data.\n",
    "dummy_batch = tf.random.uniform(shape=(4, image_height, image_width, channels))\n",
    "\n",
    "# Validate that the dummy batch shape matches the input.\n",
    "assert dummy_batch.shape[1:] == inputs.shape[1:], \"Shape mismatch detected.\"\n",
    "\n",
    "# Run a forward pass to obtain model predictions.\n",
    "predictions = model(dummy_batch, training=False)\n",
    "\n",
    "# Print the shapes of inputs and outputs for clarity.\n",
    "print(\"Dummy batch shape:\", dummy_batch.shape)\n",
    "print(\"Predictions shape:\", predictions.shape)\n",
    "\n",
    "# Show the first prediction vector to inspect output structure.\n",
    "print(\"First prediction vector:\", predictions[0].numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c255b3",
   "metadata": {},
   "source": [
    "### **1.2. Multiple Model Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b2463",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_01_02.jpg?v=1769435419\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Functional models can produce several outputs simultaneously\n",
    ">* Shared layers feed separate heads for different predictions\n",
    "\n",
    ">* One input can drive several related predictions\n",
    ">* Shared layers boost efficiency, specialization, and generalization\n",
    "\n",
    ">* Each output has its own targets, loss\n",
    ">* Named outputs control training, weighting, and supervision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ec0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Multiple Model Outputs\n",
    "\n",
    "# This script shows Keras functional multiple outputs.\n",
    "# It builds a tiny model with shared base layers.\n",
    "# It trains briefly and prints shapes and predictions.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Select device preference based on availability.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if physical_gpus:\n",
    "    device_type = \"GPU\"\n",
    "else:\n",
    "    device_type = \"CPU\"\n",
    "\n",
    "# Print which device type will likely be used.\n",
    "print(\"Using device type:\", device_type)\n",
    "\n",
    "# Define input shape for simple numeric features.\n",
    "input_dim = 8\n",
    "num_samples = 64\n",
    "num_classes = 3\n",
    "\n",
    "# Create random input data with correct shape.\n",
    "X = np.random.rand(num_samples, input_dim).astype(\"float32\")\n",
    "\n",
    "# Create classification labels as integers.\n",
    "class_labels = np.random.randint(num_classes, size=num_samples)\n",
    "\n",
    "# Create regression targets as continuous values.\n",
    "reg_targets = np.random.rand(num_samples, 1).astype(\"float32\")\n",
    "\n",
    "# One hot encode classification labels.\n",
    "class_targets = keras.utils.to_categorical(class_labels, num_classes)\n",
    "\n",
    "# Validate shapes before building the model.\n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Class target shape:\", class_targets.shape)\n",
    "print(\"Reg target shape:\", reg_targets.shape)\n",
    "\n",
    "# Define the functional model input tensor.\n",
    "inputs = keras.Input(shape=(input_dim,), name=\"features\")\n",
    "\n",
    "# Build a small shared dense representation.\n",
    "shared = layers.Dense(16, activation=\"relu\", name=\"shared_dense\")(inputs)\n",
    "\n",
    "# Add a second shared layer for richer features.\n",
    "shared = layers.Dense(8, activation=\"relu\", name=\"shared_dense_two\")(shared)\n",
    "\n",
    "# Define classification output head from shared features.\n",
    "class_output = layers.Dense(\n",
    "    num_classes,\n",
    "    activation=\"softmax\",\n",
    "    name=\"class_output\",\n",
    ")(shared)\n",
    "\n",
    "# Define regression output head from shared features.\n",
    "reg_output = layers.Dense(\n",
    "    1,\n",
    "    activation=\"linear\",\n",
    "    name=\"reg_output\",\n",
    ")(shared)\n",
    "\n",
    "# Create the functional model with two outputs.\n",
    "model = keras.Model(\n",
    "    inputs=inputs,\n",
    "    outputs=[class_output, reg_output],\n",
    "    name=\"multi_output_model\",\n",
    ")\n",
    "\n",
    "# Print a short summary using minimal lines.\n",
    "model.summary(print_fn=lambda x: None)\n",
    "print(\"Model outputs:\", [t.name for t in model.outputs])\n",
    "\n",
    "# Compile model with separate losses and metrics.\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"class_output\": \"categorical_crossentropy\", \"reg_output\": \"mse\"},\n",
    "    metrics={\"class_output\": \"accuracy\", \"reg_output\": \"mae\"},\n",
    ")\n",
    "\n",
    "# Train briefly with small epochs and silent logs.\n",
    "history = model.fit(\n",
    "    X,\n",
    "    {\"class_output\": class_targets, \"reg_output\": reg_targets},\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Evaluate model once to check both outputs.\n",
    "results = model.evaluate(\n",
    "    X,\n",
    "    {\"class_output\": class_targets, \"reg_output\": reg_targets},\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Print evaluation results in a compact way.\n",
    "print(\"Evaluation results:\", results)\n",
    "\n",
    "# Run prediction on a small batch of inputs.\n",
    "sample_inputs = X[:2]\n",
    "class_pred, reg_pred = model.predict(sample_inputs, verbose=0)\n",
    "\n",
    "# Print shapes of the two prediction outputs.\n",
    "print(\"Pred class shape:\", class_pred.shape)\n",
    "print(\"Pred reg shape:\", reg_pred.shape)\n",
    "\n",
    "# Print first sample predictions for both heads.\n",
    "print(\"First sample class probs:\", class_pred[0])\n",
    "print(\"First sample reg value:\", reg_pred[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d4238",
   "metadata": {},
   "source": [
    "### **1.3. Constructing Keras Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bc135",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_01_03.jpg?v=1769435458\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Imagine data flowing through layers as transformations\n",
    ">* Connect layers into a graph from input to output\n",
    "\n",
    ">* Map inputs through layers to final prediction\n",
    ">* Explicitly pair input and output tensors as model\n",
    "\n",
    ">* Same input-output pattern scales to any architecture\n",
    ">* Explicit mappings make models clearer, shareable, debuggable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Constructing Keras Models\n",
    "\n",
    "# This script shows Keras Functional API basics.\n",
    "# It focuses on explicit inputs and outputs.\n",
    "# Run cells sequentially inside Google Colab.\n",
    "\n",
    "# TensorFlow is available in this environment already.\n",
    "# Uncomment next line if running outside this notebook.\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define input shape for simple numeric features.\n",
    "num_features = 4\n",
    "\n",
    "# Create an explicit Input tensor for the model.\n",
    "inputs = keras.Input(shape=(num_features,), name=\"house_features\")\n",
    "\n",
    "# Add first Dense layer transforming the input tensor.\n",
    "x = layers.Dense(8, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Add second Dense layer for further feature mixing.\n",
    "x = layers.Dense(4, activation=\"relu\", name=\"dense_2\")(x)\n",
    "\n",
    "# Create final prediction layer producing one output value.\n",
    "outputs = layers.Dense(1, activation=\"linear\", name=\"price_output\")(x)\n",
    "\n",
    "# Build the Functional model from inputs and outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"price_model\")\n",
    "\n",
    "# Show a short model summary for debugging shapes.\n",
    "model.summary(expand_nested=False, show_trainable=True)\n",
    "\n",
    "# Create a tiny dummy dataset with correct feature shape.\n",
    "import numpy as np\n",
    "num_samples = 6\n",
    "\n",
    "# Generate small deterministic feature matrix.\n",
    "features = np.arange(num_samples * num_features, dtype=\"float32\")\n",
    "features = features.reshape((num_samples, num_features))\n",
    "\n",
    "# Generate simple target values as small float numbers.\n",
    "targets = np.linspace(100000.0, 160000.0, num_samples, dtype=\"float32\")\n",
    "\n",
    "# Validate that feature and target shapes are compatible.\n",
    "assert features.shape == (num_samples, num_features)\n",
    "assert targets.shape == (num_samples,)\n",
    "\n",
    "# Compile the model with mean squared error loss.\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Train briefly with silent verbose setting to avoid logs.\n",
    "history = model.fit(features, targets, epochs=5, batch_size=2, verbose=0)\n",
    "\n",
    "# Use the model to predict prices for the same features.\n",
    "predictions = model.predict(features, verbose=0)\n",
    "\n",
    "# Print shapes to confirm input and output tensor dimensions.\n",
    "print(\"Input shape:\", features.shape)\n",
    "print(\"Output shape:\", predictions.shape)\n",
    "\n",
    "# Print a few example predictions alongside true targets.\n",
    "for i in range(min(3, num_samples)):\n",
    "    print(\"Sample\", i, \"target:\", float(targets[i]), \"pred:\", float(predictions[i, 0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c076d1b",
   "metadata": {},
   "source": [
    "## **2. Functional Graph Connections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc336bbe",
   "metadata": {},
   "source": [
    "### **2.1. Calling Layers in Functional API**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f828eb",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_02_01.jpg?v=1769435498\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Layers act as functions transforming input tensors\n",
    ">* Graph view enables branches, merges, skip connections\n",
    "\n",
    ">* Layer calls show changing tensor shapes clearly\n",
    ">* Graph wiring supports complex, real-world workflows\n",
    "\n",
    ">* Layers on tensors enable flexible graph patterns\n",
    ">* Easily build shared, branched, and merged pathways\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfa65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Calling Layers in Functional API\n",
    "\n",
    "# This script shows Keras Functional API basics.\n",
    "# It focuses on calling layers like tensor functions.\n",
    "# We also build a small branching and skip model.\n",
    "\n",
    "# Install TensorFlow if needed in other environments.\n",
    "# pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Define input tensor for simple numeric features.\n",
    "inputs = tf.keras.Input(shape=(4,), name=\"numeric_input\")\n",
    "\n",
    "# Call a Dense layer on the input tensor.\n",
    "base = tf.keras.layers.Dense(\n",
    "    8, activation=\"relu\", name=\"base_dense\"\n",
    ")(inputs)\n",
    "\n",
    "# Branch one processes base features for task A.\n",
    "branch_a = tf.keras.layers.Dense(\n",
    "    4, activation=\"relu\", name=\"branch_a_dense\"\n",
    ")(base)\n",
    "\n",
    "# Branch two processes base features for task B.\n",
    "branch_b = tf.keras.layers.Dense(\n",
    "    4, activation=\"relu\", name=\"branch_b_dense\"\n",
    ")(base)\n",
    "\n",
    "# Create a skip connection from input to merge point.\n",
    "skip = tf.keras.layers.Dense(\n",
    "    4, activation=\"linear\", name=\"skip_from_input\"\n",
    ")(inputs)\n",
    "\n",
    "# Concatenate both branches and the skip tensor.\n",
    "merged = tf.keras.layers.Concatenate(name=\"merge_branches\")(\n",
    "    [branch_a, branch_b, skip]\n",
    ")\n",
    "\n",
    "# Add a shared layer called on merged tensor.\n",
    "shared = tf.keras.layers.Dense(\n",
    "    6, activation=\"relu\", name=\"shared_dense\"\n",
    ")(merged)\n",
    "\n",
    "# Output for main prediction task.\n",
    "output_main = tf.keras.layers.Dense(\n",
    "    1, activation=\"sigmoid\", name=\"main_output\"\n",
    ")(shared)\n",
    "\n",
    "# Output for auxiliary prediction task.\n",
    "output_aux = tf.keras.layers.Dense(\n",
    "    1, activation=\"sigmoid\", name=\"aux_output\"\n",
    ")(branch_b)\n",
    "\n",
    "# Build the Functional model from inputs and outputs.\n",
    "model = tf.keras.Model(\n",
    "    inputs=inputs, outputs=[output_main, output_aux], name=\"branch_skip_model\"\n",
    ")\n",
    "\n",
    "# Show a short summary to inspect graph shapes.\n",
    "model.summary(line_length=80, expand_nested=False)\n",
    "\n",
    "# Create a tiny batch of dummy numeric data.\n",
    "x_sample = tf.ones(shape=(3, 4), dtype=tf.float32)\n",
    "\n",
    "# Validate input shape before calling the model.\n",
    "assert x_sample.shape[1] == 4\n",
    "\n",
    "# Call the model on the sample to get predictions.\n",
    "y_main_pred, y_aux_pred = model(x_sample, training=False)\n",
    "\n",
    "# Print shapes to see how tensors flowed.\n",
    "print(\"Input shape:\", x_sample.shape)\n",
    "\n",
    "# Print main output tensor shape.\n",
    "print(\"Main output shape:\", y_main_pred.shape)\n",
    "\n",
    "# Print auxiliary output tensor shape.\n",
    "print(\"Aux output shape:\", y_aux_pred.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a33030",
   "metadata": {},
   "source": [
    "### **2.2. Merging Add and Concatenate**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822f8eb",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_02_02.jpg?v=1769435534\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Addition blends same-shaped branches elementwise into one\n",
    ">* Concatenation stacks features, expanding dimensions and capacity\n",
    "\n",
    ">* Addition sums same-shaped feature maps, enforcing consensus\n",
    ">* Best for residual refinements; preserves shape, blends sources\n",
    "\n",
    ">* Concatenation keeps branch features separate for later mixing\n",
    ">* It enlarges representations, increasing parameters and computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60507c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Merging Add and Concatenate\n",
    "\n",
    "# This script shows Keras functional merging operations.\n",
    "# We compare Add and Concatenate on simple branches.\n",
    "# Focus on shapes and connections not training performance.\n",
    "\n",
    "# Install TensorFlow if missing in some environments.\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras functional utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a small input tensor for dense features.\n",
    "inputs = keras.Input(shape=(4,), name=\"numeric_input\")\n",
    "\n",
    "# Build first branch with one Dense layer.\n",
    "branch_one = layers.Dense(3, activation=\"relu\", name=\"b1_dense\")(\n",
    "    inputs\n",
    ")\n",
    "\n",
    "# Build second branch with different Dense layer.\n",
    "branch_two = layers.Dense(3, activation=\"relu\", name=\"b2_dense\")(\n",
    "    inputs\n",
    ")\n",
    "\n",
    "# Confirm both branch output shapes are identical.\n",
    "print(\"Branch one shape:\", branch_one.shape)\n",
    "print(\"Branch two shape:\", branch_two.shape)\n",
    "\n",
    "# Merge branches using elementwise Add layer.\n",
    "added = layers.Add(name=\"merge_add\")([\n",
    "    branch_one,\n",
    "    branch_two,\n",
    "])\n",
    "\n",
    "# Merge branches using feature Concatenate layer.\n",
    "concatenated = layers.Concatenate(name=\"merge_concat\")([\n",
    "    branch_one,\n",
    "    branch_two,\n",
    "])\n",
    "\n",
    "# Show shapes after Add and Concatenate merges.\n",
    "print(\"Added merge shape:\", added.shape)\n",
    "print(\"Concatenated merge shape:\", concatenated.shape)\n",
    "\n",
    "# Build model that outputs both merged tensors.\n",
    "model = keras.Model(\n",
    "    inputs=inputs,\n",
    "    outputs=[added, concatenated],\n",
    "    name=\"add_vs_concat_model\",\n",
    ")\n",
    "\n",
    "# Display a concise model summary for debugging.\n",
    "model.summary(line_length=80, expand_nested=False)\n",
    "\n",
    "# Create a tiny batch of example numeric data.\n",
    "example_batch = tf.constant(\n",
    "    [[1.0, 2.0, 3.0, 4.0], [0.5, 0.5, 0.5, 0.5]],\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "\n",
    "# Run the model once to get both outputs.\n",
    "added_out, concat_out = model(example_batch)\n",
    "\n",
    "# Print small slices to compare values and shapes.\n",
    "print(\"Added output sample:\", added_out[0].numpy())\n",
    "print(\"Concat output sample:\", concat_out[0].numpy())\n",
    "\n",
    "# Final print to emphasize dimensionality difference.\n",
    "print(\"Final shapes -> add:\", added_out.shape, \"concat:\", concat_out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8867b3",
   "metadata": {},
   "source": [
    "### **2.3. Designing Skip Connections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b8201",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_02_03.jpg?v=1769435574\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Skip connections bypass layers to preserve information, gradients\n",
    ">* Functional API wires earlier tensors directly into later operations\n",
    "\n",
    ">* Plan what to skip and how to merge\n",
    ">* Match tensor shapes and wire skips explicitly\n",
    "\n",
    ">* Skip connections enable multi-scale models across domains\n",
    ">* Functional API makes experimenting with skip patterns easy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e30b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Designing Skip Connections\n",
    "\n",
    "# This script shows Keras functional skip connections.\n",
    "# It builds and inspects a simple residual style model.\n",
    "# Focus on shapes and graph style tensor wiring.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required modules from TensorFlow.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "import numpy as np\n",
    "import random as py_random\n",
    "np.random.seed(7)\n",
    "py_random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a small input shape for demonstration.\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Create an Input tensor for the functional model.\n",
    "inputs = keras.Input(shape=input_shape, name=\"image_input\")\n",
    "\n",
    "# Apply a first convolution block on the input.\n",
    "x = layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "\n",
    "# Store this tensor as the skip connection source.\n",
    "skip_tensor = x\n",
    "\n",
    "# Add a second convolution block for deeper features.\n",
    "x = layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "# Ensure shapes match before adding the skip connection.\n",
    "if skip_tensor.shape != x.shape:\n",
    "    raise ValueError(\"Skip and main tensors must share shape.\")\n",
    "\n",
    "# Merge skip and main path using elementwise addition.\n",
    "merged = layers.Add(name=\"skip_add\")([skip_tensor, x])\n",
    "\n",
    "# Continue with pooling and flattening after merge.\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(merged)\n",
    "\n",
    "# Flatten spatial dimensions into a feature vector.\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Add a small dense layer for classification.\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"class_output\")(x)\n",
    "\n",
    "# Build the functional model from inputs and outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"skip_demo_model\")\n",
    "\n",
    "# Display a concise model summary for shape inspection.\n",
    "model.summary(line_length=80, expand_nested=False)\n",
    "\n",
    "# Create a tiny batch of random images for testing.\n",
    "sample_batch = np.random.rand(4, 28, 28, 1).astype(\"float32\")\n",
    "\n",
    "# Run a forward pass to verify output shape.\n",
    "preds = model(sample_batch, training=False)\n",
    "\n",
    "# Print key tensor shapes to highlight skip behavior.\n",
    "print(\"Input batch shape:\", sample_batch.shape)\n",
    "print(\"Skip tensor shape:\", skip_tensor.shape)\n",
    "print(\"Merged tensor shape:\", merged.shape)\n",
    "print(\"Output batch shape:\", preds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42640cd3",
   "metadata": {},
   "source": [
    "## **3. Inspecting Functional Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881f018",
   "metadata": {},
   "source": [
    "### **3.1. Reading Model Summaries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb58c33",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_03_01.jpg?v=1769435609\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Model summary shows data flow through layers\n",
    ">* Trace branches and merges to verify architecture\n",
    "\n",
    ">* Track how tensor shapes change between layers\n",
    ">* Use shape patterns to spot errors quickly\n",
    "\n",
    ">* Use summaries to track complex layer connections\n",
    ">* Check merges and skips to avoid subtle bugs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Reading Model Summaries\n",
    "\n",
    "# This script shows how to read model summaries.\n",
    "# It uses a small Functional API example model.\n",
    "# Focus on shapes and connections in the summary.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Define an image input for a tiny branch.\n",
    "image_input = keras.Input(shape=(8, 8, 1), name=\"image_input\")\n",
    "\n",
    "# Define a tabular input for a second branch.\n",
    "tabular_input = keras.Input(shape=(4,), name=\"tabular_input\")\n",
    "\n",
    "# Build a small convolutional block for images.\n",
    "x = layers.Conv2D(4, (3, 3), activation=\"relu\")(image_input)\n",
    "\n",
    "# Flatten image features to a vector.\n",
    "x = layers.Flatten(name=\"image_flatten\")(x)\n",
    "\n",
    "# Build a dense block for tabular data.\n",
    "y = layers.Dense(8, activation=\"relu\", name=\"tabular_dense\")(tabular_input)\n",
    "\n",
    "# Add a skip connection on the tabular branch.\n",
    "skip = layers.Dense(8, activation=\"relu\", name=\"tabular_skip\")(tabular_input)\n",
    "\n",
    "# Concatenate main and skip tabular features.\n",
    "y = layers.Concatenate(name=\"tabular_concat\")([y, skip])\n",
    "\n",
    "# Merge image and tabular branches together.\n",
    "merged = layers.Concatenate(name=\"fusion_concat\")([x, y])\n",
    "\n",
    "# Add a small hidden layer after fusion.\n",
    "hidden = layers.Dense(16, activation=\"relu\", name=\"fusion_dense\")(merged)\n",
    "\n",
    "# Define a final classification output layer.\n",
    "output = layers.Dense(3, activation=\"softmax\", name=\"class_output\")(hidden)\n",
    "\n",
    "# Create the Functional model from inputs and output.\n",
    "model = keras.Model(inputs=[image_input, tabular_input], outputs=output)\n",
    "\n",
    "# Print a compact model summary for inspection.\n",
    "model.summary(line_length=80, expand_nested=False)\n",
    "\n",
    "# Show the model inputs and outputs shapes clearly.\n",
    "print(\"Inputs:\", [inp.shape for inp in model.inputs])\n",
    "print(\"Output:\", model.output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a59ed9",
   "metadata": {},
   "source": [
    "### **3.2. Visualizing Model Graphs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1e374",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_03_02.jpg?v=1769435638\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Graph diagrams show layers and tensor flow clearly\n",
    ">* They reveal branches, merges, and overall architecture\n",
    "\n",
    ">* Graphs clarify branching, merging, and skip connections\n",
    ">* They help catch missing, misaligned, or wrong branches\n",
    "\n",
    ">* Graphs show tensor shapes and layer compatibility\n",
    ">* They pinpoint shape errors and guide architecture fixes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93188b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Visualizing Model Graphs\n",
    "\n",
    "# This script shows Keras functional model visualization.\n",
    "# It focuses on graph structure and tensor shapes.\n",
    "# Run cells in order to follow the explanation.\n",
    "\n",
    "# Optional install for specific TensorFlow version in Colab.\n",
    "# !pip install -q tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Print TensorFlow version for reproducibility.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set random seeds for deterministic behavior.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Define input for image like data.\n",
    "image_input = keras.Input(shape=(28, 28, 1), name=\"image_input\")\n",
    "\n",
    "# Define a small convolution block.\n",
    "x = layers.Conv2D(8, (3, 3), activation=\"relu\")(image_input)\n",
    "\n",
    "# Add max pooling to reduce spatial size.\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Add another convolution layer for depth.\n",
    "x = layers.Conv2D(16, (3, 3), activation=\"relu\")(x)\n",
    "\n",
    "# Flatten features for dense layers.\n",
    "flat_features = layers.Flatten(name=\"flat_features\")(x)\n",
    "\n",
    "# Define a second input branch for numeric data.\n",
    "meta_input = keras.Input(shape=(4,), name=\"meta_input\")\n",
    "\n",
    "# Process metadata with a dense layer.\n",
    "meta_features = layers.Dense(8, activation=\"relu\")(meta_input)\n",
    "\n",
    "# Concatenate image and metadata features.\n",
    "merged = layers.Concatenate(name=\"merge_features\")(\n",
    "    [flat_features, meta_features]\n",
    ")\n",
    "\n",
    "# Add a dense layer after merging.\n",
    "hidden = layers.Dense(16, activation=\"relu\")(merged)\n",
    "\n",
    "# Define output for binary classification.\n",
    "output = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(hidden)\n",
    "\n",
    "# Build the functional model from inputs and outputs.\n",
    "model = keras.Model(inputs=[image_input, meta_input], outputs=output)\n",
    "\n",
    "# Print a short summary to inspect shapes.\n",
    "model.summary(line_length=80, expand_nested=False)\n",
    "\n",
    "# Visualize model graph to a PNG file.\n",
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"functional_model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    ")\n",
    "\n",
    "# Confirm that the plot file was created successfully.\n",
    "import os\n",
    "print(\"Plot file exists:\", os.path.exists(\"functional_model.png\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6183e7",
   "metadata": {},
   "source": [
    "### **3.3. Debugging shape mismatches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46a332",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_03/Lecture_B/image_03_03.jpg?v=1769435694\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Shape mismatches happen when tensor dimensions disagree\n",
    ">* Trace one example’s shape through layers to debug\n",
    "\n",
    ">* Compare expected and actual tensor shapes around errors\n",
    ">* Align shapes with pooling, projections, or reshaping\n",
    "\n",
    ">* Describe each tensor’s meaning and expected shape\n",
    ">* Use tiny test inputs to locate mismatches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Debugging shape mismatches\n",
    "\n",
    "# This script shows debugging shape mismatches.\n",
    "# It uses Keras Functional API with tensors.\n",
    "# Focus on inspecting shapes and fixing errors.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define an image input tensor.\n",
    "image_input = keras.Input(shape=(28, 28, 1), name=\"image_input\")\n",
    "\n",
    "# Apply a small convolution block.\n",
    "x = layers.Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")(image_input)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Intentionally create a mismatched skip tensor.\n",
    "skip = layers.Conv2D(8, (1, 1), activation=\"relu\")(image_input)\n",
    "\n",
    "# Show shapes before the faulty addition.\n",
    "print(\"Main branch shape:\", x.shape)\n",
    "print(\"Skip branch shape:\", skip.shape)\n",
    "\n",
    "# Demonstrate what a bad Add would receive.\n",
    "print(\"Attempting Add would need equal shapes.\")\n",
    "\n",
    "# Fix mismatch by downsampling the skip path.\n",
    "fixed_skip = layers.MaxPooling2D(pool_size=(2, 2))(skip)\n",
    "\n",
    "# Confirm shapes now match for addition.\n",
    "print(\"Fixed skip shape:\", fixed_skip.shape)\n",
    "\n",
    "# Safely add tensors with matching shapes.\n",
    "added = layers.Add()([x, fixed_skip])\n",
    "\n",
    "# Flatten and add a small Dense head.\n",
    "flat = layers.Flatten()(added)\n",
    "output = layers.Dense(10, activation=\"softmax\", name=\"class_output\")(flat)\n",
    "\n",
    "# Build the Functional model object.\n",
    "model = keras.Model(inputs=image_input, outputs=output, name=\"debug_model\")\n",
    "\n",
    "# Print a concise summary to inspect shapes.\n",
    "model.summary(expand_nested=False, show_trainable=True)\n",
    "\n",
    "# Create tiny synthetic image data.\n",
    "sample_images = np.random.rand(4, 28, 28, 1).astype(\"float32\")\n",
    "\n",
    "# Run a forward pass to verify everything.\n",
    "preds = model(sample_images, training=False)\n",
    "\n",
    "# Print final prediction shape for confirmation.\n",
    "print(\"Prediction batch shape:\", preds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec4580",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Functional API**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fd632",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Define Keras models using the Functional API with explicit Input and Output tensors. \n",
    "- Implement models with branching or skip connections using the Functional API graph structure. \n",
    "- Visualize and debug Functional models to ensure correct tensor shapes and connections. \n",
    "\n",
    "In the next Module (Module 4), we will go over 'Training Workflows'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
