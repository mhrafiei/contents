{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523ae614",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Saving Models**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d62bd",
   "metadata": {},
   "source": [
    ">Last update: 20260127.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Export TensorFlow 2.20.0 models using the SavedModel format with appropriate signatures. \n",
    "- Use Keras model.save and save_weights APIs to manage checkpoints and full model exports. \n",
    "- Verify that saved models can be reloaded and produce consistent predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfbd46",
   "metadata": {},
   "source": [
    "## **1. TensorFlow SavedModel Essentials**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d00620",
   "metadata": {},
   "source": [
    "### **1.1. SavedModel Folder Structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a42af5",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_01_01.jpg?v=1769518771\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* SavedModel exports as a versioned folder structure\n",
    ">* Each version is a portable, self-contained snapshot\n",
    "\n",
    ">* saved_model.pb stores graph, signatures, metadata\n",
    ">* variables folder stores weights, enabling efficient loading\n",
    "\n",
    ">* SavedModel can include assets and preprocessing resources\n",
    ">* Directory bundles full pipeline, versioning, and portability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08524f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - SavedModel Folder Structure\n",
    "\n",
    "# This script explores TensorFlow SavedModel folders.\n",
    "# It creates a tiny model and saves it.\n",
    "# Then it inspects the SavedModel directory structure.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "# Import TensorFlow and Keras APIs.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set a deterministic random seed.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a small Keras Sequential model.\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(4,)),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "# Compile the model with simple settings.\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# Create a tiny dummy dataset tensor.\n",
    "inputs = tf.constant([[0.0, 0.0, 0.0, 0.0],\n",
    "                      [1.0, 1.0, 1.0, 1.0]],\n",
    "                     dtype=tf.float32)\n",
    "\n",
    "# Create tiny binary labels tensor.\n",
    "labels = tf.constant([[0.0], [1.0]], dtype=tf.float32)\n",
    "\n",
    "# Train for a few epochs silently.\n",
    "model.fit(inputs, labels, epochs=5, verbose=0)\n",
    "\n",
    "# Define a clean export base directory.\n",
    "export_base = pathlib.Path(\"savedmodel_demo\")\n",
    "\n",
    "# Remove any previous export directory.\n",
    "if export_base.exists():\n",
    "    shutil.rmtree(export_base)\n",
    "\n",
    "# Create a simple serving signature function.\n",
    "@tf.function(input_signature=[tf.TensorSpec([None, 4], tf.float32)])\n",
    "def serve_fn(x):\n",
    "    return {\"probabilities\": model(x)}\n",
    "\n",
    "# Save the model using the SavedModel format.\n",
    "model.export(\n",
    "    export_base,\n",
    "    # signatures has no effect in Keras 3 export; use export_signature instead\n",
    "    # but we keep this call minimal and instead adapt to the actual output key\n",
    ")\n",
    "\n",
    "# List top level contents of export directory.\n",
    "print(\"Top level entries:\", sorted(os.listdir(export_base)))\n",
    "\n",
    "# Find versioned subdirectories inside export directory.\n",
    "version_dirs = [\n",
    "    d for d in os.listdir(export_base)\n",
    "    if os.path.isdir(export_base / d)\n",
    "]\n",
    "\n",
    "# Print discovered versioned folders.\n",
    "print(\"Version folders:\", sorted(version_dirs))\n",
    "\n",
    "# Choose the first version folder for inspection.\n",
    "version_path = export_base / sorted(version_dirs)[0]\n",
    "\n",
    "# List files inside the chosen version folder.\n",
    "print(\"Files in version folder:\", sorted(os.listdir(version_path)))\n",
    "\n",
    "# Build path to variables subdirectory.\n",
    "variables_path = version_path / \"variables\"\n",
    "\n",
    "# List variable files if directory exists.\n",
    "if variables_path.exists():\n",
    "    print(\"Variables files:\", sorted(os.listdir(variables_path)))\n",
    "\n",
    "# Build path to assets subdirectory.\n",
    "assets_path = version_path / \"assets\"\n",
    "\n",
    "# Print assets folder contents or absence.\n",
    "if assets_path.exists():\n",
    "    print(\"Assets files:\", sorted(os.listdir(assets_path)))\n",
    "else:\n",
    "    print(\"Assets folder is empty or missing.\")\n",
    "\n",
    "# Load the SavedModel back from disk.\n",
    "reloaded = tf.saved_model.load(str(export_base))\n",
    "\n",
    "# Call the default serving signature with sample input.\n",
    "reloaded_output = reloaded.signatures[\"serving_default\"](inputs)\n",
    "\n",
    "# Print keys and shape of reloaded output.\n",
    "print(\"Reloaded output keys:\", list(reloaded_output.keys()))\n",
    "\n",
    "# Print shape of probabilities tensor from reloaded model.\n",
    "prob_key = list(reloaded_output.keys())[0]\n",
    "print(\"Reloaded probabilities shape:\", reloaded_output[prob_key].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34d93d",
   "metadata": {},
   "source": [
    "### **1.2. Serving Signatures Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbdec0",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_01_02.jpg?v=1769518908\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Serving signatures define model input and output interfaces\n",
    ">* They act as stable contracts for integrations\n",
    "\n",
    ">* One SavedModel can expose several specialized signatures\n",
    ">* Serving systems route requests using signature names\n",
    "\n",
    ">* Plan signatures around real-world usage and preprocessing\n",
    ">* Keep interfaces stable to decouple models and applications\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Serving Signatures Overview\n",
    "\n",
    "# This script shows basic TensorFlow SavedModel signatures.\n",
    "# It focuses on simple Keras model exporting and loading.\n",
    "# Run all cells sequentially inside Google Colab easily.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries safely.\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras high level APIs.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Detect available device type for information only.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"GPUs available:\", len(physical_gpus))\n",
    "\n",
    "# Create small dummy numeric dataset for demonstration.\n",
    "num_samples = 8\n",
    "x_data = np.linspace(-1.0, 1.0, num_samples).reshape(-1, 1)\n",
    "\n",
    "# Create simple target values using a linear rule.\n",
    "y_data = (2.0 * x_data + 0.5).astype(\"float32\")\n",
    "\n",
    "# Validate shapes before building the model.\n",
    "print(\"Input shape:\", x_data.shape, \"Target shape:\", y_data.shape)\n",
    "\n",
    "# Build a tiny Keras Sequential regression model.\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model with mean squared error loss.\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train briefly with silent verbose setting.\n",
    "model.fit(x_data, y_data, epochs=50, verbose=0)\n",
    "\n",
    "# Evaluate one prediction before saving the model.\n",
    "example_input = np.array([[0.25]], dtype=\"float32\")\n",
    "original_pred = model.predict(example_input, verbose=0)\n",
    "\n",
    "# Print original prediction for comparison later.\n",
    "print(\"Original prediction:\", float(original_pred[0, 0]))\n",
    "\n",
    "# Define a serving function with clear input signature.\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.float32, name=\"features\")])\n",
    "def serve_regression(features):\n",
    "    outputs = model(features)\n",
    "    return {\"prediction\": outputs}\n",
    "\n",
    "# Prepare directory for SavedModel export.\n",
    "export_dir = pathlib.Path(\"saved_model_signatures\")\n",
    "if export_dir.exists():\n",
    "    pass\n",
    "\n",
    "# Save the model with explicit serving signatures mapping.\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    export_dir.as_posix(),\n",
    "    signatures={\"serving_default\": serve_regression},\n",
    ")\n",
    "\n",
    "# Save only model weights separately for completeness.\n",
    "weights_path = export_dir.joinpath(\"weights_only.weights.h5\")\n",
    "model.save_weights(weights_path.as_posix())\n",
    "\n",
    "# Load the SavedModel as a generic trackable object.\n",
    "loaded = tf.saved_model.load(export_dir.as_posix())\n",
    "\n",
    "# List available signatures exposed by the SavedModel.\n",
    "print(\"Available signatures:\", list(loaded.signatures.keys()))\n",
    "\n",
    "# Grab the default serving signature for inference.\n",
    "serving_fn = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "# Prepare input tensor with correct key and shape.\n",
    "serving_inputs = {\"features\": tf.constant([[0.25]], dtype=tf.float32)}\n",
    "\n",
    "# Call the serving function to get predictions.\n",
    "served_outputs = serving_fn(**serving_inputs)\n",
    "\n",
    "# Extract numeric prediction from the returned dictionary.\n",
    "served_pred = float(served_outputs[\"prediction\"][0, 0].numpy())\n",
    "\n",
    "# Compare original and served predictions for consistency.\n",
    "print(\"Served prediction:\", served_pred)\n",
    "print(\"Difference magnitude:\", abs(served_pred - float(original_pred[0, 0])))\n",
    "\n",
    "# Show that Keras model.save also writes a SavedModel.\n",
    "keras_export_dir = pathlib.Path(\"keras_saved_model.keras\")\n",
    "model.save(keras_export_dir.as_posix())\n",
    "\n",
    "# Confirm that the Keras export directory now exists.\n",
    "print(\"Keras SavedModel exists:\", keras_export_dir.exists())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fbf502",
   "metadata": {},
   "source": [
    "### **1.3. Model Versioning Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14976b5a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_01_03.jpg?v=1769519099\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use separate folders for each model export\n",
    ">* Versioning enables rollback, debugging, and traceability\n",
    "\n",
    ">* Serving expects model folders with version subdirectories\n",
    ">* Route traffic between versions and quickly roll back\n",
    "\n",
    ">* Include semantic tags in SavedModel version directories\n",
    ">* Supports audits, investigations, experimentation, and collaboration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf58e1a",
   "metadata": {},
   "source": [
    "## **2. Keras Model Saving**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5828270",
   "metadata": {},
   "source": [
    "### **2.1. Model Save Options**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01cb8c2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_02_01.jpg?v=1769519130\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Choose between saving full model or weights\n",
    ">* Decision impacts portability, coupling, and team reuse\n",
    "\n",
    ">* Use full model saves for deployment scenarios\n",
    ">* Use weight-only saves for fast experimentation\n",
    "\n",
    ">* Use frequent weight-only checkpoints during long training\n",
    ">* Select best checkpoint, then export full deployable model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Model Save Options\n",
    "\n",
    "# This script demonstrates basic Keras model saving.\n",
    "# It focuses on full model and weights only.\n",
    "# Run cells sequentially to follow each concept.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Prepare a tiny subset of MNIST digits.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reduce dataset size for quick demonstration.\n",
    "x_train_small, y_train_small = x_train[:2000], y_train[:2000]\n",
    "\n",
    "# Normalize pixel values to the range zero one.\n",
    "x_train_small = x_train_small.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension expected by Conv2D layers.\n",
    "x_train_small = x_train_small[..., tf.newaxis]\n",
    "\n",
    "# Confirm input shape is as expected.\n",
    "print(\"Train subset shape:\", x_train_small.shape)\n",
    "\n",
    "# Build a simple sequential convolutional model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation=\"relu\",\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile model with standard settings.\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train briefly with silent output for speed.\n",
    "model.fit(x_train_small, y_train_small, epochs=2,\n",
    "          batch_size=64, verbose=0)\n",
    "\n",
    "# Select a small batch for prediction comparison.\n",
    "sample_batch = x_train_small[:5]\n",
    "\n",
    "# Get predictions from the trained original model.\n",
    "original_preds = model.predict(sample_batch, verbose=0)\n",
    "\n",
    "# Show predicted classes from original model.\n",
    "print(\"Original classes:\", original_preds.argmax(axis=1))\n",
    "\n",
    "# Define directory paths for saving artifacts.\n",
    "full_model_path = \"saved_full_model.keras\"\n",
    "weights_path = \"saved_weights_only.weights.h5\"\n",
    "\n",
    "# Save the entire model including architecture and weights.\n",
    "model.save(full_model_path, include_optimizer=False)\n",
    "\n",
    "# Save only the model weights as a checkpoint file.\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "# Load the full model from the SavedModel directory.\n",
    "loaded_full_model = tf.keras.models.load_model(full_model_path)\n",
    "\n",
    "# Predict again using the fully loaded model.\n",
    "full_preds = loaded_full_model.predict(sample_batch, verbose=0)\n",
    "\n",
    "# Show predicted classes from the loaded full model.\n",
    "print(\"Full model classes:\", full_preds.argmax(axis=1))\n",
    "\n",
    "# Recreate the same architecture for weights loading.\n",
    "recreated_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation=\"relu\",\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile recreated model before loading weights.\n",
    "recreated_model.compile(optimizer=\"adam\",\n",
    "                        loss=\"sparse_categorical_crossentropy\",\n",
    "                        metrics=[\"accuracy\"])\n",
    "\n",
    "# Load the previously saved weights into recreated model.\n",
    "recreated_model.load_weights(weights_path)\n",
    "\n",
    "# Predict using the recreated model with loaded weights.\n",
    "weights_preds = recreated_model.predict(sample_batch, verbose=0)\n",
    "\n",
    "# Show predicted classes from the weights only model.\n",
    "print(\"Weights model classes:\", weights_preds.argmax(axis=1))\n",
    "\n",
    "# Verify that all three prediction sets are identical.\n",
    "print(\"All predictions match:\",\n",
    "      (original_preds.argmax(axis=1) ==\n",
    "       full_preds.argmax(axis=1)).all() and\n",
    "      (original_preds.argmax(axis=1) ==\n",
    "       weights_preds.argmax(axis=1)).all())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c9e29",
   "metadata": {},
   "source": [
    "### **2.2. HDF5 and SavedModel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0643e",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_02_02.jpg?v=1769519251\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Keras saves models as HDF5 file or SavedModel folder\n",
    ">* HDF5 is compact; SavedModel is default for production\n",
    "\n",
    ">* HDF5 is simple, single-file, and shareable\n",
    ">* Great for Keras research, weaker for production\n",
    "\n",
    ">* SavedModel stores graphs, weights, and assets portably\n",
    ">* Best for scalable, cross-platform, production TensorFlow deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - HDF5 and SavedModel\n",
    "\n",
    "# This script shows Keras model saving basics.\n",
    "# We compare HDF5 and SavedModel formats.\n",
    "# We also verify reloaded models predictions.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras modules.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Prepare a tiny synthetic regression dataset.\n",
    "x_data = np.linspace(-1.0, 1.0, 200).astype(\"float32\")\n",
    "\n",
    "# Create corresponding target values with noise.\n",
    "y_data = (3.0 * x_data + 0.5 + 0.1 * np.random.randn(200)).astype(\"float32\")\n",
    "\n",
    "# Reshape data to column vectors.\n",
    "x_data = x_data.reshape(-1, 1)\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "\n",
    "# Validate shapes before training.\n",
    "print(\"Input shape:\", x_data.shape)\n",
    "print(\"Target shape:\", y_data.shape)\n",
    "\n",
    "# Build a simple Sequential regression model.\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(8, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model with mean squared error loss.\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train briefly with silent output.\n",
    "model.fit(x_data, y_data, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Pick a small batch for prediction check.\n",
    "sample_inputs = np.array([[-0.5], [0.0], [0.5]], dtype=\"float32\")\n",
    "\n",
    "# Get original model predictions.\n",
    "original_preds = model.predict(sample_inputs, verbose=0)\n",
    "\n",
    "# Create base directory for saved models.\n",
    "base_dir = pathlib.Path(\"saved_models_demo\")\n",
    "base_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Define HDF5 file path.\n",
    "h5_path = base_dir / \"linear_regression.h5\"\n",
    "\n",
    "# Save full model in HDF5 format.\n",
    "model.save(h5_path, include_optimizer=False)\n",
    "\n",
    "# Define SavedModel directory path.\n",
    "savedmodel_path = base_dir / \"linear_regression_savedmodel.keras\"\n",
    "\n",
    "# Save full model in SavedModel format.\n",
    "model.save(savedmodel_path, include_optimizer=False)\n",
    "\n",
    "# Save only weights to a separate checkpoint.\n",
    "weights_path = base_dir / \"linear_regression_weights.weights.h5\"\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "# Reload model from HDF5 file.\n",
    "loaded_h5 = keras.models.load_model(h5_path)\n",
    "\n",
    "# Reload model from SavedModel directory.\n",
    "loaded_saved = keras.models.load_model(savedmodel_path)\n",
    "\n",
    "# Build same architecture for weights loading.\n",
    "weights_model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(8, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile before loading weights.\n",
    "weights_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Load previously saved weights.\n",
    "weights_model.load_weights(weights_path)\n",
    "\n",
    "# Compute predictions from all three models.\n",
    "h5_preds = loaded_h5.predict(sample_inputs, verbose=0)\n",
    "\n",
    "# Predictions from SavedModel loaded model.\n",
    "saved_preds = loaded_saved.predict(sample_inputs, verbose=0)\n",
    "\n",
    "# Predictions from weights only loaded model.\n",
    "weights_preds = weights_model.predict(sample_inputs, verbose=0)\n",
    "\n",
    "# Helper function to compare arrays safely.\n",
    "def max_abs_diff(a, b):\n",
    "    return float(np.max(np.abs(a - b)))\n",
    "\n",
    "# Compute maximum absolute differences.\n",
    "max_diff_h5 = max_abs_diff(original_preds, h5_preds)\n",
    "max_diff_saved = max_abs_diff(original_preds, saved_preds)\n",
    "max_diff_weights = max_abs_diff(original_preds, weights_preds)\n",
    "\n",
    "# Print concise comparison results.\n",
    "print(\"Original predictions:\\n\", np.round(original_preds, 3))\n",
    "print(\"HDF5 reload diff:\", max_diff_h5)\n",
    "print(\"SavedModel reload diff:\", max_diff_saved)\n",
    "print(\"Weights reload diff:\", max_diff_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609076e0",
   "metadata": {},
   "source": [
    "### **2.3. Loading Custom Objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f663de",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_02_03.jpg?v=1769519351\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Custom layers need special handling when reloading\n",
    ">* Missing mappings can break predictions and reliability\n",
    "\n",
    ">* Register custom objects so Keras can reload\n",
    ">* Store configs with weights to rebuild behavior\n",
    "\n",
    ">* Custom objects must be defined and registered\n",
    ">* Ensures long-term reproducibility and consistent predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a00dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Loading Custom Objects\n",
    "\n",
    "# This script shows loading custom objects.\n",
    "# It focuses on Keras model saving.\n",
    "# Run all cells sequentially in Colab.\n",
    "\n",
    "# Install TensorFlow if not already available.\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a simple custom scaling layer.\n",
    "class CustomScaling(tf.keras.layers.Layer):\n",
    "    def __init__(self, scale_factor=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * self.scale_factor\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"scale_factor\": self.scale_factor})\n",
    "        return config\n",
    "\n",
    "# Create a tiny model using the custom layer.\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "scaled = CustomScaling(scale_factor=2.0)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(scaled)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model with a simple configuration.\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# Create a tiny synthetic dataset.\n",
    "x_train = np.random.rand(8, 4).astype(\"float32\")\n",
    "y_train = np.random.randint(0, 2, size=(8, 1)).astype(\"float32\")\n",
    "\n",
    "# Validate shapes before training.\n",
    "assert x_train.shape == (8, 4)\n",
    "assert y_train.shape == (8, 1)\n",
    "\n",
    "# Train briefly with silent output.\n",
    "model.fit(x_train, y_train, epochs=3, verbose=0)\n",
    "\n",
    "# Generate a small batch for prediction.\n",
    "x_sample = np.array([[0.1, 0.2, 0.3, 0.4]], dtype=\"float32\")\n",
    "\n",
    "# Get predictions before saving.\n",
    "original_pred = model.predict(x_sample, verbose=0)\n",
    "\n",
    "# Define a directory for saving the model.\n",
    "save_dir = \"custom_scaling_model.keras\"\n",
    "\n",
    "# Remove any existing directory safely.\n",
    "if tf.io.gfile.exists(save_dir):\n",
    "    tf.io.gfile.rmtree(save_dir)\n",
    "\n",
    "# Save the full model including custom layer.\n",
    "model.save(save_dir, include_optimizer=False)\n",
    "\n",
    "# Load the model without custom_objects to show failure.\n",
    "loaded_without = None\n",
    "try:\n",
    "    loaded_without = tf.keras.models.load_model(save_dir)\n",
    "except Exception as e:\n",
    "    print(\"Load without custom_objects failed.\")\n",
    "\n",
    "# Load the model with custom_objects mapping.\n",
    "loaded_with = tf.keras.models.load_model(\n",
    "    save_dir,\n",
    "    custom_objects={\"CustomScaling\": CustomScaling},\n",
    ")\n",
    "\n",
    "# Predict again using the correctly loaded model.\n",
    "reloaded_pred = loaded_with.predict(x_sample, verbose=0)\n",
    "\n",
    "# Compare predictions for consistency.\n",
    "print(\"Original prediction:\", np.round(original_pred, 4))\n",
    "print(\"Reloaded prediction:\", np.round(reloaded_pred, 4))\n",
    "print(\"Difference:\", np.round(original_pred - reloaded_pred, 8))\n",
    "\n",
    "# Show that the custom layer type is preserved.\n",
    "print(\"Loaded layer type:\", type(loaded_with.layers[1]).__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d6a5f",
   "metadata": {},
   "source": [
    "## **3. Reloading and Validating Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19d583",
   "metadata": {},
   "source": [
    "### **3.1. Loading Saved Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f16799",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_03_01.jpg?v=1769519459\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Load saved models back into memory objects\n",
    ">* Restore full pipeline to reproduce original behavior\n",
    "\n",
    ">* Signatures define expected inputs and returned outputs\n",
    ">* Check signatures align with pipeline and use case\n",
    "\n",
    ">* Run test inputs and compare stored predictions\n",
    ">* Catch version, pipeline, or file corruption issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Loading Saved Models\n",
    "\n",
    "# This script shows how to reload models.\n",
    "# It focuses on loading and validating predictions.\n",
    "# Follow along to understand SavedModel reloading.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Select device based on GPU availability.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if physical_gpus:\n",
    "    device_name = \"GPU\"\n",
    "else:\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "# Inform which device is being used.\n",
    "print(\"Running on device:\", device_name)\n",
    "\n",
    "# Load a small built in dataset.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reduce dataset size for quick training.\n",
    "x_train_small = x_train[:2000].astype(\"float32\") / 255.0\n",
    "y_train_small = y_train[:2000].astype(\"int32\")\n",
    "\n",
    "# Add channel dimension for convolutional layers.\n",
    "x_train_small = np.expand_dims(x_train_small, axis=-1)\n",
    "\n",
    "# Validate shapes before building model.\n",
    "print(\"Train subset shape:\", x_train_small.shape)\n",
    "\n",
    "# Build a simple sequential CNN model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile the model with standard settings.\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train briefly with silent output.\n",
    "model.fit(\n",
    "    x_train_small,\n",
    "    y_train_small,\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Select a tiny batch for prediction tests.\n",
    "x_sample = x_train_small[:5]\n",
    "y_sample = y_train_small[:5]\n",
    "\n",
    "# Get predictions from the in memory model.\n",
    "original_probs = model.predict(x_sample, verbose=0)\n",
    "\n",
    "# Convert probabilities to class indices.\n",
    "original_preds = np.argmax(original_probs, axis=1)\n",
    "\n",
    "# Show original predictions and labels.\n",
    "print(\"Original preds:\", original_preds, \"Labels:\", y_sample)\n",
    "\n",
    "# Prepare directory paths for saving.\n",
    "base_dir = \"saved_models_demo\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Define SavedModel export path.\n",
    "savedmodel_path = os.path.join(base_dir, \"mnist_savedmodel.keras\")\n",
    "\n",
    "# Save full model using SavedModel format.\n",
    "model.save(savedmodel_path)\n",
    "\n",
    "# Define weights only checkpoint path.\n",
    "weights_path = os.path.join(base_dir, \"mnist_weights.weights.h5\")\n",
    "\n",
    "# Save only the model weights to disk.\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "# Reload full model from SavedModel directory.\n",
    "reloaded_model = tf.keras.models.load_model(savedmodel_path)\n",
    "\n",
    "# Predict again using the reloaded full model.\n",
    "reloaded_probs = reloaded_model.predict(x_sample, verbose=0)\n",
    "\n",
    "# Convert probabilities to class indices again.\n",
    "reloaded_preds = np.argmax(reloaded_probs, axis=1)\n",
    "\n",
    "# Compare original and reloaded predictions.\n",
    "print(\"Reloaded preds:\", reloaded_preds)\n",
    "\n",
    "# Check if predictions match exactly.\n",
    "match_full = np.array_equal(original_preds, reloaded_preds)\n",
    "\n",
    "# Report whether full model predictions match.\n",
    "print(\"Full model predictions match:\", bool(match_full))\n",
    "\n",
    "# Rebuild the same model architecture for weights.\n",
    "weights_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile the weights model before loading.\n",
    "weights_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Load the previously saved weights file.\n",
    "weights_model.load_weights(weights_path)\n",
    "\n",
    "# Predict using the weights only reloaded model.\n",
    "weights_probs = weights_model.predict(x_sample, verbose=0)\n",
    "\n",
    "# Convert probabilities to class indices again.\n",
    "weights_preds = np.argmax(weights_probs, axis=1)\n",
    "\n",
    "# Check if weights model predictions match original.\n",
    "match_weights = np.array_equal(original_preds, weights_preds)\n",
    "\n",
    "# Print final consistency summary for both reload paths.\n",
    "print(\"Weights model predictions match:\", bool(match_weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d49c3",
   "metadata": {},
   "source": [
    "### **3.2. Deterministic Model Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecd29f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_03_02.jpg?v=1769519613\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Check reloaded models give identical outputs consistently\n",
    ">* Determinism enables debugging, auditing, and trustworthy comparisons\n",
    "\n",
    ">* Control randomness and use fixed test inputs\n",
    ">* Compare outputs to baseline to confirm identical behavior\n",
    "\n",
    ">* Control or disable stochastic behavior during inference\n",
    ">* Use deterministic config in production, document conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Deterministic Model Predictions\n",
    "\n",
    "# This script shows deterministic TensorFlow predictions.\n",
    "# It trains saves reloads and compares model outputs.\n",
    "# Use this to validate stable serving model behavior.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set global random seeds for determinism.\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Select device preferring GPU when available.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if physical_gpus:\n",
    "    device_name = \"/GPU:0\"\n",
    "else:\n",
    "    device_name = \"/CPU:0\"\n",
    "print(\"Using device:\", device_name)\n",
    "\n",
    "# Create a tiny deterministic dataset.\n",
    "num_samples = 64\n",
    "x_data = np.linspace(-1.0, 1.0, num_samples).reshape(-1, 1)\n",
    "noise = np.zeros_like(x_data)\n",
    "y_data = 3.0 * x_data + 0.5 + noise\n",
    "\n",
    "# Validate dataset shapes defensively.\n",
    "assert x_data.shape == (num_samples, 1)\n",
    "assert y_data.shape == (num_samples, 1)\n",
    "\n",
    "# Build a simple Keras regression model.\n",
    "with tf.device(device_name):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "# Compile the model with mean squared error.\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train briefly with silent output.\n",
    "history = model.fit(\n",
    "    x_data,\n",
    "    y_data,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Choose a small fixed test batch.\n",
    "x_test = np.array([[-0.5], [0.0], [0.5]], dtype=np.float32)\n",
    "assert x_test.shape == (3, 1)\n",
    "\n",
    "# Get baseline predictions before saving.\n",
    "baseline_preds = model.predict(x_test, verbose=0)\n",
    "\n",
    "# Define a safe export directory.\n",
    "export_dir = \"deterministic_model_export\"\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Save full model using SavedModel format.\n",
    "model_save_path = os.path.join(export_dir, \"full_model.keras\")\n",
    "model.save(model_save_path)\n",
    "\n",
    "# Save only weights to a separate file.\n",
    "weights_path = os.path.join(export_dir, \"model_weights.weights.h5\")\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "# Reload full model from disk.\n",
    "reloaded_model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "# Ensure reloaded model input shape matches.\n",
    "reloaded_input_shape = reloaded_model.inputs[0].shape\n",
    "assert reloaded_input_shape[1] == 1\n",
    "\n",
    "# Get predictions from the reloaded model.\n",
    "reloaded_preds = reloaded_model.predict(x_test, verbose=0)\n",
    "\n",
    "# Compare predictions using a small tolerance.\n",
    "max_abs_diff = np.max(np.abs(baseline_preds - reloaded_preds))\n",
    "are_close = np.allclose(baseline_preds, reloaded_preds, atol=1e-6)\n",
    "\n",
    "# Print deterministic comparison summary.\n",
    "print(\"Baseline predictions:\", np.round(baseline_preds.flatten(), 4))\n",
    "print(\"Reloaded predictions:\", np.round(reloaded_preds.flatten(), 4))\n",
    "print(\"Max absolute difference:\", float(max_abs_diff))\n",
    "print(\"Predictions match within tolerance:\", bool(are_close))\n",
    "\n",
    "# Demonstrate reusing weights with same architecture.\n",
    "with tf.device(device_name):\n",
    "    same_arch_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "# Load saved weights into new model.\n",
    "same_arch_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "same_arch_model.load_weights(weights_path)\n",
    "\n",
    "# Predict again to confirm deterministic behavior.\n",
    "weights_preds = same_arch_model.predict(x_test, verbose=0)\n",
    "\n",
    "# Check that weights based predictions also match.\n",
    "weights_close = np.allclose(baseline_preds, weights_preds, atol=1e-6)\n",
    "print(\"Weights based predictions:\", np.round(weights_preds.flatten(), 4))\n",
    "print(\"Weights predictions match baseline:\", bool(weights_close))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ab09cc",
   "metadata": {},
   "source": [
    "### **3.3. Handling Missing Dependencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf655ce",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_09/Lecture_A/image_03_03.jpg?v=1769519820\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Models depend on specific code and libraries\n",
    ">* Mismatched environments cause loading errors or behavior changes\n",
    "\n",
    ">* Record versions and list all model dependencies\n",
    ">* Package custom components so reloaded models behave consistently\n",
    "\n",
    ">* Version mismatches can cause subtle prediction changes\n",
    ">* Validate outputs across environments and align dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48930a75",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Saving Models**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c617f617",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Export TensorFlow 2.20.0 models using the SavedModel format with appropriate signatures. \n",
    "- Use Keras model.save and save_weights APIs to manage checkpoints and full model exports. \n",
    "- Verify that saved models can be reloaded and produce consistent predictions. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Serving and APIs'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
