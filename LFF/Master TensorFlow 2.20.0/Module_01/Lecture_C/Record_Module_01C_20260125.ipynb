{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2615b4b1",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**TF 2.20 Overview**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a9e64",
   "metadata": {},
   "source": [
    ">Last update: 20260125.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Summarize the core architectural concepts behind TensorFlow 2.x and eager execution. \n",
    "- Identify the primary high-level APIs in TensorFlow 2.20.0 and their roles. \n",
    "- Distinguish between stable, legacy, and experimental TensorFlow APIs relevant in 2026. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087987f9",
   "metadata": {},
   "source": [
    "## **1. Eager Execution Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78194deb",
   "metadata": {},
   "source": [
    "### **1.1. Immediate Tensor Execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf29924",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_01_01.jpg?v=1769364297\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Ops run immediately and return real values\n",
    ">* Feels like normal numerical coding, easier reasoning\n",
    "\n",
    ">* Eager results enable natural debugging with Python tools\n",
    ">* Supports fast, interactive experimentation, especially in notebooks\n",
    "\n",
    ">* Eager mode hides device placement and optimizations\n",
    ">* Pythonic interface atop scalable, graph-based runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53470ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Immediate Tensor Execution\n",
    "\n",
    "# This script demonstrates immediate tensor execution basics.\n",
    "# We use only Python standard library for clarity.\n",
    "# Focus on simple numeric operations and observations.\n",
    "\n",
    "# Import the math module for numeric comparisons.\n",
    "import math\n",
    "\n",
    "# Define a helper function to print section titles.\n",
    "def print_title(title):\n",
    "    print(\"\\n\" + title)\n",
    "\n",
    "# Show a simple numeric operation executing immediately.\n",
    "print_title(\"1) Immediate numeric operations in Python\")\n",
    "result_add = 3 + 4\n",
    "print(\"Addition result is\", result_add)\n",
    "\n",
    "# Show that the result is a concrete Python integer.\n",
    "print(\"Type of result_add is\", type(result_add))\n",
    "\n",
    "# Demonstrate a small list comprehension executing immediately.\n",
    "print_title(\"2) Immediate list comprehension execution\")\n",
    "values = [x * 2 for x in range(3)]\n",
    "print(\"Doubled values are\", values)\n",
    "\n",
    "# Confirm the length to emphasize concrete data availability.\n",
    "print(\"Length of values is\", len(values))\n",
    "\n",
    "# Define a function that mimics a tiny computation step.\n",
    "def tiny_step(x):\n",
    "    return x * x + 1\n",
    "\n",
    "# Use a loop to show step by step immediate results.\n",
    "print_title(\"3) Step by step loop execution\")\n",
    "current = 0\n",
    "for step in range(3):\n",
    "    current = tiny_step(current)\n",
    "    print(\"After step\", step, \"value is\", current)\n",
    "\n",
    "# Demonstrate a conditional depending on an immediate result.\n",
    "print_title(\"4) Condition based on immediate result\")\n",
    "threshold = 5\n",
    "if current > threshold:\n",
    "    print(\"Current is above threshold\", threshold)\n",
    "else:\n",
    "    print(\"Current is not above threshold\", threshold)\n",
    "\n",
    "# Show a small numeric check using math for completeness.\n",
    "print_title(\"5) Simple numeric sanity check\")\n",
    "root_two_squared = math.sqrt(2) ** 2\n",
    "print(\"Squared root two approximately\", round(root_two_squared, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dcafd",
   "metadata": {},
   "source": [
    "### **1.2. Graph Model Changes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41f52b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_01_02.jpg?v=1769364326\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* TF2 runs ops eagerly, like NumPy\n",
    ">* Graphs remain optional for optimization and deployment\n",
    "\n",
    ">* Graphs shift from manual centerpiece to byproduct\n",
    ">* TensorFlow compiles Python code into optimized deployable graphs\n",
    "\n",
    ">* Eager mode simplifies debugging and Python control flow\n",
    ">* Graphs optimize execution for accelerators and deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Graph Model Changes\n",
    "\n",
    "# This script illustrates TensorFlow graph model changes.\n",
    "# It compares eager execution with a traced graph function.\n",
    "# Focus on small tensors and clear printed outputs.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow with a clear alias.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a tiny helper to show a separator.\n",
    "def print_sep(title):\n",
    "    print(\"\\n---\", title, \"---\")\n",
    "\n",
    "# Create a small constant tensor for demonstrations.\n",
    "with tf.device(\"CPU:0\"):\n",
    "    x = tf.constant([1.0, 2.0, 3.0])\n",
    "\n",
    "# Verify tensor shape is as expected.\n",
    "assert x.shape == (3,), \"Unexpected tensor shape for x\"\n",
    "\n",
    "# Define a simple Python function using TensorFlow ops.\n",
    "def simple_compute(t):\n",
    "    y = t * 2.0\n",
    "    z = y + 1.0\n",
    "    return z\n",
    "\n",
    "# Show eager execution behavior with direct function call.\n",
    "print_sep(\"Eager execution result\")\n",
    "\n",
    "# Call the function normally in eager mode.\n",
    "result_eager = simple_compute(x)\n",
    "\n",
    "# Print the concrete tensor values from eager execution.\n",
    "print(\"Eager result:\", result_eager.numpy())\n",
    "\n",
    "# Use tf.function to trace the same Python function.\n",
    "@tf.function\n",
    "def simple_compute_graph(t):\n",
    "    y = t * 2.0\n",
    "    z = y + 1.0\n",
    "    return z\n",
    "\n",
    "# Show graph execution behavior using tf.function.\n",
    "print_sep(\"Graph execution result\")\n",
    "\n",
    "# Call the traced function, which builds a graph internally.\n",
    "result_graph = simple_compute_graph(x)\n",
    "\n",
    "# Print the result, which matches eager computation.\n",
    "print(\"Graph result:\", result_graph.numpy())\n",
    "\n",
    "# Inspect the concrete function to emphasize graph creation.\n",
    "concrete = simple_compute_graph.get_concrete_function(\n",
    "    tf.TensorSpec(shape=(3,), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "# Show that a graph object exists behind the scenes.\n",
    "print_sep(\"Graph object summary\")\n",
    "\n",
    "# Print a short description of the internal graph.\n",
    "print(\"Graph type:\", type(concrete.graph).__name__)\n",
    "\n",
    "# Confirm that eager and graph results are identical.\n",
    "print_sep(\"Consistency check\")\n",
    "\n",
    "# Use TensorFlow assertion to validate equality.\n",
    "with tf.device(\"CPU:0\"):\n",
    "    tf.debugging.assert_near(result_eager, result_graph)\n",
    "\n",
    "# Print final confirmation message for the learner.\n",
    "print(\"Eager and graph computations match exactly.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5556dd2",
   "metadata": {},
   "source": [
    "### **1.3. Tracing with tf function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501d61b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_01_03.jpg?v=1769364412\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* tf.function traces eager code into graphs\n",
    ">* Cached graphs run faster with graph optimizations\n",
    "\n",
    ">* Tracing builds a symbolic graph from functions\n",
    ">* Optimized graphs run faster and more consistently\n",
    "\n",
    ">* Tracing builds input-specific, optimized computation graphs\n",
    ">* Python side effects change, but deployment performance improves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a65ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tracing with tf function\n",
    "\n",
    "# This script demonstrates TensorFlow eager tracing.\n",
    "# It focuses on tf function and graphs.\n",
    "# Run cells to observe tracing behavior.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import standard library modules safely.\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Disable GPU to avoid CUDA errors in environments without valid handles.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "random.seed(7)\n",
    "\n",
    "# Try importing TensorFlow and handle failures.\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError as e:\n",
    "    raise SystemExit(\"TensorFlow is required for this demo.\")\n",
    "\n",
    "# Print TensorFlow version in one concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check for available GPU devices briefly.\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "# Print whether a GPU is available for execution.\n",
    "print(\"GPU available:\", bool(gpus))\n",
    "\n",
    "# Create two small constant tensors for demonstration.\n",
    "a = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
    "\n",
    "# Create another tensor with matching shape and type.\n",
    "b = tf.constant([4.0, 5.0, 6.0], dtype=tf.float32)\n",
    "\n",
    "# Define a simple eager function using TensorFlow ops.\n",
    "def eager_add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Call the eager function and print the result.\n",
    "result_eager = eager_add(a, b)\n",
    "\n",
    "# Show that eager execution returns an immediate tensor.\n",
    "print(\"Eager result:\", result_eager.numpy())\n",
    "\n",
    "# Decorate a function with tf function for tracing.\n",
    "@tf.function\n",
    "def traced_add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Call the traced function once to trigger tracing.\n",
    "result_traced_first = traced_add(a, b)\n",
    "\n",
    "# Print the first traced call result for comparison.\n",
    "print(\"First traced result:\", result_traced_first.numpy())\n",
    "\n",
    "# Call the traced function again with same signature.\n",
    "result_traced_second = traced_add(a, b)\n",
    "\n",
    "# Print the second traced call result to show reuse.\n",
    "print(\"Second traced result:\", result_traced_second.numpy())\n",
    "\n",
    "# Inspect the concrete function created by tracing.\n",
    "concrete = traced_add.get_concrete_function(\n",
    "    tf.TensorSpec(shape=(3,), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(3,), dtype=tf.float32),\n",
    ")\n",
    "\n",
    "# Print a short summary of the traced graph.\n",
    "print(\"Concrete function inputs:\", concrete.inputs)\n",
    "\n",
    "# Print the output specification of the traced graph.\n",
    "print(\"Concrete function output:\", concrete.output_shapes)\n",
    "\n",
    "# Define a function with simple TensorFlow control flow.\n",
    "@tf.function\n",
    "def traced_square_if_positive(x):\n",
    "    return tf.cond(x > 0.0, lambda: x * x, lambda: -x)\n",
    "\n",
    "# Call the control flow function with positive input.\n",
    "positive_input = tf.constant(2.0, dtype=tf.float32)\n",
    "\n",
    "# Call the function and capture the positive result.\n",
    "positive_result = traced_square_if_positive(positive_input)\n",
    "\n",
    "# Call the control flow function with negative input.\n",
    "negative_input = tf.constant(-2.0, dtype=tf.float32)\n",
    "\n",
    "# Call the function and capture the negative result.\n",
    "negative_result = traced_square_if_positive(negative_input)\n",
    "\n",
    "# Print both results to show consistent traced behavior.\n",
    "print(\"Control flow results:\", positive_result.numpy(), negative_result.numpy())\n",
    "\n",
    "# End by confirming script finished without runtime errors.\n",
    "print(\"Tracing demo completed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a31480",
   "metadata": {},
   "source": [
    "## **2. Core High Level APIs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f47cf",
   "metadata": {},
   "source": [
    "### **2.1. Building Models With Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a5605",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_02_01.jpg?v=1769364488\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Keras is TensorFlowâ€™s main high-level interface\n",
    ">* Supports simple to complex models, hiding low-level details\n",
    "\n",
    ">* Unified setup for compile, train, evaluate workflows\n",
    ">* Same interface supports many different ML tasks\n",
    "\n",
    ">* Keras balances simplicity with deep customization options\n",
    ">* Acts as central hub connecting models, data, deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Building Models With Keras\n",
    "\n",
    "# This script shows Keras model building basics.\n",
    "# It uses TensorFlow Keras for simple classification.\n",
    "# Focus on defining compiling and training models.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import standard library modules safely.\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "random.seed(7)\n",
    "\n",
    "# Try importing TensorFlow and handle absence.\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError as e:\n",
    "    raise SystemExit(\"TensorFlow is required for this demo.\")\n",
    "\n",
    "# Disable GPU to avoid CUDA errors in environments without proper GPU setup.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Select device based on GPU availability.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if physical_gpus:\n",
    "    device_type = \"GPU\"\n",
    "else:\n",
    "    device_type = \"CPU\"\n",
    "\n",
    "# Print which device type will be used.\n",
    "print(\"Using device type:\", device_type)\n",
    "\n",
    "# Load MNIST dataset from Keras utilities.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Confirm dataset shapes before preprocessing.\n",
    "print(\"Train shape:\", x_train.shape, \"Test shape:\", x_test.shape)\n",
    "\n",
    "# Use a small subset for quick demonstration.\n",
    "subset_size = 2000\n",
    "x_train_small = x_train[:subset_size]\n",
    "y_train_small = y_train[:subset_size]\n",
    "\n",
    "# Normalize pixel values to range zero one.\n",
    "x_train_small = x_train_small.astype(\"float32\") / 255.0\n",
    "x_test_small = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Flatten images to vectors for dense network.\n",
    "input_shape = (28 * 28,)\n",
    "x_train_small = x_train_small.reshape((-1,) + input_shape)\n",
    "x_test_small = x_test_small.reshape((-1,) + input_shape)\n",
    "\n",
    "# Validate shapes after reshaping operation.\n",
    "assert x_train_small.shape[1:] == input_shape\n",
    "assert x_test_small.shape[1:] == input_shape\n",
    "\n",
    "# Build a simple Sequential Keras model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=input_shape),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Show a short model summary using print.\n",
    "model.summary(print_fn=lambda line: print(line))\n",
    "\n",
    "# Compile model with optimizer loss and metrics.\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train model briefly with silent verbose setting.\n",
    "history = model.fit(\n",
    "    x_train_small,\n",
    "    y_train_small,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    verbose=0,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Evaluate model on a small test subset.\n",
    "loss, accuracy = model.evaluate(\n",
    "    x_test_small[:1000],\n",
    "    y_test[:1000],\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Print concise training and evaluation results.\n",
    "print(\"Final training accuracy:\", round(history.history[\"accuracy\"][-1], 4))\n",
    "print(\"Validation accuracy:\", round(history.history[\"val_accuracy\"][-1], 4))\n",
    "print(\"Test accuracy on subset:\", round(accuracy, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd558b02",
   "metadata": {},
   "source": [
    "### **2.2. Efficient Data Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d834aeae",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_02_02.jpg?v=1769364561\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* tf.data builds scalable, integrated Dataset pipelines\n",
    ">* Automates loading, transforming, batching, and prefetching efficiently\n",
    "\n",
    ">* Handles many data sources as Datasets\n",
    ">* Runs complex preprocessing efficiently for smooth training\n",
    "\n",
    ">* tf.data scales cleanly across devices and workers\n",
    ">* Sharding, caching, prefetching keep training fast, balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Efficient Data Pipelines\n",
    "\n",
    "# This script introduces efficient TensorFlow data pipelines.\n",
    "# We simulate tf.data ideas using pure Python lists.\n",
    "# Focus on batching, shuffling, mapping, and prefetching.\n",
    "\n",
    "# Required external libraries would be installed here.\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import standard modules for randomness and typing.\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# Set deterministic random seed for reproducible behavior.\n",
    "random.seed(42)\n",
    "\n",
    "# Create a tiny synthetic dataset of feature label pairs.\n",
    "raw_features = list(range(20))\n",
    "raw_labels = [x % 2 for x in raw_features]\n",
    "\n",
    "# Check dataset sizes before building the pipeline.\n",
    "assert len(raw_features) == len(raw_labels)\n",
    "\n",
    "# Define a simple normalization mapping function.\n",
    "\n",
    "def normalize_feature(x):\n",
    "    return (x - 10) / 10\n",
    "\n",
    "# Define a function that yields shuffled indices.\n",
    "def shuffled_indices(n_items, seed):\n",
    "    indices = list(range(n_items))\n",
    "    random.Random(seed).shuffle(indices)\n",
    "    return indices\n",
    "\n",
    "# Define a generator that yields mapped and shuffled samples.\n",
    "def sample_generator(features, labels, seed):\n",
    "    n_items = len(features)\n",
    "    for idx in shuffled_indices(n_items, seed):\n",
    "        feat = normalize_feature(features[idx])\n",
    "        lab = labels[idx]\n",
    "        yield feat, lab\n",
    "\n",
    "# Define a batching function that groups samples.\n",
    "def batch_generator(sample_iter, batch_size):\n",
    "    batch_feats, batch_labs = [], []\n",
    "    for feat, lab in sample_iter:\n",
    "        batch_feats.append(feat)\n",
    "        batch_labs.append(lab)\n",
    "        if len(batch_feats) == batch_size:\n",
    "            yield batch_feats, batch_labs\n",
    "            batch_feats, batch_labs = [], []\n",
    "    if batch_feats:\n",
    "        yield batch_feats, batch_labs\n",
    "\n",
    "# Define a simple prefetch wrapper using an internal buffer.\n",
    "def prefetch_generator(batched_iter, buffer_size):\n",
    "    buffer = []\n",
    "    for batch in batched_iter:\n",
    "        buffer.append(batch)\n",
    "        if len(buffer) > buffer_size:\n",
    "            yield buffer.pop(0)\n",
    "    for batch in buffer:\n",
    "        yield batch\n",
    "\n",
    "# Build the pipeline step by step for one small epoch.\n",
    "base_iter = sample_generator(raw_features, raw_labels, seed=123)\n",
    "\n",
    "# Apply batching to the shuffled and normalized samples.\n",
    "batched_iter = batch_generator(base_iter, batch_size=4)\n",
    "\n",
    "# Apply prefetching to simulate overlapping work.\n",
    "prefetched_iter = prefetch_generator(batched_iter, buffer_size=2)\n",
    "\n",
    "# Collect a few batches to inspect the pipeline output.\n",
    "collected_batches = list(itertools.islice(prefetched_iter, 3))\n",
    "\n",
    "# Print a short summary of the pipeline behavior.\n",
    "print(\"Total raw samples:\", len(raw_features))\n",
    "print(\"Number of collected batches:\", len(collected_batches))\n",
    "print(\"Batch shapes (features, labels) preview:\")\n",
    "for i, (bf, bl) in enumerate(collected_batches):\n",
    "    print(\"Batch\", i, \"sizes:\", len(bf), len(bl))\n",
    "\n",
    "# Show actual normalized feature values for the first batch.\n",
    "first_features, first_labels = collected_batches[0]\n",
    "print(\"First batch features:\", first_features)\n",
    "print(\"First batch labels:\", first_labels)\n",
    "\n",
    "# Confirm that all labels are still correctly aligned.\n",
    "reconstructed = []\n",
    "for feats, labs in collected_batches:\n",
    "    reconstructed.extend(list(zip(feats, labs)))\n",
    "print(\"Reconstructed pairs count:\", len(reconstructed))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e12fc",
   "metadata": {},
   "source": [
    "### **2.3. Distributed Training Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5888d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_02_03.jpg?v=1769364635\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Distribution strategies scale training across many devices\n",
    ">* They hide low-level details, enabling easy scaling\n",
    "\n",
    ">* Unified interface for varied hardware distribution strategies\n",
    ">* Supports GPUs, TPUs, and multi-machine training\n",
    "\n",
    ">* Strategies plug into existing models and pipelines\n",
    ">* Enable quick scaling from local experiments to clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Distributed Training Strategies\n",
    "\n",
    "# This script introduces TensorFlow distribution strategies.\n",
    "# It uses a tiny model and synthetic data.\n",
    "# It keeps output short and beginner friendly.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import standard libraries for reproducibility.\n",
    "import os, random, math, sys\n",
    "\n",
    "# Set deterministic random seeds for safety.\n",
    "random.seed(7); os.environ[\"PYTHONHASHSEED\"] = \"7\"\n",
    "\n",
    "# Try importing TensorFlow inside a safe block.\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow import failed, exiting safely.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Disable GPU to avoid CUDA handle errors in constrained environments.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check for available GPUs for potential distribution.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "# Decide whether to use MirroredStrategy or default.\n",
    "if len(physical_gpus) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# Briefly report which strategy class is being used.\n",
    "print(\"Using strategy:\", strategy.__class__.__name__)\n",
    "\n",
    "# Define tiny synthetic dataset parameters safely.\n",
    "num_samples, num_features = 256, 8\n",
    "\n",
    "# Create synthetic features as a small tensor.\n",
    "features = tf.random.uniform((num_samples, num_features), seed=7)\n",
    "\n",
    "# Create synthetic labels with a simple rule.\n",
    "labels = tf.reduce_sum(features, axis=1, keepdims=True)\n",
    "\n",
    "# Validate shapes before building dataset.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "# Build a small batched dataset for training.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Shuffle and batch with a small buffer size.\n",
    "dataset = dataset.shuffle(256, seed=7, reshuffle_each_iteration=False).batch(32)\n",
    "\n",
    "# Create the model inside the strategy scope.\n",
    "with strategy.scope():\n",
    "    # Define a simple Sequential regression model.\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(num_features,)),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "# Compile the model with mean squared error loss.\n",
    "with strategy.scope():\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train for a few epochs with silent logging.\n",
    "history = model.fit(dataset, epochs=3, verbose=0)\n",
    "\n",
    "# Evaluate the model briefly on a small batch.\n",
    "small_batch = next(iter(dataset))\n",
    "\n",
    "# Unpack the batch into inputs and targets.\n",
    "x_batch, y_batch = small_batch\n",
    "\n",
    "# Confirm batch shapes before evaluation.\n",
    "print(\"Batch shape:\", x_batch.shape, y_batch.shape)\n",
    "\n",
    "# Evaluate without verbose logs for cleanliness.\n",
    "loss, mae = model.evaluate(x_batch, y_batch, verbose=0)\n",
    "\n",
    "# Show a concise summary of training quality.\n",
    "print(\"Small batch loss:\", float(loss))\n",
    "\n",
    "# Show mean absolute error for interpretability.\n",
    "print(\"Small batch MAE:\", float(mae))\n",
    "\n",
    "# Demonstrate a single prediction using the model.\n",
    "sample_input = tf.expand_dims(x_batch[0], axis=0)\n",
    "\n",
    "# Run prediction on the tiny sample input.\n",
    "prediction = model.predict(sample_input, verbose=0)\n",
    "\n",
    "# Print the true label and predicted value.\n",
    "print(\"True label:\", float(y_batch[0][0].numpy()), \"Predicted:\", float(prediction[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fbbdf",
   "metadata": {},
   "source": [
    "## **3. TensorFlow API Landscape**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5567c36",
   "metadata": {},
   "source": [
    "### **3.1. Stable and Deprecated APIs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7158f99",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_03_01.jpg?v=1769364752\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Stable APIs signal long-term, backward-compatible support\n",
    ">* Use them for reliable, scalable production ML systems\n",
    "\n",
    ">* Deprecated APIs stay for now, but vanish later\n",
    ">* Use them only while migrating to stable APIs\n",
    "\n",
    ">* Stable APIs support long-term, maintainable ML projects\n",
    ">* Deprecated APIs temporarily bridge legacy systems to modern\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817b75b",
   "metadata": {},
   "source": [
    "### **3.2. Model Export and Serving**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4278161",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_03_02.jpg?v=1769364773\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* SavedModel is the standard format for deployment\n",
    ">* Supports TF Serving, TFLite, stable production use\n",
    "\n",
    ">* Legacy frozen-graph and session workflows remain deprecated\n",
    ">* Teams should migrate legacy systems to SavedModel workflows\n",
    "\n",
    ">* Experimental export features enable cutting-edge deployment scenarios\n",
    ">* Use them cautiously with version pinning and sandboxing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Model Export and Serving\n",
    "\n",
    "# This script introduces TensorFlow model export concepts.\n",
    "# We simulate export and serving without external libraries.\n",
    "# Focus is on stable legacy and experimental style APIs.\n",
    "\n",
    "# Import standard libraries for paths and randomness.\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set deterministic random seed for reproducibility.\n",
    "random.seed(42)\n",
    "\n",
    "# Define a tiny fake model class for demonstration.\n",
    "class TinyLinearModel:\n",
    "    # Initialize with simple weight and bias parameters.\n",
    "    def __init__(self, weight: float, bias: float):\n",
    "        self.weight = float(weight)\n",
    "        self.bias = float(bias)\n",
    "\n",
    "    # Define a simple predict method like a model call.\n",
    "    def predict(self, x_value: float) -> float:\n",
    "        return self.weight * float(x_value) + self.bias\n",
    "\n",
    "# Create a small instance representing a trained model.\n",
    "stable_model = TinyLinearModel(weight=2.0, bias=0.5)\n",
    "\n",
    "# Prepare a stable SavedModel style export dictionary.\n",
    "stable_export = {\n",
    "    \"format\": \"savedmodel_like\",\n",
    "    \"version\": 1,\n",
    "    \"signatures\": {\"serving_default\": {\"inputs\": [\"x\"], \"outputs\": [\"y\"]}},\n",
    "    \"weights\": {\"weight\": stable_model.weight, \"bias\": stable_model.bias},\n",
    "}\n",
    "\n",
    "# Define a legacy frozen graph style export dictionary.\n",
    "legacy_export = {\n",
    "    \"format\": \"frozen_graph_like\",\n",
    "    \"graph_nodes\": [\"x\", \"mul\", \"add\", \"y\"],\n",
    "    \"note\": \"represents older TensorFlow 1.x style graphs\",\n",
    "}\n",
    "\n",
    "# Define an experimental export with extra quantization metadata.\n",
    "experimental_export = {\n",
    "    \"format\": \"savedmodel_like_experimental\",\n",
    "    \"version\": 1,\n",
    "    \"quantization\": {\"scheme\": \"int8_per_channel\", \"status\": \"experimental\"},\n",
    "}\n",
    "\n",
    "# Choose a small base directory for our fake exports.\n",
    "base_dir = os.path.join(os.getcwd(), \"tf_export_demo\")\n",
    "\n",
    "# Safely create the directory if it does not exist.\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Helper function to save a dictionary as a JSON file.\n",
    "def save_export_dict(export_dict: dict, file_path: str) -> None:\n",
    "    # Validate that export_dict is not empty before saving.\n",
    "    if not export_dict:\n",
    "        raise ValueError(\"Export dictionary must not be empty.\")\n",
    "\n",
    "    # Write JSON with indentation for readability.\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(export_dict, file, indent=2)\n",
    "\n",
    "# Save the stable export to a JSON file.\n",
    "stable_path = os.path.join(base_dir, \"stable_savedmodel_like.json\")\n",
    "save_export_dict(stable_export, stable_path)\n",
    "\n",
    "# Save the legacy export to a JSON file.\n",
    "legacy_path = os.path.join(base_dir, \"legacy_frozen_graph_like.json\")\n",
    "save_export_dict(legacy_export, legacy_path)\n",
    "\n",
    "# Save the experimental export to a JSON file.\n",
    "experimental_path = os.path.join(base_dir, \"experimental_savedmodel_like.json\")\n",
    "save_export_dict(experimental_export, experimental_path)\n",
    "\n",
    "# Simulate loading a stable export and running a prediction.\n",
    "with open(stable_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    loaded_stable = json.load(file)\n",
    "\n",
    "# Rebuild a TinyLinearModel instance from loaded weights.\n",
    "weights = loaded_stable.get(\"weights\", {})\n",
    "reloaded_model = TinyLinearModel(weight=weights.get(\"weight\", 1.0), bias=weights.get(\"bias\", 0.0))\n",
    "\n",
    "# Validate that the reloaded model behaves as expected.\n",
    "input_value = 3.0\n",
    "prediction = reloaded_model.predict(input_value)\n",
    "\n",
    "# Collect short summary lines for printing.\n",
    "summary_lines = [\n",
    "    \"Stable export path: \" + os.path.basename(stable_path),\n",
    "    \"Legacy export path: \" + os.path.basename(legacy_path),\n",
    "    \"Experimental export path: \" + os.path.basename(experimental_path),\n",
    "    \"Stable format type: \" + stable_export[\"format\"],\n",
    "    \"Legacy format type: \" + legacy_export[\"format\"],\n",
    "    \"Experimental format type: \" + experimental_export[\"format\"],\n",
    "    \"Stable signature keys: \" + \",\".join(stable_export[\"signatures\"].keys()),\n",
    "    \"Legacy graph nodes count: \" + str(len(legacy_export[\"graph_nodes\"])),\n",
    "    \"Experimental quantization scheme: \" + experimental_export[\"quantization\"][\"scheme\"],\n",
    "    \"Reloaded prediction for x=3.0: \" + str(prediction),\n",
    "]\n",
    "\n",
    "# Print each summary line to illustrate key differences.\n",
    "for line in summary_lines:\n",
    "    print(line)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad40cb2",
   "metadata": {},
   "source": [
    "### **3.3. Experimental API Namespaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c9fc4",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_C/image_03_03.jpg?v=1769364865\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Experimental APIs offer cutting-edge, not-yet-standard features\n",
    ">* They may change or disappear; use cautiously\n",
    "\n",
    ">* Experimental namespaces let users test new ideas\n",
    ">* Successful features stabilize; weak ones change or disappear\n",
    "\n",
    ">* Expect frequent changes; avoid mission-critical dependence\n",
    ">* Use for research, gain insight into future features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b167a",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**TF 2.20 Overview**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f678377",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Summarize the core architectural concepts behind TensorFlow 2.x and eager execution. \n",
    "- Identify the primary high-level APIs in TensorFlow 2.20.0 and their roles. \n",
    "- Distinguish between stable, legacy, and experimental TensorFlow APIs relevant in 2026. \n",
    "\n",
    "In the next Module (Module 2), we will go over 'Tensor Basics'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
