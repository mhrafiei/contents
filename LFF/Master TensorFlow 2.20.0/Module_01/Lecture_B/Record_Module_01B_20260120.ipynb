{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e231cb85",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Environment Setup**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3cbb4",
   "metadata": {},
   "source": [
    ">Last update: 20260120.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Install TensorFlow 2.20.0 and verify the installation on local or cloud hardware. \n",
    "- Configure GPU or TPU acceleration for TensorFlow 2.20.0 where available. \n",
    "- Set up a reproducible project structure for TensorFlow experiments used in this course. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb1705",
   "metadata": {},
   "source": [
    "## **1. TensorFlow Installation Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac4031",
   "metadata": {},
   "source": [
    "### **1.1. TensorFlow Install Commands**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be7175",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_01_01.jpg?v=1768961180\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Install TensorFlow 2.20.0 using Python package manager\n",
    ">* Command fetches correct CPU or GPU build\n",
    "\n",
    ">* Pin TensorFlow 2.20.0 and hardware type\n",
    ">* Choose CPU or GPU build for consistency\n",
    "\n",
    ">* Install commands fit local, corporate, and cloud setups\n",
    ">* They create a consistent, repeatable TensorFlow environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7083c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - TensorFlow Install Commands\n",
    "\n",
    "# This script demonstrates TensorFlow installation commands conceptually in Colab environment.\n",
    "# It checks current TensorFlow version and explains how to request version 2.20.0.\n",
    "# It helps beginners understand install commands without actually reinstalling TensorFlow.\n",
    "\n",
    "# !pip install tensorflow==2.20.0 --quiet  # Example CPU focused TensorFlow installation command.\n",
    "# !pip install tensorflow[and-cuda]==2.20.0 --quiet  # Example GPU optimized TensorFlow installation command.\n",
    "\n",
    "# Import required modules for system inspection and TensorFlow usage.\n",
    "import sys\n",
    "import subprocess\n",
    "import textwrap\n",
    "import importlib\n",
    "\n",
    "# Define a helper function for safely importing TensorFlow module.\n",
    "def safe_import_tensorflow_module():\n",
    "    try:\n",
    "        module = importlib.import_module(\"tensorflow\")\n",
    "        return module\n",
    "    except ImportError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Define a helper function for running shell commands and capturing outputs.\n",
    "def run_shell_command_capture_output(command_list):\n",
    "    completed = subprocess.run(command_list, capture_output=True, text=True)\n",
    "    return completed.stdout.strip(), completed.stderr.strip()\n",
    "\n",
    "\n",
    "# Retrieve current Python version information for environment context.\n",
    "python_version_info = sys.version.split()[0]\n",
    "\n",
    "# Attempt to import TensorFlow module using the safe helper function.\n",
    "tf = safe_import_tensorflow_module()\n",
    "\n",
    "\n",
    "# Prepare an explanatory message about TensorFlow installation commands usage.\n",
    "explanation_text = (\n",
    "    \"In Colab, you usually install TensorFlow using pip commands in separate cells. \"\n",
    "    \"For this course, you would request version 2.20.0 explicitly, for example using \"\n",
    "    \"pip install tensorflow==2.20.0 for CPU or pip install tensorflow[and-cuda]==2.20.0 \"\n",
    "    \"for GPU capable environments. This script only demonstrates the idea without \"\n",
    "    \"changing the currently installed TensorFlow version in this runtime.\"\n",
    ")\n",
    "\n",
    "# Wrap the explanatory text to keep printed lines reasonably short.\n",
    "wrapped_explanation_lines = textwrap.wrap(explanation_text, width=90)\n",
    "\n",
    "\n",
    "# Print basic environment information including Python version string.\n",
    "print(f\"Python version in this environment: {python_version_info}\")\n",
    "\n",
    "# Print whether TensorFlow is currently importable in this environment.\n",
    "if tf is None:\n",
    "    print(\"TensorFlow is not currently importable in this environment runtime.\")\n",
    "else:\n",
    "    print(\"TensorFlow is already importable in this environment runtime.\")\n",
    "\n",
    "\n",
    "# If TensorFlow is available, print its version and simple device information.\n",
    "if tf is not None:\n",
    "    print(f\"Detected TensorFlow version in environment: {tf.__version__}\")\n",
    "    physical_devices = tf.config.list_physical_devices()\n",
    "    print(f\"Detected physical devices list length: {len(physical_devices)}\")\n",
    "\n",
    "\n",
    "# Print the wrapped explanation lines about installation commands usage.\n",
    "for line in wrapped_explanation_lines:\n",
    "    print(line)\n",
    "\n",
    "# Final simple TensorFlow operation if TensorFlow is available and imported.\n",
    "result_value = tf.constant(3.0) + tf.constant(4.0) if tf is not None else 0.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117086c4",
   "metadata": {},
   "source": [
    "### **1.2. Managing CUDA and cuDNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfabe9b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_01_02.jpg?v=1768961223\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* CUDA connects TensorFlow to NVIDIA GPU hardware\n",
    ">* cuDNN speeds up deep learning GPU operations\n",
    "\n",
    ">* Match CUDA and cuDNN versions with TensorFlow\n",
    ">* Use standardized or prebuilt images to avoid mismatches\n",
    "\n",
    ">* Maintain versioned environments and monitor CUDA updates\n",
    ">* Systematically troubleshoot GPU visibility and library mismatches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccdd5e9",
   "metadata": {},
   "source": [
    "### **1.3. Confirming TensorFlow Version**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241940f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_01_03.jpg?v=1768961242\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Start Python and print TensorFlow version number\n",
    ">* Confirm it shows 2.20.0 to avoid issues\n",
    "\n",
    ">* Different environments can hold different TensorFlow versions\n",
    ">* Routinely check versions so everyone matches setups\n",
    "\n",
    ">* Cloud images may include wrong TensorFlow version\n",
    ">* Always check version to avoid wasted, inconsistent runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Confirming TensorFlow Version\n",
    "\n",
    "# This script confirms installed TensorFlow version and prints basic environment details.\n",
    "# It helps verify TensorFlow 2.20.0 installation in a fresh Python runtime.\n",
    "# It also shows available devices including any detected GPU or TPU.\n",
    "\n",
    "# !pip install tensorflow==2.20.0\n",
    "\n",
    "# Import standard library modules for environment inspection.\n",
    "import os, sys, platform, random\n",
    "\n",
    "# Set deterministic random seeds for reproducible behavior demonstration.\n",
    "random.seed(42)\n",
    "\n",
    "# Try importing TensorFlow and handle potential import errors gracefully.\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError as import_error:\n",
    "    print(\"TensorFlow import failed, please check installation and environment configuration.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Retrieve the TensorFlow version string from the imported module.\n",
    "tf_version: str = tf.__version__\n",
    "\n",
    "# Print the detected TensorFlow version for user confirmation.\n",
    "print(\"Detected TensorFlow version is:\", tf_version)\n",
    "\n",
    "# Check whether the detected version matches the expected course version.\n",
    "expected_version: str = \"2.20.0\"\n",
    "\n",
    "# Compare versions and print a clear message about the match status.\n",
    "if tf_version.startswith(expected_version):\n",
    "    print(\"TensorFlow version matches expected 2.20.0 for this course.\")\n",
    "else:\n",
    "    print(\"Warning, TensorFlow version does not match expected 2.20.0 version.\")\n",
    "\n",
    "# Print basic Python interpreter and operating system information.\n",
    "print(\"Python version:\", sys.version.split()[0], \"on\", platform.system())\n",
    "\n",
    "# List available physical devices recognized by TensorFlow runtime.\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "\n",
    "# Print a short summary of detected devices including CPU and GPU types.\n",
    "print(\"Detected physical devices list:\", [device.device_type for device in physical_devices])\n",
    "\n",
    "# Specifically list GPU devices to confirm hardware acceleration availability.\n",
    "gpu_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "# Print whether at least one GPU device is available for TensorFlow operations.\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available for TensorFlow operations in this environment.\")\n",
    "else:\n",
    "    print(\"GPU is not available, TensorFlow will run on CPU instead.\")\n",
    "\n",
    "# Create a tiny constant tensor to ensure TensorFlow executes a simple operation.\n",
    "small_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "# Compute a simple deterministic operation using the tiny constant tensor.\n",
    "result_tensor = tf.reduce_sum(small_tensor)\n",
    "\n",
    "# Print the result value to confirm TensorFlow computations are functioning correctly.\n",
    "print(\"Simple TensorFlow computation result is:\", float(result_tensor.numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33634bf",
   "metadata": {},
   "source": [
    "## **2. TensorFlow Hardware Acceleration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ba99f",
   "metadata": {},
   "source": [
    "### **2.1. Detecting Available Devices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6597b",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_02_01.jpg?v=1768961285\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Check which CPU, GPU, TPU TensorFlow detects\n",
    ">* Confirm drivers and libraries so accelerators work\n",
    "\n",
    ">* Device lists differ across local, cluster, cloud\n",
    ">* Regular checks clarify hardware, performance, and reproducibility\n",
    "\n",
    ">* Use device checks to troubleshoot slow training\n",
    ">* Routine detection ensures reliable, comparable experiment performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Detecting Available Devices\n",
    "\n",
    "# This script shows how TensorFlow detects available hardware devices.\n",
    "# It prints visible CPU GPU and TPU devices for this runtime.\n",
    "# Use this as a quick diagnostic before running TensorFlow training.\n",
    "\n",
    "# !pip install tensorflow==2.20.0\n",
    "\n",
    "# Import TensorFlow and system utilities for environment inspection.\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic random seed for any potential randomness here.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print Python version and TensorFlow version for clear context.\n",
    "print(\"Python version:\", sys.version.split()[0])\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# List all physical devices that TensorFlow can currently access.\n",
    "all_devices = tf.config.list_physical_devices()\n",
    "print(\"Total detected devices:\", len(all_devices))\n",
    "\n",
    "# Safely iterate and print each device type and device name string.\n",
    "for index, device in enumerate(all_devices):\n",
    "    print(\"Device\", index, \"type:\", device.device_type, \"name:\", device.name)\n",
    "\n",
    "# List only GPU devices and report how many are available here.\n",
    "gpu_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Visible GPU devices count:\", len(gpu_devices))\n",
    "\n",
    "# Conditionally print a helpful message depending on GPU availability.\n",
    "if len(gpu_devices) > 0:\n",
    "    print(\"At least one GPU is available for TensorFlow computations.\")\n",
    "else:\n",
    "    print(\"No GPUs detected so TensorFlow will use CPU only.\")\n",
    "\n",
    "# Attempt to detect TPU devices using TensorFlow distributed strategy utilities.\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tpu_name = resolver.cluster_spec().as_dict()\n",
    "    print(\"TPU devices appear available with cluster spec:\", bool(tpu_name))\n",
    "except Exception as detection_error:\n",
    "    print(\"No TPU detected or TPU not configured in this environment.\")\n",
    "\n",
    "# Confirm script completion so learners know detection finished successfully.\n",
    "print(\"Device detection script finished without runtime errors.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63649800",
   "metadata": {},
   "source": [
    "### **2.2. GPU Memory Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba4335",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_02_02.jpg?v=1768961316\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* TensorFlow reserves most GPU memory at startup\n",
    ">* Pre-allocation prevents fragmentation and misleading “full” readings\n",
    "\n",
    ">* Large models risk GPU memory errors, slowdowns\n",
    ">* Adjust batch size, model, limits for sharing\n",
    "\n",
    ">* Plan experiments around known GPU memory needs\n",
    ">* Standardize setups to reduce failures and ease portability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - GPU Memory Management\n",
    "\n",
    "# This script demonstrates TensorFlow GPU memory growth configuration.\n",
    "# It helps beginners avoid unexpected full GPU memory allocation.\n",
    "# It prints device information and simple model training memory behavior.\n",
    "\n",
    "# !pip install tensorflow==2.20.0\n",
    "\n",
    "# Import required modules including TensorFlow and operating system utilities.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version information for reproducibility and verification.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set deterministic random seeds for reproducible behavior across multiple runs.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# List physical GPU devices and print a short summary for the learner.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Physical GPUs detected:\", physical_gpus)\n",
    "\n",
    "# Configure memory growth if at least one GPU is available in this environment.\n",
    "if physical_gpus:\n",
    "    try:\n",
    "        for gpu_device in physical_gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu_device, True)\n",
    "        print(\"Enabled memory growth on all detected GPUs.\")\n",
    "    except RuntimeError as runtime_error:\n",
    "        print(\"Could not change memory growth setting:\", runtime_error)\n",
    "\n",
    "# Define a helper function that prints logical devices for additional clarity.\n",
    "def print_logical_devices():\n",
    "    logical_devices = tf.config.list_logical_devices()\n",
    "    print(\"Logical devices currently visible:\")\n",
    "    for device in logical_devices:\n",
    "        print(\" \", device)\n",
    "\n",
    "# Call the helper function to show logical devices after configuration.\n",
    "print_logical_devices()\n",
    "\n",
    "# Load a small dataset subset using MNIST digits for quick demonstration.\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "mnist_images = mnist_images[:2000].astype(\"float32\") / 255.0\n",
    "mnist_labels = mnist_labels[:2000].astype(\"int32\")\n",
    "\n",
    "# Expand image dimensions to include channel axis required by convolution layers.\n",
    "mnist_images = np.expand_dims(mnist_images, axis=-1)\n",
    "print(\"Training subset shape:\", mnist_images.shape)\n",
    "\n",
    "# Build a tiny convolutional model that fits easily into limited GPU memory.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, 3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile the model with simple optimizer and loss suitable for classification.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Print a short model summary line count limited for console readability.\n",
    "print(\"Model has\", model.count_params(), \"trainable parameters total.\")\n",
    "\n",
    "# Train the model briefly to exercise GPU memory allocation behavior.\n",
    "history = model.fit(\n",
    "    mnist_images,\n",
    "    mnist_labels,\n",
    "    epochs=2,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Print final training accuracy to confirm successful execution and training.\n",
    "final_accuracy = history.history[\"accuracy\"][-1]\n",
    "print(\"Final training accuracy value:\", round(float(final_accuracy), 4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31545aab",
   "metadata": {},
   "source": [
    "### **2.3. Colab and Cloud TPUs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf3414",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_02_03.jpg?v=1768961355\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Cloud notebooks give easy access to accelerators\n",
    ">* GPUs and TPUs greatly speed deep learning training\n",
    "\n",
    ">* Choose GPU or TPU runtime, then restart\n",
    ">* Verify device availability and confirm faster training speed\n",
    "\n",
    ">* TPUs need efficient pipelines and tuned batch sizes\n",
    ">* Expect different memory limits, precision, and training behavior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Colab and Cloud TPUs\n",
    "\n",
    "# This script checks Colab TPU availability and basic TensorFlow device configuration.\n",
    "# It helps beginners verify TPU runtime selection and understand visible accelerator devices.\n",
    "# It runs quickly using a tiny computation on available TPU, GPU, or CPU.\n",
    "\n",
    "# !pip install tensorflow==2.20.0\n",
    "\n",
    "# Import required modules for TensorFlow device inspection and simple computation.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducible behavior across supported random generators.\n",
    "seed_value = 7\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version information for clarity about environment configuration.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Try resolving TPU cluster configuration when running inside supported Colab runtimes.\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"\")\n",
    "    tpu_available = True\n",
    "except (ValueError, tf.errors.NotFoundError):\n",
    "    resolver = None\n",
    "    tpu_available = False\n",
    "\n",
    "# Initialize TPU system when resolver exists and TPU runtime appears correctly configured.\n",
    "if tpu_available:\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# List logical devices visible to TensorFlow for quick accelerator verification.\n",
    "logical_devices = tf.config.list_logical_devices()\n",
    "print(\"Logical devices detected:\")\n",
    "for device in logical_devices:\n",
    "    print(\" \", device.name, device.device_type)\n",
    "\n",
    "# Determine preferred accelerator type string based on detected TPU or GPU availability.\n",
    "if tpu_available:\n",
    "    accelerator_type = \"TPU\"\n",
    "elif tf.config.list_physical_devices(\"GPU\"):\n",
    "    accelerator_type = \"GPU\"\n",
    "else:\n",
    "    accelerator_type = \"CPU\"\n",
    "\n",
    "# Print concise summary describing which accelerator will run the tiny computation.\n",
    "print(\"Selected accelerator type:\", accelerator_type)\n",
    "\n",
    "# Define a simple TensorFlow function performing small matrix multiplication operation.\n",
    "@tf.function\n",
    "def tiny_matmul(x_tensor, y_tensor):\n",
    "    return tf.matmul(x_tensor, y_tensor)\n",
    "\n",
    "# Create small deterministic tensors for demonstration of accelerator backed computation.\n",
    "matrix_size = 4\n",
    "x_values = tf.ones((matrix_size, matrix_size), dtype=tf.float32)\n",
    "y_values = tf.fill((matrix_size, matrix_size), 2.0)\n",
    "\n",
    "# Run the tiny computation inside strategy scope to leverage available accelerator devices.\n",
    "with strategy.scope():\n",
    "    result_tensor = tiny_matmul(x_values, y_values)\n",
    "\n",
    "# Convert result tensor to numpy array and print shape and first row values.\n",
    "result_array = result_tensor.numpy()\n",
    "print(\"Result shape:\", result_array.shape)\n",
    "print(\"First row values:\", result_array[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826f286",
   "metadata": {},
   "source": [
    "## **3. Reproducible TF Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef49bb",
   "metadata": {},
   "source": [
    "### **3.1. Project Folder Structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c7bcd",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_03_01.jpg?v=1768961392\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use one organized folder per TensorFlow project\n",
    ">* Separate data, code, configs, and results clearly\n",
    "\n",
    ">* Organized folders mirror the full experiment lifecycle\n",
    ">* Structure links raw data, code, outputs, and results\n",
    "\n",
    ">* Same layout for every TensorFlow project\n",
    ">* Easier collaboration, fewer mistakes, smoother reruns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab4b76",
   "metadata": {},
   "source": [
    "### **3.2. Virtual Environments Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35e606",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_03_02.jpg?v=1768961408\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Virtual environments isolate TensorFlow and its dependencies\n",
    ">* Isolation keeps versions stable, experiments repeatable over time\n",
    "\n",
    ">* Different projects need conflicting TensorFlow and libraries\n",
    ">* Virtual envs isolate dependencies and simplify switching\n",
    "\n",
    ">* Shared configs let others recreate your setup\n",
    ">* Consistent environments make deep learning results trustworthy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0763178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Virtual Environments Basics\n",
    "\n",
    "# This script explains environment isolation using simple package version inspection.\n",
    "# It simulates virtual environment ideas inside a single Colab runtime.\n",
    "# It shows how dependencies affect reproducible TensorFlow based experiments.\n",
    "\n",
    "# !pip install tensorflow==2.20.0\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "\n",
    "# Import required standard libraries for environment inspection.\n",
    "import sys\n",
    "import subprocess\n",
    "import textwrap\n",
    "\n",
    "# Import TensorFlow library and confirm version information.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a helper function for safe package version retrieval.\n",
    "def get_package_version(package_name: str) -> str:\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        version = getattr(module, \"__version__\", \"unknown\")\n",
    "        return str(version)\n",
    "    except Exception as import_error:\n",
    "        return f\"not installed: {import_error}\"\n",
    "\n",
    "# Define a function that prints concise environment summary information.\n",
    "def print_environment_summary() -> None:\n",
    "    python_version = sys.version.split()[0]\n",
    "    tf_version = tf.__version__\n",
    "    numpy_version = get_package_version(\"numpy\")\n",
    "    pandas_version = get_package_version(\"pandas\")\n",
    "\n",
    "    print(\"Python version in this environment:\", python_version)\n",
    "    print(\"TensorFlow version in this environment:\", tf_version)\n",
    "    print(\"NumPy version in this environment:\", numpy_version)\n",
    "    print(\"Pandas version in this environment:\", pandas_version)\n",
    "\n",
    "# Define a function that explains virtual environment concepts textually.\n",
    "def explain_virtual_environment_concept() -> None:\n",
    "    explanation = (\n",
    "        \"In a real project, each virtual environment would lock these versions. \"\n",
    "        \"Different projects could safely use different TensorFlow or NumPy versions. \"\n",
    "        \"Here we only inspect the current Colab environment, but the idea matches.\"\n",
    "    )\n",
    "    wrapped = textwrap.fill(explanation, width=80)\n",
    "    print(wrapped)\n",
    "\n",
    "# Define a function that demonstrates deterministic TensorFlow behavior.\n",
    "def demonstrate_deterministic_tensorflow_behavior() -> None:\n",
    "    tf.random.set_seed(42)\n",
    "    random_tensor_one = tf.random.uniform(shape=(2, 3), minval=0.0, maxval=1.0)\n",
    "    tf.random.set_seed(42)\n",
    "    random_tensor_two = tf.random.uniform(shape=(2, 3), minval=0.0, maxval=1.0)\n",
    "    tensors_equal = tf.reduce_all(tf.equal(random_tensor_one, random_tensor_two))\n",
    "    print(\"Deterministic TensorFlow random tensors equal:\", bool(tensors_equal.numpy()))\n",
    "\n",
    "# Define a function that summarizes why reproducibility depends on environments.\n",
    "def summarize_reproducibility_message() -> None:\n",
    "    message = (\n",
    "        \"If you recreate this environment later, these versions and behaviors should match. \"\n",
    "        \"Virtual environments help ensure that your collaborators see the same results.\"\n",
    "    )\n",
    "    wrapped_message = textwrap.fill(message, width=80)\n",
    "    print(wrapped_message)\n",
    "\n",
    "# Execute the defined functions to display environment and reproducibility information.\n",
    "print_environment_summary()\n",
    "explain_virtual_environment_concept()\n",
    "demonstrate_deterministic_tensorflow_behavior()\n",
    "summarize_reproducibility_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476d230",
   "metadata": {},
   "source": [
    "### **3.3. Git Workflow Essentials**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a91004",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_01/Lecture_B/image_03_03.jpg?v=1768961452\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Version control records every meaningful project change\n",
    ">* Helps compare experiments, reproduce results, and collaborate\n",
    "\n",
    ">* Initialize a repo and branch for experiments\n",
    ">* Merge successful branches to document research history\n",
    "\n",
    ">* Track code, configs, and small sample data\n",
    ">* Write clear commits, treat repo like experiment notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a9b67",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Environment Setup**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738789e",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Install TensorFlow 2.20.0 and verify the installation on local or cloud hardware. \n",
    "- Configure GPU or TPU acceleration for TensorFlow 2.20.0 where available. \n",
    "- Set up a reproducible project structure for TensorFlow experiments used in this course. \n",
    "\n",
    "In the next Lecture (Lecture C), we will go over 'TF 2.20 Overview'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
