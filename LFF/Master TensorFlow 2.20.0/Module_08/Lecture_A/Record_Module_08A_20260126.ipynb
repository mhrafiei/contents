{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bc119f",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Distribution Basics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e9a6a8",
   "metadata": {},
   "source": [
    ">Last update: 20260126.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Describe the main tf.distribute strategies available in TensorFlow 2.20.0 and their typical use cases. \n",
    "- Explain how data parallelism and replica synchronization work in distributed training. \n",
    "- Identify the changes required in model and input code to support distribution strategies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b167d9",
   "metadata": {},
   "source": [
    "## **1. Core Distribution Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a22ee5",
   "metadata": {},
   "source": [
    "### **1.1. Single Host MirroredStrategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e93b9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_01_01.jpg?v=1769446326\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Copies one model across all GPUs, synchronizing gradients\n",
    ">* Enables easy multi-GPU training on one machine\n",
    "\n",
    ">* Use multiple GPUs to speed up training\n",
    ">* Shared host memory keeps data handling simple\n",
    "\n",
    ">* Fast on one machine, easy to integrate\n",
    ">* Limited by single host resources, scales modestly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Single Host MirroredStrategy\n",
    "\n",
    "# This script demonstrates Single Host MirroredStrategy basics.\n",
    "# It compares single GPU or CPU with mirrored multi GPU training.\n",
    "# It keeps output short while showing key distribution behavior.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and distribution utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Detect available GPUs for potential mirroring.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "num_gpus = len(physical_gpus)\n",
    "print(\"Detected GPUs:\", num_gpus)\n",
    "\n",
    "# Decide whether to use MirroredStrategy or default.\n",
    "if num_gpus > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    strategy_name = \"MirroredStrategy\"\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    strategy_name = \"DefaultStrategy\"\n",
    "\n",
    "# Print chosen strategy and replica count.\n",
    "print(\"Using strategy:\", strategy_name, \"replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Load MNIST dataset from Keras utilities.\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reduce dataset size for quick demonstration.\n",
    "x_train = x_train[:6000]\n",
    "y_train = y_train[:6000]\n",
    "\n",
    "# Normalize images to float32 in range zero one.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension for convolutional layers.\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "\n",
    "# Validate shapes before building dataset.\n",
    "print(\"Train shape:\", x_train.shape, \"Labels shape:\", y_train.shape)\n",
    "\n",
    "# Create tf.data dataset with small batch size.\n",
    "batch_size = 128\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(6000, seed=seed_value)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "# Define a simple CNN model builder function.\n",
    "def create_model():\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(16, 3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build and compile model inside strategy scope.\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "# Show a brief model summary line manually.\n",
    "print(\"Model parameters:\", model.count_params())\n",
    "\n",
    "# Train for a few epochs with silent verbose setting.\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Extract final loss and accuracy from history.\n",
    "final_loss = history.history[\"loss\"][-1]\n",
    "final_acc = history.history[\"accuracy\"][-1]\n",
    "\n",
    "# Print concise training results for comparison.\n",
    "print(\"Final loss:\", round(float(final_loss), 4))\n",
    "print(\"Final accuracy:\", round(float(final_acc), 4))\n",
    "\n",
    "# Show effective global batch size under strategy.\n",
    "effective_batch = batch_size * strategy.num_replicas_in_sync\n",
    "print(\"Effective global batch size:\", effective_batch)\n",
    "\n",
    "# Confirm that strategy kept variables synchronized.\n",
    "print(\"Trainable variables count:\", len(model.trainable_variables))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501984a",
   "metadata": {},
   "source": [
    "### **1.2. Multiworker Mirrored Strategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5ff57",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_01_02.jpg?v=1769446365\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Scales synchronous training from one machine to clusters\n",
    ">* Replicates model on workers, aggregates gradients to synchronize\n",
    "\n",
    ">* Best for clusters of networked GPU machines\n",
    ">* Speeds training while hiding coordination and failures\n",
    "\n",
    ">* More workers increase global batch size, adjust hyperparameters\n",
    ">* Needs fast, balanced cluster to scale large workloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fd7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Multiworker Mirrored Strategy\n",
    "\n",
    "# This script introduces MultiWorkerMirroredStrategy basics.\n",
    "# It simulates multiworker setup on a single machine.\n",
    "# It keeps training tiny and output very compact.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Import TensorFlow and check version.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "random.seed(7)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"7\"\n",
    "\n",
    "# Set TensorFlow random seed deterministically.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Explain that we simulate two workers locally.\n",
    "print(\"Simulating two workers on one process.\")\n",
    "\n",
    "# Build a simple JSON cluster specification.\n",
    "cluster_spec = {\"worker\": [\"localhost:12345\"]}\n",
    "\n",
    "# Convert cluster specification to JSON string.\n",
    "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
    "    \"cluster\": cluster_spec,\n",
    "    \"task\": {\"type\": \"worker\", \"index\": 0}\n",
    "})\n",
    "\n",
    "# Create the MultiWorkerMirroredStrategy instance.\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Print how many replicas are in sync.\n",
    "print(\"Replicas in sync:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Prepare a tiny synthetic dataset for training.\n",
    "features = tf.random.normal(shape=(64, 4))\n",
    "\n",
    "# Create small integer labels for classification.\n",
    "labels = tf.random.uniform(shape=(64,), maxval=3, dtype=tf.int32)\n",
    "\n",
    "# Zip features and labels into a dataset.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Shuffle and batch the dataset for training.\n",
    "base_ds = base_ds.shuffle(64, seed=7).batch(8)\n",
    "\n",
    "# Distribute the dataset across strategy replicas.\n",
    "dist_ds = strategy.experimental_distribute_dataset(base_ds)\n",
    "\n",
    "# Define a simple model building function.\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(4,)),\n",
    "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create optimizer and loss objects for training.\n",
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "# Define a function to compute per replica loss.\n",
    "def compute_loss(labels, predictions):\n",
    "    per_example_loss = loss_obj(labels, predictions)\n",
    "    return tf.nn.compute_average_loss(\n",
    "        per_example_loss, global_batch_size=64\n",
    "    )\n",
    "\n",
    "# Define one distributed training step function.\n",
    "@tf.function\n",
    "def distributed_train_step(dist_inputs):\n",
    "    def replica_step(inputs):\n",
    "        x, y = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(x, training=True)\n",
    "            loss = compute_loss(y, preds)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    per_replica_losses = strategy.run(replica_step, args=(dist_inputs,))\n",
    "    return strategy.reduce(\n",
    "        tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None\n",
    "    )\n",
    "\n",
    "# Run a very small training loop for demonstration.\n",
    "for epoch in range(2):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for batch in dist_ds:\n",
    "        loss = distributed_train_step(batch)\n",
    "        total_loss += loss.numpy()\n",
    "        num_batches += 1\n",
    "    avg_loss = total_loss / float(num_batches)\n",
    "    print(\"Epoch\", epoch, \"average loss:\", round(avg_loss, 4))\n",
    "\n",
    "# Evaluate the model briefly on a few samples.\n",
    "small_batch = features[:8]\n",
    "\n",
    "# Get predictions from the trained model.\n",
    "preds = model(small_batch, training=False)\n",
    "\n",
    "# Print predicted class indices for quick inspection.\n",
    "print(\"Predicted classes:\", tf.argmax(preds, axis=1).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a59724",
   "metadata": {},
   "source": [
    "### **1.3. TPU Strategy Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60871d6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_01_03.jpg?v=1769453669\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Uses TPUs to train huge models efficiently\n",
    ">* Automatically replicates models and hides hardware details\n",
    "\n",
    ">* TPUs run via managed cloud, preconfigured environments\n",
    ">* Strategy handles cores, suits large matrix-heavy models\n",
    "\n",
    ">* Best for large, high-throughput, TPU-shaped workloads\n",
    ">* Requires TPU-friendly batches; runtime manages orchestration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - TPU Strategy Basics\n",
    "\n",
    "# This script introduces basic TPU distribution strategy.\n",
    "# It runs safely even without real TPU hardware.\n",
    "# Focus on concepts using a tiny Keras example.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "random.seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "# Import TensorFlow and Keras utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Try to detect and initialize a TPU if available.\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    device_type = \"TPU\"\n",
    "except Exception:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    device_type = \"CPU_or_GPU\"\n",
    "\n",
    "# Print which distribution strategy is being used.\n",
    "print(\"Using strategy:\", type(strategy).__name__, \"on\", device_type)\n",
    "\n",
    "# Load a tiny subset of MNIST for quick training.\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Keep only a small number of samples.\n",
    "x_train = x_train[:2048]\n",
    "y_train = y_train[:2048]\n",
    "\n",
    "# Normalize and add channel dimension.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "\n",
    "# Validate shapes before building the model.\n",
    "print(\"Train shape:\", x_train.shape, \"Labels:\", y_train.shape)\n",
    "\n",
    "# Create a simple model building function.\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(16, (3, 3), activation=\"relu\",\n",
    "                            input_shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Define batch size and epochs for quick runs.\n",
    "GLOBAL_BATCH_SIZE = 128\n",
    "EPOCHS = 2\n",
    "\n",
    "# Build and train the model inside strategy scope.\n",
    "with strategy.scope():\n",
    "    model = create_model(input_shape=x_train.shape[1:],\n",
    "                         num_classes=10)\n",
    "\n",
    "# Train silently to avoid long logs.\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=GLOBAL_BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Fetch final loss and accuracy from history.\n",
    "final_loss = history.history[\"loss\"][-1]\n",
    "final_acc = history.history[\"accuracy\"][-1]\n",
    "\n",
    "# Print a short summary of training results.\n",
    "print(\"Final loss:\", round(float(final_loss), 4))\n",
    "print(\"Final accuracy:\", round(float(final_acc), 4))\n",
    "\n",
    "# Show how many replicas the strategy is using.\n",
    "print(\"Number of replicas in sync:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a45f39",
   "metadata": {},
   "source": [
    "## **2. Data Parallelism Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6568f",
   "metadata": {},
   "source": [
    "### **2.1. TensorFlow Replicas Explained**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1a70a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_02_01.jpg?v=1769453741\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Replicas are identical model copies running in parallel\n",
    ">* Each replica handles different data, enabling scalable training\n",
    "\n",
    ">* Replicas run the same step on different data\n",
    ">* Strategy coordinates, syncs results as one big model\n",
    "\n",
    ">* Each replica sees only its own mini-batch\n",
    ">* Together replicas approximate large-batch training, hiding details\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - TensorFlow Replicas Explained\n",
    "\n",
    "# This script explains TensorFlow replicas conceptually.\n",
    "# It uses MirroredStrategy with a tiny example.\n",
    "# Focus is on data parallelism and synchronization.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required modules from TensorFlow.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set a deterministic random seed value.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Detect available logical GPUs for demonstration.\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "\n",
    "# Decide number of devices used by strategy.\n",
    "num_devices = max(len(logical_gpus), 1)\n",
    "\n",
    "# Print how many devices will host replicas.\n",
    "print(\"Number of devices for replicas:\", num_devices)\n",
    "\n",
    "# Create a simple MirroredStrategy for data parallelism.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Print how many replicas the strategy will manage.\n",
    "print(\"Number of replicas in sync:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Define global batch size based on replica count.\n",
    "global_batch_size = 8 * strategy.num_replicas_in_sync\n",
    "\n",
    "# Create a tiny synthetic dataset for demonstration.\n",
    "features = tf.range(0, global_batch_size, dtype=tf.float32)\n",
    "\n",
    "# Create simple labels as double the features.\n",
    "labels = features * 2.0\n",
    "\n",
    "# Validate shapes to avoid broadcasting surprises.\n",
    "assert features.shape == labels.shape\n",
    "\n",
    "# Build a tf.data.Dataset from tensors.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Batch the dataset using the global batch size.\n",
    "base_ds = base_ds.batch(global_batch_size)\n",
    "\n",
    "# Distribute the dataset across replicas automatically.\n",
    "dist_ds = strategy.experimental_distribute_dataset(base_ds)\n",
    "\n",
    "# Define a very small linear model inside strategy scope.\n",
    "with strategy.scope():\n",
    "    # Create a simple Dense model for regression.\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "# Define a mean squared error loss function.\n",
    "loss_obj = tf.keras.losses.MeanSquaredError(reduction=\"none\")\n",
    "\n",
    "# Create an optimizer with a small learning rate.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# Define per replica loss scaled by global batch size.\n",
    "def compute_loss(labels_replica, preds_replica):\n",
    "    # Compute unreduced loss for each example.\n",
    "    per_example_loss = loss_obj(labels_replica, preds_replica)\n",
    "    # Scale loss by global batch size value.\n",
    "    return tf.nn.compute_average_loss(\n",
    "        per_example_loss, global_batch_size=global_batch_size\n",
    "    )\n",
    "\n",
    "# Define one training step run on each replica.\n",
    "@tf.function\n",
    "def train_step(dist_inputs):\n",
    "    # Unpack distributed features and labels.\n",
    "    dist_x, dist_y = dist_inputs\n",
    "\n",
    "    # Define replica computation using strategy.run.\n",
    "    def replica_step(x_replica, y_replica):\n",
    "        # Reshape inputs to match model expectations.\n",
    "        x_replica = tf.reshape(x_replica, (-1, 1))\n",
    "        y_replica = tf.reshape(y_replica, (-1, 1))\n",
    "        # Forward pass to compute predictions.\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(x_replica, training=True)\n",
    "            loss = compute_loss(y_replica, preds)\n",
    "        # Compute gradients for model variables.\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # Apply gradients to update shared weights.\n",
    "        optimizer.apply_gradients(\n",
    "            zip(grads, model.trainable_variables)\n",
    "        )\n",
    "        # Return the per replica loss value.\n",
    "        return loss\n",
    "\n",
    "    # Run replica_step on each replica in parallel.\n",
    "    per_replica_losses = strategy.run(\n",
    "        replica_step, args=(dist_x, dist_y)\n",
    "    )\n",
    "\n",
    "    # Reduce losses to get a single scalar value.\n",
    "    mean_loss = strategy.reduce(\n",
    "        tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None\n",
    "    )\n",
    "\n",
    "    # Return the synchronized mean loss.\n",
    "    return mean_loss\n",
    "\n",
    "# Take one batch from the distributed dataset.\n",
    "for batch in iter(dist_ds):\n",
    "    # Run a single distributed training step.\n",
    "    initial_loss = float(train_step(batch))\n",
    "    break\n",
    "\n",
    "# Print the loss after one synchronized update.\n",
    "print(\"Loss after one distributed step:\", round(initial_loss, 4))\n",
    "\n",
    "# Show current model weight to illustrate shared parameters.\n",
    "current_weight = float(model.layers[0].kernel[0, 0])\n",
    "\n",
    "# Print the shared weight value used by all replicas.\n",
    "print(\"Shared model weight after update:\", round(current_weight, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b99fd",
   "metadata": {},
   "source": [
    "### **2.2. All Reduce Gradients**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0269b58",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_02_02.jpg?v=1769453845\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* All-reduce gathers and combines gradients from replicas\n",
    ">* Shared gradients keep all model copies synchronized\n",
    "\n",
    ">* All-reduce combines gradients then shares results everywhere\n",
    ">* Different algorithms trade communication cost and performance\n",
    "\n",
    ">* All-reduce makes replicas act like one model\n",
    ">* Gradients are averaged so weights match after updates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e427c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - All Reduce Gradients\n",
    "\n",
    "# This script illustrates all reduce gradient behavior.\n",
    "# It uses tf.distribute.MirroredStrategy with simple data.\n",
    "# Focus is on synchronized gradient averaging across replicas.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import TensorFlow and basic utilities.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Create a MirroredStrategy for data parallel training.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Replicas in sync:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Define global batch size and per replica batch size.\n",
    "global_batch_size = 4\n",
    "per_replica_batch = global_batch_size // max(strategy.num_replicas_in_sync, 1)\n",
    "\n",
    "# Create tiny synthetic features and labels.\n",
    "features = tf.constant([[1.0], [2.0], [3.0], [4.0]], dtype=tf.float32)\n",
    "labels = tf.constant([[2.0], [4.0], [6.0], [8.0]], dtype=tf.float32)\n",
    "\n",
    "# Validate shapes before building dataset.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "assert features.shape[0] == global_batch_size\n",
    "\n",
    "# Build a small dataset and batch it once.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "dataset = dataset.batch(global_batch_size, drop_remainder=True)\n",
    "\n",
    "# Distribute the dataset across replicas.\n",
    "dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "# Define a simple linear model inside strategy scope.\n",
    "with strategy.scope():\n",
    "    # Single dense layer represents y = wx + b.\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1, use_bias=True, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "    # Use mean squared error loss function.\n",
    "    loss_obj = tf.keras.losses.MeanSquaredError(\n",
    "        reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    # Use a simple SGD optimizer.\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# Define a function to compute per example loss.\n",
    "def compute_loss(labels, predictions):\n",
    "    per_example_loss = loss_obj(labels, predictions)\n",
    "    return tf.nn.compute_average_loss(\n",
    "        per_example_loss, global_batch_size=global_batch_size\n",
    "    )\n",
    "\n",
    "# Define one training step run on each replica.\n",
    "@tf.function\n",
    "def distributed_train_step(dist_inputs):\n",
    "    # Run the replica step on each replica.\n",
    "    per_replica_losses, per_replica_grads = strategy.run(\n",
    "        replica_step, args=(dist_inputs,)\n",
    "    )\n",
    "\n",
    "    # Reduce losses across replicas for reporting.\n",
    "    mean_loss = strategy.reduce(\n",
    "        tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None\n",
    "    )\n",
    "\n",
    "    # Gradients are already reduced by optimizer.apply_gradients.\n",
    "    return mean_loss, per_replica_grads\n",
    "\n",
    "# Define the replica computation including gradient calculation.\n",
    "def replica_step(inputs):\n",
    "    features_replica, labels_replica = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features_replica, training=True)\n",
    "        loss = compute_loss(labels_replica, predictions)\n",
    "\n",
    "    # Compute gradients of loss with respect to trainable variables.\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss, grads\n",
    "\n",
    "# Take one batch from the distributed dataset.\n",
    "for batch in dist_dataset:\n",
    "    first_batch = batch\n",
    "    break\n",
    "\n",
    "# Run a single distributed training step.\n",
    "mean_loss_value, per_replica_grads = distributed_train_step(first_batch)\n",
    "\n",
    "# Collect gradients from each replica for the kernel weight.\n",
    "kernel_grads = strategy.experimental_local_results(per_replica_grads[0])\n",
    "\n",
    "# Print mean loss after one synchronized step.\n",
    "print(\"Mean loss after one step:\", float(mean_loss_value))\n",
    "\n",
    "# Print per replica gradient values for the kernel.\n",
    "for idx, g in enumerate(kernel_grads):\n",
    "    print(\"Replica\", idx, \"kernel grad:\", float(g.numpy()[0][0]))\n",
    "\n",
    "# Print final shared kernel weight to show synchronization.\n",
    "print(\"Shared kernel weight:\", float(model.trainable_variables[0].numpy()[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6a0cc",
   "metadata": {},
   "source": [
    "### **2.3. Sync and Async Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027cc34",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_02_03.jpg?v=1769453881\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Synchronous training updates shared weights in lockstep\n",
    ">* All replicas match weights; speed limited by stragglers\n",
    "\n",
    ">* Replicas update shared weights independently, improving utilization\n",
    ">* Stale weights add noise, slowing and complicating convergence\n",
    "\n",
    ">* Synchronous training dominates on tightly connected accelerators\n",
    ">* Asynchronous suits loosely coupled systems, trading stability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cb0e0",
   "metadata": {},
   "source": [
    "## **3. Adjusting Code for Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e956308",
   "metadata": {},
   "source": [
    "### **3.1. Strategy Scope Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae2484",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_03_01.jpg?v=1769453896\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Strategy scope controls variable placement and execution\n",
    ">* Inside scope is distributed; outside remains regular\n",
    "\n",
    ">* Create models and variables inside strategy scope\n",
    ">* Keep local utilities outside to avoid sync bugs\n",
    "\n",
    ">* Put variable and gradient logic inside scope\n",
    ">* Keep replica-aware metrics and steps under strategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Strategy Scope Basics\n",
    "\n",
    "# This script shows basic strategy scope usage.\n",
    "# It compares non distributed and distributed model creation.\n",
    "# Focus on where we enter and exit strategy scope.\n",
    "\n",
    "# Uncomment next line if TensorFlow is not installed.\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required modules from TensorFlow.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set a deterministic global random seed.\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a simple function that builds a small model.\n",
    "def build_simple_model(input_shape, num_classes):\n",
    "    # Create a sequential model with two dense layers.\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=input_shape),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    # Compile the model with optimizer and loss.\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Prepare a tiny dummy dataset for quick demonstration.\n",
    "num_samples, num_features, num_classes = 32, 8, 3\n",
    "\n",
    "# Create random features and integer labels.\n",
    "features = tf.random.normal(shape=(num_samples, num_features))\n",
    "labels = tf.random.uniform(\n",
    "    shape=(num_samples,), minval=0, maxval=num_classes, dtype=tf.int32\n",
    ")\n",
    "\n",
    "# Validate shapes before using the tensors.\n",
    "assert features.shape == (num_samples, num_features)\n",
    "assert labels.shape == (num_samples,)\n",
    "\n",
    "# Build and train a model without any distribution strategy.\n",
    "plain_model = build_simple_model((num_features,), num_classes)\n",
    "\n",
    "# Train briefly with verbose set to zero.\n",
    "plain_model.fit(features, labels, epochs=1, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluate once and print a compact result line.\n",
    "plain_loss, plain_acc = plain_model.evaluate(\n",
    "    features, labels, verbose=0\n",
    ")\n",
    "print(\"Plain model accuracy:\", round(float(plain_acc), 4))\n",
    "\n",
    "# Create a MirroredStrategy for simple data parallel training.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Enter the strategy scope for distributed variable creation.\n",
    "with strategy.scope():\n",
    "    dist_model = build_simple_model((num_features,), num_classes)\n",
    "\n",
    "# Train the distributed model using the same data.\n",
    "dist_model.fit(features, labels, epochs=1, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluate the distributed model silently.\n",
    "dist_loss, dist_acc = dist_model.evaluate(\n",
    "    features, labels, verbose=0\n",
    ")\n",
    "\n",
    "# Print a short comparison of both accuracies.\n",
    "print(\"Distributed model accuracy:\", round(float(dist_acc), 4))\n",
    "\n",
    "# Show that both models share the same input data shape.\n",
    "print(\"Input feature shape:\", features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3687776f",
   "metadata": {},
   "source": [
    "### **3.2. Distributed input pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94072c",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_03_02.jpg?v=1769453931\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Distributed training requires a shared, central dataset pipeline\n",
    ">* Strategy splits global batches and routes data automatically\n",
    "\n",
    ">* Set a global batch, split across replicas\n",
    ">* Build and transform dataset once before distribution\n",
    "\n",
    ">* Use shared datasets with deterministic sharding per worker\n",
    ">* Centralize randomness to avoid inconsistent, leaky training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4769d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Distributed input pipelines\n",
    "\n",
    "# This script shows distributed input pipelines basics.\n",
    "# It compares non distributed and distributed dataset usage.\n",
    "# Focus is on tf distribute and batching behavior.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and check version.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Detect available GPUs for potential distribution.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "num_gpus = len(physical_gpus)\n",
    "print(\"Number of GPUs detected:\", num_gpus)\n",
    "\n",
    "# Create a simple synthetic dataset using NumPy.\n",
    "num_samples = 32\n",
    "features = np.arange(num_samples, dtype=np.float32).reshape((-1, 1))\n",
    "labels = (features * 2.0).astype(np.float32)\n",
    "\n",
    "# Wrap NumPy arrays into a tf.data Dataset.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Define a small global batch size for demonstration.\n",
    "global_batch_size = 8\n",
    "\n",
    "# Build the input pipeline with shuffle and batch.\n",
    "train_ds = (base_ds.shuffle(buffer_size=num_samples, seed=seed_value)\n",
    "            .batch(global_batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# Show one batch shape in the non distributed case.\n",
    "for batch_x, batch_y in train_ds.take(1):\n",
    "    print(\"Single device batch shape:\", batch_x.shape)\n",
    "\n",
    "# Choose a distribution strategy based on available GPUs.\n",
    "if num_gpus > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "\n",
    "# Print the number of replicas in the strategy.\n",
    "print(\"Replicas in sync:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Create a distributed dataset from the base dataset.\n",
    "with strategy.scope():\n",
    "    dist_ds = (base_ds.shuffle(buffer_size=num_samples, seed=seed_value)\n",
    "               .batch(global_batch_size)\n",
    "               .prefetch(tf.data.AUTOTUNE))\n",
    "    dist_ds = strategy.experimental_distribute_dataset(dist_ds)\n",
    "\n",
    "# Inspect one distributed batch and per replica shapes.\n",
    "# \"DistributedDataset\" in this TF version does not implement \"take\".\n",
    "# Convert to an iterator and manually take one batch instead.\n",
    "_dist_iter = iter(dist_ds)\n",
    "for dist_batch_x, dist_batch_y in [_dist_iter.__next__()]:\n",
    "    def show_replica_shape(x):\n",
    "        return tf.shape(x)\n",
    "\n",
    "    per_replica_shapes = strategy.run(show_replica_shape, args=(dist_batch_x,))\n",
    "    # dist_batch_x is already a PerReplica; just use its first replica to infer global batch size.\n",
    "    any_replica = tf.nest.flatten(dist_batch_x)[0]\n",
    "    print(\"Global batch shape:\", tf.shape(any_replica) * 0 + global_batch_size)\n",
    "    print(\"Per replica shapes:\", per_replica_shapes)\n",
    "\n",
    "# Build a tiny model inside the strategy scope.\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
    "\n",
    "# Train briefly to show the pipeline works with strategy.\n",
    "history = model.fit(dist_ds, epochs=1, steps_per_epoch=2, verbose=0)\n",
    "\n",
    "# Print final loss from the short distributed training.\n",
    "print(\"Final distributed training loss:\", float(history.history[\"loss\"][-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4bbf2",
   "metadata": {},
   "source": [
    "### **3.3. Batch Size Semantics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbf3e2",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master TensorFlow 2.20.0/Module_08/Lecture_A/image_03_03.jpg?v=1769454005\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Understand batch size meaning changes with distribution\n",
    ">* Distinguish global and per-replica batch sizes\n",
    "\n",
    ">* Set a global batch; strategy splits automatically\n",
    ">* Optimizer updates per global batch keep training consistent\n",
    "\n",
    ">* Larger global batches change optimization and generalization behavior\n",
    ">* Balance device memory, throughput, and training dynamics carefully\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Batch Size Semantics\n",
    "\n",
    "# This script illustrates batch size semantics simply.\n",
    "# It compares global and per replica batch sizes clearly.\n",
    "# It uses MirroredStrategy with a tiny synthetic dataset.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required modules for TensorFlow and numpy.\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic seeds for reproducible behavior.\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Print TensorFlow version in one concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Detect available GPUs and print a short summary.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Num GPUs detected:\", len(physical_gpus))\n",
    "\n",
    "# Choose strategy based on GPU availability for clarity.\n",
    "if len(physical_gpus) > 0:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/cpu:0\")\n",
    "\n",
    "# Print the number of replicas used by the strategy.\n",
    "print(\"Replicas in sync:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Define a small global batch size for demonstration.\n",
    "global_batch_size = 8\n",
    "print(\"Global batch size:\", global_batch_size)\n",
    "\n",
    "# Compute per replica batch size from global and replicas.\n",
    "per_replica_batch = global_batch_size // strategy.num_replicas_in_sync\n",
    "print(\"Per replica batch size:\", per_replica_batch)\n",
    "\n",
    "# Create a tiny synthetic dataset of simple features.\n",
    "num_examples = 32\n",
    "features = np.arange(num_examples, dtype=\"float32\").reshape(-1, 1)\n",
    "labels = (features * 0.5 + 1.0).astype(\"float32\")\n",
    "\n",
    "# Validate shapes before building the TensorFlow dataset.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "assert features.shape[1] == 1 and labels.shape[1] == 1\n",
    "\n",
    "# Build a tf.data.Dataset and batch with global size.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "base_ds = base_ds.batch(global_batch_size, drop_remainder=True)\n",
    "\n",
    "# Distribute the dataset using the chosen strategy.\n",
    "dist_ds = strategy.experimental_distribute_dataset(base_ds)\n",
    "\n",
    "# Define a simple model building function inside strategy.\n",
    "with strategy.scope():\n",
    "    # Create a minimal dense model for demonstration.\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "# Compile the model with a basic optimizer and loss.\n",
    "with strategy.scope():\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "        loss=\"mse\",\n",
    "        run_eagerly=False\n",
    "    )\n",
    "\n",
    "# Train for a single epoch with silent logging.\n",
    "history = model.fit(\n",
    "    dist_ds,\n",
    "    epochs=1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Take one distributed batch and inspect per replica shapes.\n",
    "for batch_features, batch_labels in iter(dist_ds):\n",
    "    per_replica_features = batch_features\n",
    "    per_replica_labels = batch_labels\n",
    "    break\n",
    "\n",
    "# Convert per replica tensors to a list for inspection.\n",
    "feature_parts = strategy.experimental_local_results(per_replica_features)\n",
    "label_parts = strategy.experimental_local_results(per_replica_labels)\n",
    "\n",
    "# Print how the global batch is split across replicas.\n",
    "print(\"Number of feature parts:\", len(feature_parts))\n",
    "print(\"Shape of first part:\", feature_parts[0].shape)\n",
    "print(\"Shape of global batch:\", feature_parts[0].shape)\n",
    "\n",
    "# Print a small sample to confirm correct slicing behavior.\n",
    "print(\"First replica feature sample:\", feature_parts[0][0].numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb3cfa",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Distribution Basics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0053186",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Describe the main tf.distribute strategies available in TensorFlow 2.20.0 and their typical use cases. \n",
    "- Explain how data parallelism and replica synchronization work in distributed training. \n",
    "- Identify the changes required in model and input code to support distribution strategies. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Implementing Strategies'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
