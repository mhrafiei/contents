{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144b786a",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Environment Setup**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d696e20",
   "metadata": {},
   "source": [
    ">Last update: 20260128.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Install PyTorch 2.10.0 with appropriate CUDA or CPU support on the target platform. \n",
    "- Configure a Python development environment suitable for PyTorch projects, including virtual environments and key extensions. \n",
    "- Organize a basic PyTorch project folder structure that supports experiments, logging, and version control. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335cc2d",
   "metadata": {},
   "source": [
    "## **1. Install PyTorch Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c71da",
   "metadata": {},
   "source": [
    "### **1.1. PyTorch Install Commands**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dbd684",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_01_01.jpg?v=1769650144\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Match install command to OS and hardware\n",
    ">* Use website selector to generate correct command\n",
    "\n",
    ">* Choose pip or conda based on environment\n",
    ">* Run generated command for correct version and build\n",
    "\n",
    ">* Choose commands for laptop, server, or cloud\n",
    ">* Match command to Python, OS, and hardware\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54629b02",
   "metadata": {},
   "source": [
    "### **1.2. CUDA Compatibility Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146cf98",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_01_02.jpg?v=1769650164\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* CUDA, driver, and GPU must match PyTorch\n",
    ">* Aligned versions ensure GPU acceleration instead of CPU\n",
    "\n",
    ">* NVIDIA driver version must match CUDA PyTorch build\n",
    ">* Always confirm driver is new enough before installing\n",
    "\n",
    ">* Choose CUDA or CPU builds by hardware\n",
    ">* Match installs to GPU support and workflow constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - CUDA Compatibility Overview\n",
    "\n",
    "# This script explains CUDA compatibility basics.\n",
    "# It uses TensorFlow to inspect GPU availability.\n",
    "# You can compare results to choose PyTorch build.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import standard library modules safely.\n",
    "import os\n",
    "import textwrap\n",
    "import random\n",
    "\n",
    "# Import numpy for simple numeric checks.\n",
    "import numpy as np\n",
    "\n",
    "# Try importing tensorflow and handle failures.\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except Exception as import_error:\n",
    "    tf = None\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define a helper to print a wrapped section title.\n",
    "def print_title(title_text: str) -> None:\n",
    "    wrapped = textwrap.fill(title_text, width=60)\n",
    "    print(\"\\n\" + wrapped)\n",
    "\n",
    "# Define a helper to safely get environment info.\n",
    "def get_env_info() -> dict:\n",
    "    info = {}\n",
    "    info[\"python_version\"] = (\n",
    "        f\"{os.sys.version_info.major}.\" f\"{os.sys.version_info.minor}\"\n",
    "    )\n",
    "    info[\"tf_available\"] = bool(tf is not None)\n",
    "    return info\n",
    "\n",
    "# Define a helper to summarize detected GPU devices.\n",
    "def get_gpu_summary() -> dict:\n",
    "    summary = {\"gpus\": [], \"gpu_count\": 0}\n",
    "    if tf is None:\n",
    "        return summary\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    except Exception:\n",
    "        gpus = []\n",
    "    summary[\"gpus\"] = [str(device) for device in gpus]\n",
    "    summary[\"gpu_count\"] = len(gpus)\n",
    "    return summary\n",
    "\n",
    "# Define a helper to suggest PyTorch build choice.\n",
    "def suggest_pytorch_build(gpu_count: int) -> str:\n",
    "    if gpu_count == 0:\n",
    "        return \"Suggested PyTorch build: CPU only (no CUDA).\"\n",
    "    return (\n",
    "        \"Suggested PyTorch build: CUDA enabled, \"\n",
    "        \"matching your driver supported CUDA.\"\n",
    "    )\n",
    "\n",
    "# Collect environment and GPU information.\n",
    "env_info = get_env_info()\n",
    "gpu_info = get_gpu_summary()\n",
    "\n",
    "# Print a short title about CUDA compatibility.\n",
    "print_title(\"CUDA compatibility starts with checking your hardware.\")\n",
    "\n",
    "# Print basic Python and TensorFlow availability.\n",
    "print(\n",
    "    \"Python version:\",\n",
    "    env_info[\"python_version\"],\n",
    "    \"| TensorFlow available:\",\n",
    "    env_info[\"tf_available\"],\n",
    ")\n",
    "\n",
    "# Print TensorFlow version if available for reference.\n",
    "if tf is not None:\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "else:\n",
    "    print(\"TensorFlow not available, GPU check limited.\")\n",
    "\n",
    "# Print how many GPUs TensorFlow can see.\n",
    "print(\"Detected GPU count:\", gpu_info[\"gpu_count\"])\n",
    "\n",
    "# If there is at least one GPU, show the first device.\n",
    "if gpu_info[\"gpu_count\"] > 0:\n",
    "    print(\"Example GPU device:\", gpu_info[\"gpus\"][0])\n",
    "else:\n",
    "    print(\"No GPU devices detected by TensorFlow.\")\n",
    "\n",
    "# Print a suggestion about which PyTorch build to install.\n",
    "print(suggest_pytorch_build(gpu_info[\"gpu_count\"]))\n",
    "\n",
    "# Print a final reminder about matching CUDA and drivers.\n",
    "print(\n",
    "    \"Reminder: Match PyTorch CUDA build with your\", \"NVIDIA driver capabilities.\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b1f1d",
   "metadata": {},
   "source": [
    "### **1.3. Verifying Installation Script**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b37a03",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_01_03.jpg?v=1769650304\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Verify script creates a reliable, usable environment\n",
    ">* Ensure correct version, backend, and no hidden issues\n",
    "\n",
    ">* Run automated checks after environment creation\n",
    ">* Validate version, backend, tensor ops, and reliability\n",
    "\n",
    ">* Test scripts on all target environments regularly\n",
    ">* Automate checks and refine based on clear feedback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Verifying Installation Script\n",
    "\n",
    "# This script verifies a basic PyTorch style environment.\n",
    "# It focuses on simple checks and clear feedback.\n",
    "# Use it after running your installation setup script.\n",
    "\n",
    "# Import standard libraries for system inspection.\n",
    "import sys\n",
    "import platform\n",
    "import textwrap\n",
    "\n",
    "\n",
    "# Define a small helper to print section titles.\n",
    "def print_title(title):\n",
    "    line = \"=\" * len(title)\n",
    "    print(f\"\\n{title}\\n{line}\")\n",
    "\n",
    "# Try importing torch and capture any import error.\n",
    "try:\n",
    "    import importlib\n",
    "    torch_spec = importlib.util.find_spec(\"torch\")\n",
    "    torch = importlib.import_module(\"torch\") if torch_spec else None\n",
    "except Exception as exc:\n",
    "    torch = None\n",
    "    import_error = exc\n",
    "else:\n",
    "    import_error = None\n",
    "\n",
    "# Print basic Python and platform information.\n",
    "print_title(\"Python and platform info\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "\n",
    "# Check whether torch is importable and report status.\n",
    "print_title(\"PyTorch import check\")\n",
    "if torch is None:\n",
    "    print(\"PyTorch is NOT available in this environment.\")\n",
    "    print(\"Check your installation script and rerun it.\")\n",
    "else:\n",
    "    print(\"PyTorch import succeeded without errors.\")\n",
    "\n",
    "# If torch is missing, stop further checks early.\n",
    "if torch is None:\n",
    "    sys.exit(0)\n",
    "\n",
    "# Show the installed PyTorch version in one short line.\n",
    "print_title(\"PyTorch version check\")\n",
    "print(f\"Detected torch.__version__: {torch.__version__}\")\n",
    "\n",
    "# Define the expected major and minor version numbers.\n",
    "EXPECTED_MAJOR = 2\n",
    "EXPECTED_MINOR = 10\n",
    "\n",
    "# Parse the version string defensively and compare parts.\n",
    "version_parts = torch.__version__.split(\"+\")[0].split(\".\")\n",
    "major = int(version_parts[0]) if len(version_parts) > 0 else 0\n",
    "minor = int(version_parts[1]) if len(version_parts) > 1 else 0\n",
    "\n",
    "# Report whether the version matches the expected target.\n",
    "if major == EXPECTED_MAJOR and minor == EXPECTED_MINOR:\n",
    "    print(\"Version matches expected PyTorch 2.10.x series.\")\n",
    "else:\n",
    "    print(\"Version differs from expected PyTorch 2.10.x.\")\n",
    "\n",
    "# Check which compute backend is available on this system.\n",
    "print_title(\"Backend availability check\")\n",
    "has_cuda = hasattr(torch, \"cuda\") and torch.cuda.is_available()\n",
    "backend = \"CUDA\" if has_cuda else \"CPU only\"\n",
    "print(f\"Detected backend: {backend}\")\n",
    "\n",
    "# If CUDA is available, show basic device information.\n",
    "if has_cuda:\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"CUDA device 0 name: {device_name}\")\n",
    "\n",
    "# Run a tiny tensor computation to verify core behavior.\n",
    "print_title(\"Tensor operation smoke test\")\n",
    "import math\n",
    "\n",
    "# Create a small tensor on the appropriate device.\n",
    "device = torch.device(\"cuda:0\") if has_cuda else torch.device(\"cpu\")\n",
    "values = torch.tensor([1.0, 2.0, 3.0, 4.0], device=device)\n",
    "\n",
    "# Perform a simple deterministic computation on the tensor.\n",
    "result = values.square().sum().item()\n",
    "expected = sum(v * v for v in [1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "# Validate that the numerical result matches expectation.\n",
    "if math.isclose(result, expected, rel_tol=1e-6, abs_tol=1e-6):\n",
    "    print(\"Tensor computation succeeded with correct result.\")\n",
    "else:\n",
    "    print(\"Tensor computation produced an unexpected result.\")\n",
    "\n",
    "# Summarize overall verification outcome in a final message.\n",
    "print_title(\"Verification summary\")\n",
    "summary_lines = []\n",
    "\n",
    "# Build a short human friendly summary list.\n",
    "summary_lines.append(\n",
    "    \"PyTorch import: OK\" if torch is not None else \"PyTorch import: FAILED\"\n",
    ")\n",
    "summary_lines.append(\n",
    "    f\"Version: {torch.__version__}\" if torch is not None else \"Version: unknown\"\n",
    ")\n",
    "summary_lines.append(f\"Backend: {backend}\")\n",
    "\n",
    "# Wrap and print the summary as a compact paragraph.\n",
    "summary_text = \"; \".join(summary_lines)\n",
    "print(textwrap.fill(summary_text, width=70))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8523e4",
   "metadata": {},
   "source": [
    "## **2. Python Dev Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355038d",
   "metadata": {},
   "source": [
    "### **2.1. Virtual Environments Choice**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25d831",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_02_01.jpg?v=1769650393\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use virtual environments to isolate PyTorch dependencies\n",
    ">* Pick one env tool and use it consistently\n",
    "\n",
    ">* Different env tools suit different workflows, contexts\n",
    ">* Pick one you understand, document, and replicate\n",
    "\n",
    ">* Pick tools that match collaboration and deployment\n",
    ">* Use clean, per-project environments as configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb314f",
   "metadata": {},
   "source": [
    "### **2.2. VS Code and Jupyter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d6bac",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_02_02.jpg?v=1769650418\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* VS Code plus Jupyter supports fast PyTorch prototyping\n",
    ">* Same setup scales to debugging and team collaboration\n",
    "\n",
    ">* Python and Jupyter extensions boost coding accuracy\n",
    ">* Tight integration streamlines notebooks, scripts, and experiments\n",
    "\n",
    ">* Debugger and breakpoints help inspect PyTorch training\n",
    ">* Shared configs support teamwork and scalable workflows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0924c",
   "metadata": {},
   "source": [
    "### **2.3. Dependency Management Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa3940",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_02_03.jpg?v=1769650435\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Track exact package versions for consistent behavior\n",
    ">* Avoid broken, irreproducible, or inconsistent model runs\n",
    "\n",
    ">* Treat each projectâ€™s environment as versioned assets\n",
    ">* Record exact package versions to ensure reproducibility\n",
    "\n",
    ">* Controlled dependencies enable safe experimentation and cleanup\n",
    ">* Recorded environments simplify reproduction, collaboration, and deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b36327",
   "metadata": {},
   "source": [
    "## **3. PyTorch Project Structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce34e7c",
   "metadata": {},
   "source": [
    "### **3.1. Source and Tests Layout**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0bca9a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_03_01.jpg?v=1769650454\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Keep PyTorch source code in a dedicated folder\n",
    ">* Separate from tests, scripts, data, and configs\n",
    "\n",
    ">* Mirror source structure inside a dedicated tests directory\n",
    ">* Write tests per module for behavior and automation\n",
    "\n",
    ">* Clear source and tests enable advanced workflows\n",
    ">* Stronger tests make experimentation and upgrades safer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e7fe5c",
   "metadata": {},
   "source": [
    "### **3.2. Configs and Logs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f12450",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_03_02.jpg?v=1769650473\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Keep configs and logs in dedicated folders\n",
    ">* Configs separate settings, enabling easy reproducible runs\n",
    "\n",
    ">* Use readable formats like YAML, JSON, TOML\n",
    ">* Organize configs per experiment, with shared bases\n",
    "\n",
    ">* Use dedicated run folders for logs, checkpoints\n",
    ">* Organized logs plus configs enable comparison and reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0966a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Configs and Logs\n",
    "\n",
    "# This script shows configs and logs structure.\n",
    "# It creates folders and simple config examples.\n",
    "# It also simulates saving a tiny run log.\n",
    "\n",
    "# !pip install pyyaml.\n",
    "\n",
    "# Import standard library modules for paths.\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set a deterministic random seed value.\n",
    "random.seed(42)\n",
    "\n",
    "# Define a base project directory name.\n",
    "PROJECT_ROOT = \"pytorch_project_demo\"\n",
    "\n",
    "# Define subdirectories for configs and logs.\n",
    "CONFIG_DIR = os.path.join(PROJECT_ROOT, \"configs\")\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT, \"logs\")\n",
    "\n",
    "# Create a helper function for safe directory creation.\n",
    "def create_dir(path: str) -> None:\n",
    "    # Create directory if it does not already exist.\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Create the main project directory.\n",
    "create_dir(PROJECT_ROOT)\n",
    "\n",
    "# Create the configuration and logging directories.\n",
    "create_dir(CONFIG_DIR)\n",
    "create_dir(LOG_DIR)\n",
    "\n",
    "# Define two simple configuration dictionaries.\n",
    "baseline_config = {\n",
    "    \"experiment_name\": \"baseline_cnn\",\n",
    "    \"dataset\": \"FakeImagesSmall\",\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 0.001,\n",
    "}\n",
    "\n",
    "# Define a slightly different configuration variant.\n",
    "transformer_config = {\n",
    "    \"experiment_name\": \"tiny_transformer\",\n",
    "    \"dataset\": \"FakeImagesSmall\",\n",
    "    \"batch_size\": 8,\n",
    "    \"learning_rate\": 0.0005,\n",
    "}\n",
    "\n",
    "# Helper function to save a config as JSON file.\n",
    "def save_config(config: dict, filename: str) -> str:\n",
    "    # Build full path inside the config directory.\n",
    "    path = os.path.join(CONFIG_DIR, filename)\n",
    "    # Write the configuration dictionary to disk.\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    return path\n",
    "\n",
    "# Save both configuration files to the configs folder.\n",
    "baseline_path = save_config(baseline_config, \"baseline_cnn.json\")\n",
    "transformer_path = save_config(transformer_config, \"tiny_transformer.json\")\n",
    "\n",
    "# Choose one configuration to simulate a training run.\n",
    "active_config = baseline_config\n",
    "\n",
    "# Build a run folder name using experiment and seed.\n",
    "run_name = f\"{active_config['experiment_name']}_seed42\"\n",
    "\n",
    "# Create the run specific log directory.\n",
    "run_dir = os.path.join(LOG_DIR, run_name)\n",
    "create_dir(run_dir)\n",
    "\n",
    "# Define a tiny fake training history dictionary.\n",
    "training_history = {\n",
    "    \"epochs\": [1, 2, 3],\n",
    "    \"train_loss\": [0.9, 0.6, 0.4],\n",
    "    \"val_loss\": [1.0, 0.7, 0.5],\n",
    "}\n",
    "\n",
    "# Save the history as a JSON log file.\n",
    "history_path = os.path.join(run_dir, \"history.json\")\n",
    "with open(history_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "\n",
    "# Save a tiny text summary for quick inspection.\n",
    "summary_path = os.path.join(run_dir, \"summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Experiment: \" + active_config[\"experiment_name\"] + \"\\n\")\n",
    "    f.write(\"Epochs: \" + str(len(training_history[\"epochs\"])) + \"\\n\")\n",
    "\n",
    "# Collect a compact overview of created paths.\n",
    "created_items = [\n",
    "    (\"Project root\", PROJECT_ROOT),\n",
    "    (\"Config directory\", CONFIG_DIR),\n",
    "    (\"Log directory\", LOG_DIR),\n",
    "    (\"Baseline config\", baseline_path),\n",
    "    (\"Transformer config\", transformer_path),\n",
    "    (\"Run directory\", run_dir),\n",
    "    (\"History log\", history_path),\n",
    "    (\"Summary file\", summary_path),\n",
    "]\n",
    "\n",
    "# Print a short overview of the project structure.\n",
    "for label, path in created_items:\n",
    "    print(f\"{label}: {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c9118",
   "metadata": {},
   "source": [
    "### **3.3. Git and Ignore Files**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f820c5",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_01/Lecture_B/image_03_03.jpg?v=1769650554\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use Git to track all project changes\n",
    ">* History enables rollback, collaboration, and reproducibility\n",
    "\n",
    ">* Ignore files exclude generated, machine-specific, huge artifacts\n",
    ">* Keeps repo small, focused on core project\n",
    "\n",
    ">* Shared ignore rules prevent environment-specific clutter\n",
    ">* Clean repos improve collaboration and experiment reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1c58d",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Environment Setup**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f187e6",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Install PyTorch 2.10.0 with appropriate CUDA or CPU support on the target platform. \n",
    "- Configure a Python development environment suitable for PyTorch projects, including virtual environments and key extensions. \n",
    "- Organize a basic PyTorch project folder structure that supports experiments, logging, and version control. \n",
    "\n",
    "In the next Lecture (Lecture C), we will go over 'Tensors Fundamentals'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
