{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f47a2d4",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Datasets and Loaders**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009fb9db",
   "metadata": {},
   "source": [
    ">Last update: 20260129.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Implement custom PyTorch Dataset classes that load and preprocess samples on demand. \n",
    "- Configure DataLoader instances with appropriate batch sizes, shuffling, and multiprocessing workers. \n",
    "- Use built‑in datasets from torchvision and torchtext as quick starting points for experiments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f10c8a",
   "metadata": {},
   "source": [
    "## **1. Custom Dataset Design**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55a10b",
   "metadata": {},
   "source": [
    "### **1.1. Map and Iterable Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8050cf",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_01_01.jpg?v=1769669722\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Map datasets give index-based random access\n",
    ">* Best for fixed collections and supervised training\n",
    "\n",
    ">* Treat data as a one-way streaming sequence\n",
    ">* Supports huge, unbounded, or hard-to-index datasets\n",
    "\n",
    ">* Map datasets enable shuffling, subsets, efficient sampling\n",
    ">* Iterable datasets suit complex streams without random access\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27345bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Map and Iterable Datasets\n",
    "\n",
    "# This script compares map and iterable datasets.\n",
    "# It uses tiny synthetic data for clarity.\n",
    "# Run cells sequentially to follow explanations.\n",
    "\n",
    "# Optional install for PyTorch if missing.\n",
    "# !pip install torch torchvision --quiet.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "# Import torch and dataset utilities.\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define a simple map style dataset.\n",
    "class SquareMapDataset(Dataset):\n",
    "    # Initialize with a fixed size.\n",
    "    def __init__(self, size: int = 10):\n",
    "        self.size = int(size)\n",
    "\n",
    "    # Return dataset length for indexing.\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    # Get one item by integer index.\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        if index < 0 or index >= self.size:\n",
    "            raise IndexError(\"index out of range\")\n",
    "        value = float(index)\n",
    "        return torch.tensor([value, value ** 2], dtype=torch.float32)\n",
    "\n",
    "# Create a map dataset instance.\n",
    "map_dataset = SquareMapDataset(size=8)\n",
    "\n",
    "# Access a few items directly.\n",
    "first_item = map_dataset[0]\n",
    "third_item = map_dataset[2]\n",
    "\n",
    "# Wrap map dataset in a DataLoader.\n",
    "map_loader = DataLoader(\n",
    "    map_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Define a simple iterable style dataset.\n",
    "class SquareIterableDataset(IterableDataset):\n",
    "    # Initialize with a maximum count.\n",
    "    def __init__(self, max_value: int = 8):\n",
    "        self.max_value = int(max_value)\n",
    "\n",
    "    # Create an iterator over the stream.\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:\n",
    "            start = 0\n",
    "            end = self.max_value\n",
    "        else:\n",
    "            per_worker = int(\n",
    "                math.ceil(self.max_value / worker_info.num_workers)\n",
    "            )\n",
    "            start = worker_info.id * per_worker\n",
    "            end = min(start + per_worker, self.max_value)\n",
    "        for i in range(start, end):\n",
    "            value = float(i)\n",
    "            yield torch.tensor([value, value ** 2], dtype=torch.float32)\n",
    "\n",
    "# Create an iterable dataset instance.\n",
    "iter_dataset = SquareIterableDataset(max_value=8)\n",
    "\n",
    "# Wrap iterable dataset in a DataLoader.\n",
    "iter_loader = DataLoader(\n",
    "    iter_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Print framework version in one line.\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Show direct indexing from map dataset.\n",
    "print(\"Map first item:\", first_item.tolist())\n",
    "print(\"Map third item:\", third_item.tolist())\n",
    "\n",
    "# Show one shuffled batch from map loader.\n",
    "for batch in map_loader:\n",
    "    print(\"Map loader batch shape:\", batch.shape)\n",
    "    break\n",
    "\n",
    "# Show sequential batches from iterable loader.\n",
    "for batch in iter_loader:\n",
    "    print(\"Iterable loader batch shape:\", batch.shape)\n",
    "    break\n",
    "\n",
    "# Confirm that iterable dataset has no length.\n",
    "has_len = hasattr(iter_dataset, \"__len__\")\n",
    "print(\"Iterable dataset has __len__:\", has_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da3221",
   "metadata": {},
   "source": [
    "### **1.2. Core Dataset Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7cae0",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_01_02.jpg?v=1769669801\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Two methods define dataset size and samples\n",
    ">* They index raw data into structured training examples\n",
    "\n",
    ">* Accurate length makes datasets work with tools\n",
    ">* Updated length keeps all pipeline components synchronized\n",
    "\n",
    ">* Index method locates, loads, and decodes data\n",
    ">* Transforms raw records into clean model-ready samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Core Dataset Methods\n",
    "\n",
    "# This script shows core dataset methods.\n",
    "# It focuses on __len__ and __getitem__.\n",
    "# It uses a tiny custom tensor dataset.\n",
    "\n",
    "# Uncomment to install PyTorch in some environments.\n",
    "# !pip install torch torchvision torchaudio.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Import torch for tensors and Dataset.\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define a simple custom dataset class.\n",
    "class TinySquaresDataset(Dataset):\n",
    "    # Initialize with a maximum integer value.\n",
    "    def __init__(self, max_value: int = 10):\n",
    "        assert max_value > 0, \"max_value must be positive\"\n",
    "        self.values = list(range(1, max_value + 1))\n",
    "\n",
    "    # Return the number of available samples.\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.values)\n",
    "\n",
    "    # Return one sample given an integer index.\n",
    "    def __getitem__(self, index: int):\n",
    "        if index < 0 or index >= len(self.values):\n",
    "            raise IndexError(\"Index out of range for dataset\")\n",
    "        x_value = float(self.values[index])\n",
    "        x_tensor = torch.tensor([x_value], dtype=torch.float32)\n",
    "        y_tensor = torch.tensor([x_value ** 2], dtype=torch.float32)\n",
    "        return {\"input\": x_tensor, \"target\": y_tensor}\n",
    "\n",
    "# Create a tiny dataset instance.\n",
    "dataset = TinySquaresDataset(max_value=8)\n",
    "\n",
    "# Show dataset length using __len__.\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "\n",
    "# Inspect a single sample using __getitem__.\n",
    "sample_index = 3\n",
    "sample = dataset[sample_index]\n",
    "print(\"Sample index:\", sample_index, \"input:\", sample[\"input\"].item())\n",
    "print(\"Sample index:\", sample_index, \"target:\", sample[\"target\"].item())\n",
    "\n",
    "# Create a DataLoader to batch samples.\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Take one batch from the loader.\n",
    "first_batch = next(iter(loader))\n",
    "\n",
    "# Validate batch shapes before printing.\n",
    "assert first_batch[\"input\"].shape == (4, 1)\n",
    "assert first_batch[\"target\"].shape == (4, 1)\n",
    "\n",
    "# Print a short summary of the first batch.\n",
    "print(\"Batch inputs:\", first_batch[\"input\"].squeeze().tolist())\n",
    "print(\"Batch targets:\", first_batch[\"target\"].squeeze().tolist())\n",
    "\n",
    "# Confirm that dataset methods work as expected.\n",
    "print(\"Verified __len__ and __getitem__ behavior.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2301d3",
   "metadata": {},
   "source": [
    "### **1.3. On the fly preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7df2ac",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_01_03.jpg?v=1769669857\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Transform each sample right when it’s loaded\n",
    ">* Save raw data; keep preprocessing flexible, storage‑efficient\n",
    "\n",
    ">* Random transforms create varied samples each epoch\n",
    ">* Embedded logic keeps data fresh and generalizable\n",
    "\n",
    ">* Balance preprocessing cost with data loading speed\n",
    ">* Precompute heavy steps, apply cheap ones dynamically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - On the fly preprocessing\n",
    "\n",
    "# This script shows on the fly preprocessing.\n",
    "# We build a tiny custom dataset class.\n",
    "# Each sample is transformed right before use.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Create a tiny synthetic numeric dataset.\n",
    "base_features = np.arange(12, dtype=np.float32).reshape(6, 2)\n",
    "base_labels = np.array([0, 1, 0, 1, 0, 1], dtype=np.int32)\n",
    "\n",
    "# Validate shapes before building dataset.\n",
    "assert base_features.shape[0] == base_labels.shape[0]\n",
    "\n",
    "# Define a function for on the fly noise.\n",
    "def add_random_noise(features):\n",
    "    noise = tf.random.normal(tf.shape(features), stddev=0.1)\n",
    "    return features + noise\n",
    "\n",
    "# Define a function for on the fly scaling.\n",
    "def scale_features(features):\n",
    "    return (features - tf.reduce_mean(features)) / (tf.math.reduce_std(features) + 1e-6)\n",
    "\n",
    "# Define a mapping function combining both transforms.\n",
    "def preprocess_example(features, label):\n",
    "    noisy = add_random_noise(features)\n",
    "    scaled = scale_features(noisy)\n",
    "    return scaled, label\n",
    "\n",
    "# Build a tf.data Dataset from tensors.\n",
    "raw_ds = tf.data.Dataset.from_tensor_slices((base_features, base_labels))\n",
    "\n",
    "# Apply on the fly preprocessing with map.\n",
    "preprocessed_ds = raw_ds.map(preprocess_example)\n",
    "\n",
    "# Batch the dataset for efficient loading.\n",
    "preprocessed_ds = preprocessed_ds.batch(2)\n",
    "\n",
    "# Take one epoch and collect two batches.\n",
    "example_batches = list(preprocessed_ds.take(2))\n",
    "\n",
    "# Print original features for comparison.\n",
    "print(\"Original features:\\n\", base_features)\n",
    "\n",
    "# Print first preprocessed batch.\n",
    "first_batch_x, first_batch_y = example_batches[0]\n",
    "print(\"First batch preprocessed features:\\n\", first_batch_x.numpy())\n",
    "\n",
    "# Print first preprocessed batch labels.\n",
    "print(\"First batch labels:\", first_batch_y.numpy())\n",
    "\n",
    "# Iterate again to show new random noise.\n",
    "second_run_batches = list(preprocessed_ds.take(1))\n",
    "\n",
    "# Print another run to highlight randomness.\n",
    "second_x, second_y = second_run_batches[0]\n",
    "print(\"Second run first batch features:\\n\", second_x.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba39e3e",
   "metadata": {},
   "source": [
    "## **2. Efficient DataLoader Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8bdc1",
   "metadata": {},
   "source": [
    "### **2.1. Smart Batching Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b0090",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_02_01.jpg?v=1769669891\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Batch size affects speed, memory, and gradients\n",
    ">* Choose a size that fits hardware and stabilizes training\n",
    "\n",
    ">* Group samples with similar size or length\n",
    ">* This reduces padding, wasted memory, and computation\n",
    "\n",
    ">* Mix shuffling with structured, size-based batching\n",
    ">* Hybrid batching boosts efficiency while preserving robustness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1901a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Smart Batching Strategies\n",
    "\n",
    "# This script demonstrates smart batching strategies simply.\n",
    "# We simulate variable length sequences and batch them efficiently.\n",
    "# Focus is on DataLoader configuration and padding behavior.\n",
    "\n",
    "# Uncomment the next line if torch is not installed.\n",
    "# !pip install torch torchvision.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Import torch for tensors and DataLoader utilities.\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define a tiny custom dataset with variable lengths.\n",
    "class ToySequenceDataset(Dataset):\n",
    "    # Initialize with a list of sequence lengths.\n",
    "    def __init__(self, lengths):\n",
    "        self.lengths = list(lengths)\n",
    "\n",
    "    # Return dataset size for DataLoader usage.\n",
    "    def __len__(self):\n",
    "        return len(self.lengths)\n",
    "\n",
    "    # Generate a random sequence tensor for each index.\n",
    "    def __getitem__(self, idx):\n",
    "        length = int(self.lengths[idx])\n",
    "        values = torch.ones(length, dtype=torch.float32)\n",
    "        return values, length\n",
    "\n",
    "# Create a small list of varying sequence lengths.\n",
    "sequence_lengths = [3, 7, 2, 5, 9, 4, 6, 8]\n",
    "\n",
    "# Instantiate the dataset with these lengths.\n",
    "dataset = ToySequenceDataset(sequence_lengths)\n",
    "\n",
    "# Validate dataset length to avoid configuration mistakes.\n",
    "assert len(dataset) == len(sequence_lengths)\n",
    "\n",
    "# Define a simple padding collate function for naive batching.\n",
    "def naive_collate(batch):\n",
    "    sequences, lengths = zip(*batch)\n",
    "    max_len = max(int(l) for l in lengths)\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        pad_size = max_len - int(seq.shape[0])\n",
    "        pad_tensor = torch.zeros(pad_size, dtype=torch.float32)\n",
    "        padded.append(torch.cat((seq, pad_tensor)))\n",
    "    batch_tensor = torch.stack(padded, dim=0)\n",
    "    length_tensor = torch.tensor(lengths, dtype=torch.int64)\n",
    "    return batch_tensor, length_tensor\n",
    "\n",
    "# Define a bucketing function to group similar lengths.\n",
    "def make_buckets(lengths, bucket_size):\n",
    "    paired = list(enumerate(lengths))\n",
    "    paired.sort(key=lambda x: x[1])\n",
    "    buckets = []\n",
    "    for i in range(0, len(paired), bucket_size):\n",
    "        bucket = paired[i : i + bucket_size]\n",
    "        buckets.append(bucket)\n",
    "    return buckets\n",
    "\n",
    "# Build buckets to support smart batching behavior.\n",
    "buckets = make_buckets(sequence_lengths, bucket_size=4)\n",
    "\n",
    "# Define a custom sampler that yields indices by buckets.\n",
    "class BucketSampler(torch.utils.data.Sampler):\n",
    "    # Store buckets and enable optional shuffling.\n",
    "    def __init__(self, buckets, shuffle=True):\n",
    "        self.buckets = list(buckets)\n",
    "        self.shuffle = bool(shuffle)\n",
    "\n",
    "    # Return total number of samples across buckets.\n",
    "    def __len__(self):\n",
    "        return sum(len(b) for b in self.buckets)\n",
    "\n",
    "    # Yield indices, shuffling within each bucket.\n",
    "    def __iter__(self):\n",
    "        bucket_order = list(self.buckets)\n",
    "        if self.shuffle:\n",
    "            random.shuffle(bucket_order)\n",
    "        for bucket in bucket_order:\n",
    "            inner = list(bucket)\n",
    "            if self.shuffle:\n",
    "                random.shuffle(inner)\n",
    "            for idx, _length in inner:\n",
    "                yield int(idx)\n",
    "\n",
    "# Create naive DataLoader with random shuffling only.\n",
    "naive_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=naive_collate,\n",
    "                          num_workers=0)\n",
    "\n",
    "# Create smart DataLoader using bucket sampler strategy.\n",
    "bucket_sampler = BucketSampler(buckets=buckets, shuffle=True)\n",
    "smart_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=4,\n",
    "                          sampler=bucket_sampler,\n",
    "                          collate_fn=naive_collate,\n",
    "                          num_workers=0)\n",
    "\n",
    "# Helper function to inspect one epoch of a loader.\n",
    "def inspect_loader(loader, name):\n",
    "    print(f\"\\n{name} batches:\")\n",
    "    for batch_idx, (batch, lengths) in enumerate(loader):\n",
    "        shape = tuple(batch.shape)\n",
    "        min_len = int(lengths.min().item())\n",
    "        max_len = int(lengths.max().item())\n",
    "        print(f\"Batch {batch_idx}: shape={shape}, min_len={min_len}, max_len={max_len}\")\n",
    "\n",
    "# Print torch version and device information briefly.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Torch version {torch.__version__}, device {device}\")\n",
    "\n",
    "# Move one batch to device to show realistic usage.\n",
    "first_batch, first_lengths = next(iter(naive_loader))\n",
    "first_batch = first_batch.to(device)\n",
    "first_lengths = first_lengths.to(device)\n",
    "\n",
    "# Inspect naive and smart loaders to compare padding ranges.\n",
    "inspect_loader(naive_loader, \"Naive loader\")\n",
    "inspect_loader(smart_loader, \"Smart bucketed loader\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6d4a0",
   "metadata": {},
   "source": [
    "### **2.2. num_workers tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05324b51",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_02_02.jpg?v=1769669990\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Worker count controls parallel data loading processes\n",
    ">* Tune workers to balance speed and system load\n",
    "\n",
    ">* Optimal worker count depends on hardware and preprocessing\n",
    ">* Increase workers until throughput stops improving or fluctuates\n",
    "\n",
    ">* Optimal worker settings change with environment, time\n",
    ">* Regularly retune using system metrics and profiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - num_workers tuning\n",
    "\n",
    "# This script demonstrates DataLoader num_workers tuning.\n",
    "# It uses TensorFlow to simulate data loading work.\n",
    "# Focus is on timing different worker configurations.\n",
    "\n",
    "# !pip install tensorflow-io-gcs-filesystem.\n",
    "\n",
    "# Import standard libraries for timing and randomness.\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and set logging level.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print TensorFlow version in a single concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a small synthetic dataset size constant.\n",
    "NUM_SAMPLES = 2048\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Create a simple synthetic feature tensor dataset.\n",
    "features = tf.random.normal((NUM_SAMPLES, 32))\n",
    "labels = tf.random.uniform((NUM_SAMPLES, 1), 0, 2, dtype=tf.int32)\n",
    "\n",
    "# Validate shapes before building the dataset pipeline.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "# Build a base tf.data Dataset from tensors.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Define a small preprocessing function to simulate work.\n",
    "def preprocess(x, y):\n",
    "    x = tf.math.square(x)\n",
    "    x = tf.math.reduce_mean(x, axis=-1, keepdims=True)\n",
    "    return x, y\n",
    "\n",
    "# Wrap preprocessing with map for later reuse.\n",
    "def make_dataset(num_parallel_calls):\n",
    "    ds = base_ds.shuffle(256, seed=42, reshuffle_each_iteration=False)\n",
    "    ds = ds.map(preprocess, num_parallel_calls=num_parallel_calls)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Define a helper to time one full pass over the dataset.\n",
    "def time_dataset(num_parallel_calls):\n",
    "    ds = make_dataset(num_parallel_calls)\n",
    "    start = time.time()\n",
    "    batch_count = 0\n",
    "    for batch_x, batch_y in ds:\n",
    "        batch_count += 1\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    return elapsed, batch_count\n",
    "\n",
    "# Choose several worker like values to compare timings.\n",
    "worker_like_values = [1, 2, 4, 8]\n",
    "\n",
    "# Collect timing results for each configuration.\n",
    "results = []\n",
    "\n",
    "for workers in worker_like_values:\n",
    "    elapsed, batches = time_dataset(workers)\n",
    "    results.append((workers, elapsed, batches))\n",
    "\n",
    "# Print a short summary explaining the measurements.\n",
    "print(\"\\nSimulated num_workers timing with tf.data map.\")\n",
    "\n",
    "# Print each configuration result in a compact format.\n",
    "for workers, elapsed, batches in results:\n",
    "    print(\n",
    "        f\"parallel_calls={workers}: {elapsed:.3f}s for {batches} batches\"\n",
    "    )\n",
    "\n",
    "# Indicate which configuration was fastest overall.\n",
    "best_cfg = min(results, key=lambda x: x[1])\n",
    "print(\n",
    "    f\"\\nFastest setting here uses parallel_calls={best_cfg[0]} workers.\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7734bd4",
   "metadata": {},
   "source": [
    "### **2.3. Memory Pinning and Dropping**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bfa6fa",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_02_03.jpg?v=1769670078\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Pinned memory speeds CPU‑to‑GPU data transfers\n",
    ">* Enables overlapping data transfer with model computation\n",
    "\n",
    ">* Pinned memory speeds GPU training on big batches\n",
    ">* Overuse increases RAM pressure, so monitor carefully\n",
    "\n",
    ">* Free batch memory promptly to prevent buildup\n",
    ">* Avoid hidden references; combine pinning with cleanup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a731e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Memory Pinning and Dropping\n",
    "\n",
    "# This script shows PyTorch DataLoader memory pinning.\n",
    "# It compares pinned and unpinned batches on a device.\n",
    "# It also demonstrates careful memory dropping practices.\n",
    "\n",
    "# !pip install torch torchvision.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Import torch and torchvision safely.\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Set deterministic random seeds everywhere.\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Detect device preferring GPU when available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print framework version and selected device.\n",
    "print(\"Torch\", torch.__version__, \"Device\", device)\n",
    "\n",
    "# Define a tiny transform converting images to tensors.\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "# Download a very small MNIST training subset.\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Limit dataset size to keep runtime very small.\n",
    "small_size = 256\n",
    "assert small_size <= len(train_dataset)\n",
    "\n",
    "# Create a subset view of the dataset.\n",
    "indices = list(range(small_size))\n",
    "small_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "\n",
    "# Helper function to build a configured DataLoader.\n",
    "def make_loader(pinned):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        small_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=pinned,\n",
    "    )\n",
    "\n",
    "# Create loaders with and without pinned memory.\n",
    "loader_unpinned = make_loader(pinned=False)\n",
    "loader_pinned = make_loader(pinned=True)\n",
    "\n",
    "# Define a tiny model to consume batches.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 10),\n",
    ").to(device)\n",
    "\n",
    "# Ensure model parameters are on the correct device.\n",
    "for p in model.parameters():\n",
    "    assert p.device == device\n",
    "\n",
    "# Function to time one pass over a loader.\n",
    "def time_loader(loader, description):\n",
    "    start = time.time()\n",
    "    total = 0\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        assert images.ndim == 4\n",
    "        assert labels.ndim == 1\n",
    "\n",
    "        # Move batch to device using non_blocking when pinned.\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        # Run a tiny forward pass then drop references.\n",
    "        outputs = model(images)\n",
    "        total += outputs.shape[0]\n",
    "        del images, labels, outputs\n",
    "\n",
    "    end = time.time()\n",
    "    print(description, \"items\", total, \"time\", round(end - start, 3))\n",
    "\n",
    "# Time unpinned loader first for comparison.\n",
    "time_loader(loader_unpinned, \"Unpinned loader\")\n",
    "\n",
    "# Time pinned loader to observe potential speedup.\n",
    "time_loader(loader_pinned, \"Pinned loader\")\n",
    "\n",
    "# Explicitly clear caches when using CUDA devices.\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5248a",
   "metadata": {},
   "source": [
    "## **3. Using Builtin Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8a455",
   "metadata": {},
   "source": [
    "### **3.1. Working With torchvision**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0248e3",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_03_01.jpg?v=1769670159\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Torchvision offers ready-to-use image datasets quickly\n",
    ">* Lets you test models without manual data handling\n",
    "\n",
    ">* Torchvision datasets support flexible image transformations\n",
    ">* Easily test different preprocessing without changing training code\n",
    "\n",
    ">* Torchvision includes complex, richly annotated vision datasets\n",
    ">* Consistent interfaces ease scaling from toy to real projects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Working With torchvision\n",
    "\n",
    "# This script shows basic torchvision dataset usage.\n",
    "# It focuses on small image classification examples.\n",
    "# You can run everything directly inside Colab.\n",
    "\n",
    "# !pip install torch torchvision torchaudio.\n",
    "\n",
    "# Import standard libraries for reproducibility.\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Import torch and torchvision core modules.\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set a deterministic random seed value.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Set seeds for torch random number generators.\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# Detect device type for potential later use.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print torch and torchvision versions briefly.\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)\n",
    "\n",
    "# Define a simple transform pipeline for images.\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# Choose a small root directory for dataset files.\n",
    "data_root = os.path.join(\".\", \"data_torchvision_demo\")\n",
    "\n",
    "# Create the MNIST training dataset with transforms.\n",
    "mnist_train = datasets.MNIST(\n",
    "    root=data_root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_pipeline,\n",
    ")\n",
    "\n",
    "# Verify dataset length is positive and reasonable.\n",
    "assert len(mnist_train) > 0\n",
    "\n",
    "# Inspect one sample to understand shapes.\n",
    "sample_image, sample_label = mnist_train[0]\n",
    "\n",
    "# Validate the image tensor shape for safety.\n",
    "assert sample_image.ndim == 3\n",
    "assert sample_image.shape[0] == 1\n",
    "\n",
    "# Print a short summary about one sample.\n",
    "print(\"Single sample shape:\", tuple(sample_image.shape))\n",
    "print(\"Single sample label:\", int(sample_label))\n",
    "\n",
    "# Create a DataLoader with small batch size.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    mnist_train,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Get one batch from the DataLoader iterator.\n",
    "first_batch_images, first_batch_labels = next(iter(train_loader))\n",
    "\n",
    "# Move batch to the selected device safely.\n",
    "first_batch_images = first_batch_images.to(device)\n",
    "first_batch_labels = first_batch_labels.to(device)\n",
    "\n",
    "# Validate batch dimensions before further processing.\n",
    "assert first_batch_images.shape[0] == 16\n",
    "assert first_batch_images.shape[1] == 1\n",
    "\n",
    "# Print concise information about the loaded batch.\n",
    "print(\"Batch images shape:\", tuple(first_batch_images.shape))\n",
    "print(\"Batch labels shape:\", tuple(first_batch_labels.shape))\n",
    "\n",
    "# Show a few labels to confirm shuffling behavior.\n",
    "print(\"First eight labels:\", first_batch_labels[:8].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab0196",
   "metadata": {},
   "source": [
    "### **3.2. Working With Torchtext**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fad243",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_03_02.jpg?v=1769670249\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Torchtext offers ready-made datasets for NLP tasks\n",
    ">* Enables quick experiments and fair benchmark comparisons\n",
    "\n",
    ">* Torchtext offers raw text plus basic preprocessing\n",
    ">* You can customize preprocessing while interface stays consistent\n",
    "\n",
    ">* Torchtext promotes reusable text processing components\n",
    ">* Build intuition to adapt datasets and custom corpora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734583c",
   "metadata": {},
   "source": [
    "### **3.3. Dataset Download And Cache**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4c79ca",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_A/image_03_03.jpg?v=1769670411\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Datasets download once from remote servers first\n",
    ">* Later runs use cached data, avoiding network issues\n",
    "\n",
    ">* Libraries cache datasets locally, downloading only when missing\n",
    ">* Shared or persistent caches save time, bandwidth, sessions\n",
    "\n",
    ">* Monitor cache size and remove unused datasets\n",
    ">* Share cache locations and avoid deleting active data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a89d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Dataset Download And Cache\n",
    "\n",
    "# This script shows dataset download caching behavior.\n",
    "# It uses TensorFlow builtin MNIST dataset safely.\n",
    "# Focus is on download location and reuse.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "# Import numpy for simple array inspection.\n",
    "import numpy as np\n",
    "\n",
    "# Import tensorflow and its datasets module.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print TensorFlow version in one concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a small helper to describe arrays.\n",
    "def describe_array(name, array):\n",
    "    # Print array name, shape and data type.\n",
    "    print(f\"{name} shape {array.shape} dtype {array.dtype}\")\n",
    "\n",
    "# Choose a cache directory under the user home.\n",
    "home_dir = pathlib.Path.home()\n",
    "cache_dir = home_dir / \"tf_mnist_cache_demo\"\n",
    "\n",
    "# Create the cache directory if it does not exist.\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Show the chosen cache directory path.\n",
    "print(\"Cache directory:\", str(cache_dir))\n",
    "\n",
    "# Build the full path for the MNIST npz file.\n",
    "mnist_path = cache_dir / \"mnist.npz\"\n",
    "\n",
    "# Check whether the dataset file already exists.\n",
    "first_time_download = not mnist_path.exists()\n",
    "\n",
    "# Print a short message about expected behavior.\n",
    "if first_time_download:\n",
    "    print(\"MNIST not cached yet, download will occur.\")\n",
    "else:\n",
    "    print(\"MNIST already cached, load will be fast.\")\n",
    "\n",
    "# Load MNIST using keras with explicit path.\n",
    "(train_images, train_labels), (test_images, test_labels) = (\n",
    "    keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    ")\n",
    "\n",
    "# Confirm whether file now exists after loading.\n",
    "file_now_exists = mnist_path.exists()\n",
    "print(\"File exists after load:\", file_now_exists)\n",
    "\n",
    "# Describe the loaded training and test arrays.\n",
    "describe_array(\"train_images\", train_images)\n",
    "describe_array(\"train_labels\", train_labels)\n",
    "\n",
    "describe_array(\"test_images\", test_images)\n",
    "describe_array(\"test_labels\", test_labels)\n",
    "\n",
    "# Show a tiny sample of pixel values for intuition.\n",
    "print(\"First image first row:\", train_images[0, 0, :10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddff73a",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Datasets and Loaders**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3179d",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Implement custom PyTorch Dataset classes that load and preprocess samples on demand. \n",
    "- Configure DataLoader instances with appropriate batch sizes, shuffling, and multiprocessing workers. \n",
    "- Use built‑in datasets from torchvision and torchtext as quick starting points for experiments. \n",
    "\n",
    "In the next Lecture (Lecture B), we will go over 'Transforms and Augment'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
