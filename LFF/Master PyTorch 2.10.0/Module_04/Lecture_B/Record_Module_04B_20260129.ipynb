{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aef49b2",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Transforms and Augment**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abf843",
   "metadata": {},
   "source": [
    ">Last update: 20260129.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Apply common preprocessing transforms such as normalization, resizing, and tensor conversion to raw data. \n",
    "- Design and configure data augmentation pipelines that improve model robustness without corrupting labels. \n",
    "- Integrate transforms into Dataset and DataLoader workflows while monitoring their impact on training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b46a2",
   "metadata": {},
   "source": [
    "## **1. Core Preprocessing Transforms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07289fd",
   "metadata": {},
   "source": [
    "### **1.1. Tensor Conversion and Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c48e2f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_01_01.jpg?v=1769744165\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Convert varied raw data into tensor arrays\n",
    ">* Tensors enable fast batching, device moves, and training\n",
    "\n",
    ">* Normalization rescales tensor values to stable ranges\n",
    ">* It prevents large features dominating, improving learning\n",
    "\n",
    ">* Treat conversion and normalization as one pipeline\n",
    ">* Use consistent stats to avoid distribution shifts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60404a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tensor Conversion and Normalization\n",
    "\n",
    "# This script shows tensor conversion basics.\n",
    "# It uses TensorFlow for simple image tensors.\n",
    "# Focus on conversion and normalization steps.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Import TensorFlow and NumPy libraries.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set TensorFlow random seed.\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Create a small fake RGB image.\n",
    "height, width, channels = 4, 4, 3\n",
    "fake_image_uint8 = tf.random.uniform(\n",
    "    shape=(height, width, channels),\n",
    "    minval=0,\n",
    "    maxval=256,\n",
    "    dtype=tf.int32,\n",
    ")\n",
    "\n",
    "# Cast random integers to uint8 type.\n",
    "fake_image_uint8 = tf.cast(fake_image_uint8, tf.uint8)\n",
    "\n",
    "# Show original image shape and dtype.\n",
    "print(\"Original shape:\", fake_image_uint8.shape)\n",
    "print(\"Original dtype:\", fake_image_uint8.dtype)\n",
    "\n",
    "# Convert image to float32 tensor.\n",
    "image_float = tf.image.convert_image_dtype(\n",
    "    fake_image_uint8,\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "\n",
    "# Confirm new dtype and value range.\n",
    "print(\"Converted dtype:\", image_float.dtype)\n",
    "print(\"Min, max after scaling:\",\n",
    "      float(tf.reduce_min(image_float)),\n",
    "      float(tf.reduce_max(image_float)))\n",
    "\n",
    "# Define per channel mean and std values.\n",
    "mean = tf.constant([0.5, 0.5, 0.5], dtype=tf.float32)\n",
    "std = tf.constant([0.2, 0.2, 0.2], dtype=tf.float32)\n",
    "\n",
    "# Reshape mean and std for broadcasting.\n",
    "mean = tf.reshape(mean, (1, 1, 3))\n",
    "std = tf.reshape(std, (1, 1, 3))\n",
    "\n",
    "# Apply normalization to the image.\n",
    "normalized_image = (image_float - mean) / std\n",
    "\n",
    "# Check normalized image statistics.\n",
    "mean_value = tf.reduce_mean(normalized_image)\n",
    "std_value = tf.math.reduce_std(normalized_image)\n",
    "\n",
    "# Print summary statistics for understanding.\n",
    "print(\"Normalized mean (approx):\", float(mean_value))\n",
    "print(\"Normalized std (approx):\", float(std_value))\n",
    "\n",
    "# Verify normalized tensor shape matches original.\n",
    "print(\"Normalized shape:\", normalized_image.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ea969",
   "metadata": {},
   "source": [
    "### **1.2. Spatial Resizing Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384391f",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_01_02.jpg?v=1769744217\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Resize images to a common input size\n",
    ">* Standardized sizes enable efficient tensor batching and processing\n",
    "\n",
    ">* Resizing changes detail; downscaling loses small features\n",
    ">* Choose target size based on model and task\n",
    "\n",
    ">* Preserve aspect ratio to avoid shape distortion\n",
    ">* Use crop or padding to keep composition realistic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d35231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Spatial Resizing Basics\n",
    "\n",
    "# This script demonstrates basic spatial resizing concepts.\n",
    "# We use TensorFlow to resize simple example images safely.\n",
    "# Focus on shapes, aspect ratios, and visual differences.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Set NumPy and TensorFlow seeds for consistent behavior.\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset with small grayscale digit images.\n",
    "(x_train, y_train), _ = datasets.mnist.load_data()\n",
    "\n",
    "# Select a small subset of images for this demo.\n",
    "num_samples = 4\n",
    "x_small = x_train[:num_samples]\n",
    "\n",
    "# Convert NumPy images to float32 tensors with channel dimension.\n",
    "images = tf.convert_to_tensor(x_small, dtype=tf.float32)\n",
    "images = tf.expand_dims(images, axis=-1)\n",
    "\n",
    "# Confirm original image shape is as expected.\n",
    "print(\"Original batch shape:\", images.shape)\n",
    "\n",
    "# Define a target spatial size for resizing operation.\n",
    "target_height, target_width = 56, 56\n",
    "\n",
    "# Resize images using bilinear interpolation method.\n",
    "resized_bilinear = tf.image.resize(\n",
    "    images,\n",
    "    size=(target_height, target_width),\n",
    "    method=\"bilinear\",\n",
    ")\n",
    "\n",
    "# Resize images using nearest neighbor interpolation.\n",
    "resized_nearest = tf.image.resize(\n",
    "    images,\n",
    "    size=(target_height, target_width),\n",
    "    method=\"nearest\",\n",
    ")\n",
    "\n",
    "# Confirm resized shapes match the chosen target size.\n",
    "print(\"Resized bilinear shape:\", resized_bilinear.shape)\n",
    "print(\"Resized nearest shape:\", resized_nearest.shape)\n",
    "\n",
    "# Compute simple statistics to compare interpolation effects.\n",
    "orig_mean = tf.reduce_mean(images).numpy()\n",
    "\n",
    "# Compute means for resized image batches.\n",
    "mean_bilinear = tf.reduce_mean(resized_bilinear).numpy()\n",
    "mean_nearest = tf.reduce_mean(resized_nearest).numpy()\n",
    "\n",
    "# Print summary of mean pixel values for each version.\n",
    "print(\"Original mean pixel:\", round(float(orig_mean), 3))\n",
    "print(\"Bilinear mean pixel:\", round(float(mean_bilinear), 3))\n",
    "print(\"Nearest mean pixel:\", round(float(mean_nearest), 3))\n",
    "\n",
    "# Show one example of original and resized shapes and labels.\n",
    "index = 0\n",
    "print(\"Example label:\", int(y_train[index]))\n",
    "print(\"Original shape:\", images[index].shape)\n",
    "print(\"Bilinear shape:\", resized_bilinear[index].shape)\n",
    "print(\"Nearest shape:\", resized_nearest[index].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d2107",
   "metadata": {},
   "source": [
    "### **1.3. Channel and Dtype Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b094fc3",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_01_03.jpg?v=1769744267\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Channel order and dtype define data meaning\n",
    ">* Wrong channel layout makes models misread inputs\n",
    "\n",
    ">* Dtype controls value precision, storage, and speed\n",
    ">* Convert ints to floats, avoid mixed-type bugs\n",
    "\n",
    ">* Standardize channel order for all input sources\n",
    ">* Choose compatible dtypes to avoid subtle errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Channel and Dtype Basics\n",
    "\n",
    "# This script explores channels and dtypes basics.\n",
    "# It uses TensorFlow to inspect simple image tensors.\n",
    "# Focus on shapes, channel order, and dtype conversions.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and check version.\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Create a fake RGB image using NumPy.\n",
    "height, width, channels = 4, 5, 3\n",
    "np_image_uint8 = np.random.randint(\n",
    "    0, 256, size=(height, width, channels), dtype=np.uint8\n",
    ")\n",
    "\n",
    "# Show basic information about the NumPy image.\n",
    "print(\"NumPy image shape:\", np_image_uint8.shape)\n",
    "print(\"NumPy image dtype:\", np_image_uint8.dtype)\n",
    "\n",
    "# Convert NumPy image to TensorFlow tensor.\n",
    "tf_image_uint8 = tf.convert_to_tensor(np_image_uint8)\n",
    "print(\"Tensor shape (HWC):\", tf_image_uint8.shape)\n",
    "\n",
    "# Check that channels are in last dimension.\n",
    "print(\"Channels last dimension size:\", tf_image_uint8.shape[-1])\n",
    "\n",
    "# Convert dtype from uint8 to float32.\n",
    "tf_image_float = tf.cast(tf_image_uint8, tf.float32)\n",
    "print(\"Tensor dtype after cast:\", tf_image_float.dtype)\n",
    "\n",
    "# Scale pixel values to range zero to one.\n",
    "tf_image_scaled = tf_image_float / 255.0\n",
    "print(\"Min and max after scale:\",\n",
    "      float(tf.reduce_min(tf_image_scaled)),\n",
    "      float(tf.reduce_max(tf_image_scaled)))\n",
    "\n",
    "# Reorder channels from HWC to CHW layout.\n",
    "tf_image_chw = tf.transpose(tf_image_scaled, perm=(2, 0, 1))\n",
    "print(\"Tensor shape (CHW):\", tf_image_chw.shape)\n",
    "\n",
    "# Validate that channel count is preserved.\n",
    "assert tf_image_chw.shape[0] == channels\n",
    "\n",
    "# Create a small grayscale image example.\n",
    "gray_height, gray_width = 4, 4\n",
    "np_gray_uint8 = np.random.randint(\n",
    "    0, 256, size=(gray_height, gray_width), dtype=np.uint8\n",
    ")\n",
    "\n",
    "# Convert grayscale image to tensor with explicit channel.\n",
    "tf_gray = tf.convert_to_tensor(np_gray_uint8, dtype=tf.uint8)\n",
    "tf_gray_expanded = tf.expand_dims(tf_gray, axis=-1)\n",
    "\n",
    "# Show grayscale shapes before and after channel expansion.\n",
    "print(\"Gray original shape:\", tf_gray.shape)\n",
    "print(\"Gray with channel shape:\", tf_gray_expanded.shape)\n",
    "\n",
    "# Final confirmation message about channel and dtype handling.\n",
    "print(\"Channel and dtype basics demo finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff58d1",
   "metadata": {},
   "source": [
    "## **2. Designing Safe Augmentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2876eb8",
   "metadata": {},
   "source": [
    "### **2.1. Safe Spatial Augmentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2237a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_02_01.jpg?v=1769744297\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Use gentle geometric changes that keep labels\n",
    ">* Teach models to ignore position and orientation\n",
    "\n",
    ">* Match spatial transforms to realistic data geometry\n",
    ">* Use gentle changes that keep labels clearly correct\n",
    "\n",
    ">* Task and domain define label-safe geometry\n",
    ">* Randomize transforms within a carefully chosen envelope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0927ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Safe Spatial Augmentations\n",
    "\n",
    "# This script shows safe spatial augmentations.\n",
    "# We use TensorFlow image utilities for clarity.\n",
    "# Focus on flips crops and small rotations.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic random seeds everywhere.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load a small subset of CIFAR10 data.\n",
    "(x_train, y_train), _ = datasets.cifar10.load_data()\n",
    "num_samples = 8\n",
    "x_train = x_train[:num_samples]\n",
    "y_train = y_train[:num_samples]\n",
    "\n",
    "# Confirm shapes are as expected.\n",
    "print(\"Subset shape:\", x_train.shape, y_train.shape)\n",
    "\n",
    "# Normalize images to float32 range zero one.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "\n",
    "# Define a safe horizontal flip function.\n",
    "def safe_random_flip(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "# Define a safe small random crop function.\n",
    "def safe_random_crop(image):\n",
    "    image_shape = tf.shape(image)\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    crop_height = tf.cast(0.9 * tf.cast(height, tf.float32), tf.int32)\n",
    "    crop_width = tf.cast(0.9 * tf.cast(width, tf.float32), tf.int32)\n",
    "    cropped = tf.image.random_crop(image, (crop_height, crop_width, 3))\n",
    "    resized = tf.image.resize(cropped, (height, width))\n",
    "    return resized\n",
    "\n",
    "# Define a safe small rotation function.\n",
    "def safe_small_rotation(image):\n",
    "    angles = tf.random.uniform((), minval=-0.2, maxval=0.2)\n",
    "    rotated = tfa_image_rotate(image, angles)\n",
    "    return rotated\n",
    "\n",
    "# Implement rotation using dense sampling.\n",
    "def tfa_image_rotate(image, angle):\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    rotated = tfa_rotate_batch(image, angle)\n",
    "    rotated = tf.squeeze(rotated, axis=0)\n",
    "    return rotated\n",
    "\n",
    "# Rotate a batch using affine transform math.\n",
    "def tfa_rotate_batch(images, angle):\n",
    "    cos_a = tf.math.cos(angle)\n",
    "    sin_a = tf.math.sin(angle)\n",
    "    transform = [cos_a, -sin_a, 0.0, sin_a, cos_a, 0.0, 0.0, 0.0]\n",
    "    transform = tf.convert_to_tensor(transform, dtype=tf.float32)\n",
    "    transform = tf.reshape(transform, (1, 8))\n",
    "    transforms = tf.repeat(transform, tf.shape(images)[0], axis=0)\n",
    "    rotated = tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=images,\n",
    "        transforms=transforms,\n",
    "        output_shape=tf.shape(images)[1:3],\n",
    "        interpolation=\"BILINEAR\",\n",
    "        fill_mode=\"REFLECT\",\n",
    "        fill_value=0.0,\n",
    "    )\n",
    "    return rotated\n",
    "\n",
    "# Compose safe spatial augmentations together.\n",
    "def apply_safe_spatial_augment(image):\n",
    "    image = safe_random_flip(image)\n",
    "    image = safe_random_crop(image)\n",
    "    image = safe_small_rotation(image)\n",
    "    return image\n",
    "\n",
    "# Take one example image and label.\n",
    "example_image = x_train[0]\n",
    "example_label = int(y_train[0][0])\n",
    "print(\"Original label:\", example_label)\n",
    "\n",
    "# Apply augmentations several times deterministically.\n",
    "augmented_images = []\n",
    "for i in range(3):\n",
    "    tf.random.set_seed(seed_value + i)\n",
    "    aug = apply_safe_spatial_augment(example_image)\n",
    "    augmented_images.append(aug)\n",
    "\n",
    "# Stack augmented images for plotting.\n",
    "augmented_stack = tf.stack(augmented_images, axis=0)\n",
    "print(\"Augmented batch shape:\", augmented_stack.shape)\n",
    "\n",
    "# Plot original and augmented images together.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a simple figure with subplots.\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 3))\n",
    "axes[0].imshow(example_image)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Show each augmented image.\n",
    "for idx in range(3):\n",
    "    axes[idx + 1].imshow(augmented_stack[idx])\n",
    "    axes[idx + 1].set_title(\"Aug\" + str(idx + 1))\n",
    "    axes[idx + 1].axis(\"off\")\n",
    "\n",
    "# Tighten layout and display plot.\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453899e0",
   "metadata": {},
   "source": [
    "### **2.2. Color Jitter and Noise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6efebd",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_02_02.jpg?v=1769744395\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Color jitter simulates realistic lighting and camera changes\n",
    ">* Keep ranges moderate to avoid changing image meaning\n",
    "\n",
    ">* Match jitter ranges to realistic domain conditions\n",
    ">* Visually check samples; avoid label ambiguity\n",
    "\n",
    ">* Noise simulates real sensor imperfections and artifacts\n",
    ">* Increase noise slowly so labels stay clear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Color Jitter and Noise\n",
    "\n",
    "# This script shows color jitter and noise.\n",
    "# It uses TensorFlow image preprocessing utilities.\n",
    "# Focus on safe augmentations that keep labels.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set TensorFlow random seed.\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version once.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset from Keras.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select a small subset for demonstration.\n",
    "num_samples = 8\n",
    "x_small = x_train[:num_samples]\n",
    "\n",
    "# Expand grayscale images to three channels.\n",
    "x_small_rgb = np.repeat(x_small[..., np.newaxis], 3, axis=3)\n",
    "\n",
    "# Normalize pixel values to range [0,1].\n",
    "x_small_rgb = x_small_rgb.astype(\"float32\") / 255.0\n",
    "\n",
    "# Confirm shapes are as expected.\n",
    "assert x_small_rgb.shape[0] == num_samples\n",
    "\n",
    "# Create a simple color jitter layer.\n",
    "color_jitter_layer = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomBrightness(\n",
    "            factor=0.2,\n",
    "            value_range=(0.0, 1.0),\n",
    "            seed=seed_value,\n",
    "        ),\n",
    "        layers.RandomContrast(\n",
    "            factor=0.2,\n",
    "            seed=seed_value,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define a function to add gentle Gaussian noise.\n",
    "def add_gaussian_noise(images, stddev=0.05):\n",
    "    noise = tf.random.normal(\n",
    "        shape=tf.shape(images),\n",
    "        mean=0.0,\n",
    "        stddev=stddev,\n",
    "        seed=seed_value,\n",
    "    )\n",
    "    noisy = images + noise\n",
    "    noisy = tf.clip_by_value(noisy, 0.0, 1.0)\n",
    "    return noisy\n",
    "\n",
    "# Take a small batch as TensorFlow tensor.\n",
    "images_batch = tf.convert_to_tensor(x_small_rgb[:4])\n",
    "\n",
    "# Apply color jitter to the batch.\n",
    "images_jittered = color_jitter_layer(images_batch)\n",
    "\n",
    "# Apply Gaussian noise to the jittered batch.\n",
    "images_noisy = add_gaussian_noise(images_jittered, stddev=0.05)\n",
    "\n",
    "# Verify shapes remain unchanged.\n",
    "assert images_batch.shape == images_jittered.shape\n",
    "\n",
    "# Import plotting library for visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with three rows of images.\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=3,\n",
    "    ncols=4,\n",
    "    figsize=(8, 6),\n",
    ")\n",
    "\n",
    "# Plot original images in the first row.\n",
    "for idx in range(4):\n",
    "    axes[0, idx].imshow(images_batch[idx].numpy())\n",
    "    axes[0, idx].axis(\"off\")\n",
    "\n",
    "# Plot color jittered images in the second row.\n",
    "for idx in range(4):\n",
    "    axes[1, idx].imshow(images_jittered[idx].numpy())\n",
    "    axes[1, idx].axis(\"off\")\n",
    "\n",
    "# Plot jittered plus noisy images in third row.\n",
    "for idx in range(4):\n",
    "    axes[2, idx].imshow(images_noisy[idx].numpy())\n",
    "    axes[2, idx].axis(\"off\")\n",
    "\n",
    "# Add a compact title explaining each row.\n",
    "fig.suptitle(\n",
    "    \"Top: original, middle: color jitter, bottom: jitter + noise\",\n",
    "    fontsize=10,\n",
    ")\n",
    "\n",
    "# Adjust layout and display the plot.\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc69acd",
   "metadata": {},
   "source": [
    "### **2.3. Label Safe Augmentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24aa6f8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_02_03.jpg?v=1769744459\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Augment data while keeping the original label\n",
    ">* If humans might relabel, augmentation is unsafe\n",
    "\n",
    ">* Label safety depends entirely on the task\n",
    ">* Identify which cues labels rely on before augmenting\n",
    "\n",
    ">* Start with conservative, domain-informed augmentation settings\n",
    ">* Iteratively adjust, inspect outputs, and consult experts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Label Safe Augmentations\n",
    "\n",
    "# This script demonstrates label safe augmentations.\n",
    "# We use TensorFlow image utilities for simple transforms.\n",
    "# Focus on changes that preserve classification labels.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic random seeds everywhere.\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set TensorFlow random seed for reproducibility.\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset using Keras helper.\n",
    "(x_train, y_train), _ = datasets.mnist.load_data()\n",
    "\n",
    "# Select a tiny subset for quick demonstration.\n",
    "num_samples = 4\n",
    "x_small = x_train[:num_samples]\n",
    "y_small = y_train[:num_samples]\n",
    "\n",
    "# Validate shapes before further processing.\n",
    "print(\"Subset shape:\", x_small.shape)\n",
    "\n",
    "# Expand grayscale images to have channel dimension.\n",
    "x_small = np.expand_dims(x_small, axis=-1)\n",
    "\n",
    "# Convert numpy arrays to float32 tensors.\n",
    "x_small = tf.convert_to_tensor(x_small, dtype=tf.float32)\n",
    "y_small = tf.convert_to_tensor(y_small, dtype=tf.int32)\n",
    "\n",
    "# Normalize pixel values to range zero one.\n",
    "x_small = x_small / 255.0\n",
    "\n",
    "# Define a label safe augmentation function.\n",
    "def safe_augment(image: tf.Tensor) -> tf.Tensor:\n",
    "    # Apply small random rotation preserving digit identity.\n",
    "    angle_rad = tf.random.uniform((), -0.15, 0.15)\n",
    "    # Rotate image using bilinear interpolation.\n",
    "    rotated = tfa_image_rotate(image, angle_rad)\n",
    "    # Apply mild random brightness jitter.\n",
    "    jitter = tf.image.random_brightness(rotated, 0.1)\n",
    "    # Clip values to valid normalized range.\n",
    "    clipped = tf.clip_by_value(jitter, 0.0, 1.0)\n",
    "    # Return augmented image tensor.\n",
    "    return clipped\n",
    "\n",
    "\n",
    "# Implement rotation using TensorFlow raw ops.\n",
    "def tfa_image_rotate(image: tf.Tensor, angle: tf.Tensor) -> tf.Tensor:\n",
    "    # Compute rotation matrix elements from angle.\n",
    "    cos_a = tf.math.cos(angle)\n",
    "    sin_a = tf.math.sin(angle)\n",
    "\n",
    "    # Build 2x3 transform matrix for rotation.\n",
    "    transform = tf.stack([\n",
    "        cos_a,\n",
    "        -sin_a,\n",
    "        0.0,\n",
    "        sin_a,\n",
    "        cos_a,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "    ])\n",
    "\n",
    "    # Reshape transform to correct dimensions.\n",
    "    transform = tf.reshape(transform, (1, 8))\n",
    "\n",
    "    # Add batch dimension to single image.\n",
    "    image_batched = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    # Apply projective transform to image.\n",
    "    rotated = tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=image_batched,\n",
    "        transforms=transform,\n",
    "        output_shape=tf.shape(image_batched)[1:3],\n",
    "        interpolation=\"BILINEAR\",\n",
    "        fill_mode=\"REFLECT\",\n",
    "        fill_value=0.0,\n",
    "    )\n",
    "\n",
    "    # Remove batch dimension before returning.\n",
    "    return tf.squeeze(rotated, axis=0)\n",
    "\n",
    "# Apply safe augmentations to each sample.\n",
    "augmented_images = []\n",
    "for i in range(num_samples):\n",
    "    # Augment each image independently.\n",
    "    aug_img = safe_augment(x_small[i])\n",
    "\n",
    "    # Collect augmented image tensors.\n",
    "    augmented_images.append(aug_img)\n",
    "\n",
    "# Stack augmented images into single tensor.\n",
    "augmented_batch = tf.stack(augmented_images, axis=0)\n",
    "\n",
    "# Confirm shapes of original and augmented.\n",
    "print(\"Original batch shape:\", x_small.shape)\n",
    "\n",
    "# Print augmented batch shape for comparison.\n",
    "print(\"Augmented batch shape:\", augmented_batch.shape)\n",
    "\n",
    "# Convert one pair to numpy for inspection.\n",
    "original_example = x_small[0].numpy()\n",
    "augmented_example = augmented_batch[0].numpy()\n",
    "\n",
    "# Print small summaries instead of full arrays.\n",
    "print(\"Original example min max:\", original_example.min(), original_example.max())\n",
    "\n",
    "# Show augmented example statistics for comparison.\n",
    "print(\"Augmented example min max:\", augmented_example.min(), augmented_example.max())\n",
    "\n",
    "# Print labels to emphasize label safety.\n",
    "print(\"Original labels:\", y_small.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7f811",
   "metadata": {},
   "source": [
    "## **3. Integrating Data Transforms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72113c71",
   "metadata": {},
   "source": [
    "### **3.1. Using Transforms Inside Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73032ab8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_03_01.jpg?v=1769744553\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Dataset automatically transforms samples into model-ready format\n",
    ">* Keeps training loop simple, consistent, and reproducible\n",
    "\n",
    ">* Centralized transforms prevent inconsistent preprocessing bugs\n",
    ">* Every split uses the same transformation pipeline\n",
    "\n",
    ">* Different transform pipelines for training and validation\n",
    ">* Keeps code clean and data prep centralized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Using Transforms Inside Datasets\n",
    "\n",
    "# This script shows transforms inside datasets.\n",
    "# We use TensorFlow image dataset utilities.\n",
    "# Focus is integrating preprocessing into pipelines.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set TensorFlow random seed deterministically.\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define a small image size for speed.\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "# Create a tiny synthetic image dataset.\n",
    "num_samples = 12\n",
    "num_classes = 3\n",
    "\n",
    "# Generate random images and integer labels.\n",
    "images = tf.random.uniform(\n",
    "    shape=(num_samples, img_height, img_width, 3),\n",
    "    minval=0.0,\n",
    "    maxval=1.0,\n",
    ")\n",
    "\n",
    "# Create simple repeating labels.\n",
    "labels = tf.range(num_samples) % num_classes\n",
    "\n",
    "# Validate shapes before building dataset.\n",
    "assert images.shape[0] == labels.shape[0]\n",
    "\n",
    "# Build a base tf.data Dataset from tensors.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "# Define a preprocessing transform function.\n",
    "def preprocess_example(image, label):\n",
    "    # Resize image to target size.\n",
    "    image = tf.image.resize(image, (img_height, img_width))\n",
    "    # Normalize image to zero mean range.\n",
    "    image = (image - 0.5) * 2.0\n",
    "    # Return transformed image and unchanged label.\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Define a training augmentation transform function.\n",
    "def augment_example(image, label):\n",
    "    # Apply random horizontal flip.\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed_value)\n",
    "    # Apply small random brightness change.\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # Return augmented image and original label.\n",
    "    return image, label\n",
    "\n",
    "# Create dataset with only preprocessing transforms.\n",
    "val_ds = base_ds.map(preprocess_example, num_parallel_calls=1)\n",
    "\n",
    "# Create dataset with preprocessing and augmentation.\n",
    "train_ds = base_ds.map(preprocess_example, num_parallel_calls=1)\n",
    "train_ds = train_ds.map(augment_example, num_parallel_calls=1)\n",
    "\n",
    "# Batch both datasets for efficient loading.\n",
    "train_ds = train_ds.batch(4)\n",
    "val_ds = val_ds.batch(4)\n",
    "\n",
    "# Take one batch from each dataset.\n",
    "train_batch_images, train_batch_labels = next(iter(train_ds))\n",
    "val_batch_images, val_batch_labels = next(iter(val_ds))\n",
    "\n",
    "# Print basic information about the batches.\n",
    "print(\"Train batch shape:\", train_batch_images.shape)\n",
    "print(\"Train labels:\", train_batch_labels.numpy())\n",
    "print(\"Validation batch shape:\", val_batch_images.shape)\n",
    "print(\"Validation labels:\", val_batch_labels.numpy())\n",
    "\n",
    "# Show that transforms keep labels unchanged.\n",
    "print(\"First train label, first val label:\",\n",
    "      int(train_batch_labels[0]), int(val_batch_labels[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4bc55f",
   "metadata": {},
   "source": [
    "### **3.2. Compose Versus Custom Calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1915ae",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_03_02.jpg?v=1769744609\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Compose groups transforms into one ordered pipeline\n",
    ">* Improves consistency, reuse, and understanding of preprocessing\n",
    "\n",
    ">* Custom transform calls give flexible, dynamic control\n",
    ">* Scattered logic hurts debugging, reproducibility, evaluation fairness\n",
    "\n",
    ">* Choose structure or flexibility based on project stability\n",
    ">* Prototype with custom logic, then formalize composed pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a51faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Compose Versus Custom Calls\n",
    "\n",
    "# This script compares composed and custom transforms.\n",
    "# It uses TensorFlow image preprocessing utilities.\n",
    "# Focus on clarity not training performance today.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load a tiny subset of MNIST digits.\n",
    "(mnist_x_train, mnist_y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select a small batch for this demo.\n",
    "small_images = mnist_x_train[:8]\n",
    "small_labels = mnist_y_train[:8]\n",
    "\n",
    "# Validate shapes before further processing.\n",
    "print(\"Small batch shape:\", small_images.shape)\n",
    "\n",
    "# Expand grayscale images to have channel dimension.\n",
    "small_images = small_images[..., np.newaxis]\n",
    "\n",
    "# Define a composed preprocessing pipeline function.\n",
    "def composed_preprocess(image):\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed_value)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Define a custom manual preprocessing function.\n",
    "def custom_preprocess(image, index):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    if index % 2 == 0:\n",
    "        image = tf.image.resize(image, (32, 32))\n",
    "    else:\n",
    "        image = tf.image.resize(image, (28, 28))\n",
    "        image = tf.image.resize_with_pad(image, 32, 32)\n",
    "    if index % 3 == 0:\n",
    "        image = tf.image.random_flip_left_right(image, seed=seed_value)\n",
    "    return image\n",
    "\n",
    "# Build a Dataset using the composed pipeline.\n",
    "composed_ds = tf.data.Dataset.from_tensor_slices((small_images, small_labels))\n",
    "composed_ds = composed_ds.map(\n",
    "    lambda img, lbl: (composed_preprocess(img), lbl),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Build a Dataset using the custom pipeline.\n",
    "index_ds = tf.data.Dataset.range(len(small_images))\n",
    "custom_ds = tf.data.Dataset.from_tensor_slices((small_images, small_labels))\n",
    "custom_ds = tf.data.Dataset.zip((custom_ds, index_ds))\n",
    "custom_ds = custom_ds.map(\n",
    "    lambda pair, idx: (custom_preprocess(pair[0], idx), pair[1]),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Take one batch from each dataset for inspection.\n",
    "composed_batch = next(iter(composed_ds.batch(4)))\n",
    "custom_batch = next(iter(custom_ds.batch(4)))\n",
    "\n",
    "# Unpack images and labels from batches.\n",
    "composed_images, composed_labels = composed_batch\n",
    "custom_images, custom_labels = custom_batch\n",
    "\n",
    "# Print summary statistics for composed pipeline.\n",
    "print(\"Composed batch shape:\", composed_images.shape)\n",
    "print(\"Composed labels:\", composed_labels.numpy())\n",
    "\n",
    "# Print summary statistics for custom pipeline.\n",
    "print(\"Custom batch shape:\", custom_images.shape)\n",
    "print(\"Custom labels:\", custom_labels.numpy())\n",
    "\n",
    "# Show simple mean pixel values for quick comparison.\n",
    "print(\"Composed mean pixel:\", float(tf.reduce_mean(composed_images)))\n",
    "print(\"Custom mean pixel:\", float(tf.reduce_mean(custom_images)))\n",
    "\n",
    "# Final line confirms script finished successfully.\n",
    "print(\"Comparison of composed versus custom transforms done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55229195",
   "metadata": {},
   "source": [
    "### **3.3. Transform Effects on Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee144f9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_03_03.jpg?v=1769744676\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Transforms change inputs and shift training metrics\n",
    ">* Stronger augmentations may hurt training scores yet generalize\n",
    "\n",
    ">* Use strong, random transforms only during training\n",
    ">* Keep validation transforms simple, stable, and consistent\n",
    "\n",
    ">* Iteratively tweak transforms and watch learning curves\n",
    ">* Log settings, compare runs, choose effective pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411da7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Transform Effects on Metrics\n",
    "\n",
    "# This script shows how transforms affect metrics.\n",
    "# We compare training with and without simple augmentations.\n",
    "# Focus on clear metrics using a tiny MNIST subset.\n",
    "\n",
    "# !pip install tensorflow==2.20.0.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import tensorflow and keras utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print tensorflow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset from keras datasets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reduce dataset size for quick demonstration.\n",
    "train_samples = 4000\n",
    "test_samples = 1000\n",
    "x_train = x_train[:train_samples]\n",
    "y_train = y_train[:train_samples]\n",
    "\n",
    "# Slice test data for faster evaluation.\n",
    "x_test = x_test[:test_samples]\n",
    "y_test = y_test[:test_samples]\n",
    "\n",
    "# Validate shapes before building datasets.\n",
    "print(\"Train shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", x_test.shape, y_test.shape)\n",
    "\n",
    "# Normalize images to range zero one.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension for convolution layers.\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Create base tf dataset without augmentation.\n",
    "base_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)\n",
    ")\n",
    "\n",
    "# Shuffle and batch the base training dataset.\n",
    "base_train_ds = base_train_ds.shuffle(\n",
    "    buffer_size=train_samples,\n",
    "    seed=seed_value\n",
    ").batch(64)\n",
    "\n",
    "# Create validation dataset with deterministic preprocessing.\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)\n",
    ").batch(64)\n",
    "\n",
    "# Define simple augmentation function for training.\n",
    "def augment_images(images, labels):\n",
    "    images = tf.image.random_flip_left_right(\n",
    "        images,\n",
    "        seed=seed_value\n",
    "    )\n",
    "    images = tf.image.random_brightness(\n",
    "        images,\n",
    "        max_delta=0.1\n",
    "    )\n",
    "    return images, labels\n",
    "\n",
    "# Create augmented training dataset using map.\n",
    "aug_train_ds = base_train_ds.map(\n",
    "    augment_images,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "# Prefetch for better pipeline performance.\n",
    "base_train_ds = base_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "aug_train_ds = aug_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Define a small convolutional model builder.\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(16, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train model without augmentation for few epochs.\n",
    "model_no_aug = build_model()\n",
    "history_no_aug = model_no_aug.fit(\n",
    "    base_train_ds,\n",
    "    epochs=3,\n",
    "    validation_data=val_ds,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train model with augmentation using same settings.\n",
    "model_aug = build_model()\n",
    "history_aug = model_aug.fit(\n",
    "    aug_train_ds,\n",
    "    epochs=3,\n",
    "    validation_data=val_ds,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Extract final epoch metrics for both runs.\n",
    "final_no_aug = history_no_aug.history\n",
    "final_aug = history_aug.history\n",
    "\n",
    "# Print concise comparison of training and validation metrics.\n",
    "print(\"No aug - train loss, acc:\",\n",
    "      round(final_no_aug[\"loss\"][-1], 4),\n",
    "      round(final_no_aug[\"accuracy\"][-1], 4))\n",
    "print(\"No aug - val loss, acc:\",\n",
    "      round(final_no_aug[\"val_loss\"][-1], 4),\n",
    "      round(final_no_aug[\"val_accuracy\"][-1], 4))\n",
    "print(\"Aug    - train loss, acc:\",\n",
    "      round(final_aug[\"loss\"][-1], 4),\n",
    "      round(final_aug[\"accuracy\"][-1], 4))\n",
    "print(\"Aug    - val loss, acc:\",\n",
    "      round(final_aug[\"val_loss\"][-1], 4),\n",
    "      round(final_aug[\"val_accuracy\"][-1], 4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8da11",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Transforms and Augment**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0fff3",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Apply common preprocessing transforms such as normalization, resizing, and tensor conversion to raw data. \n",
    "- Design and configure data augmentation pipelines that improve model robustness without corrupting labels. \n",
    "- Integrate transforms into Dataset and DataLoader workflows while monitoring their impact on training. \n",
    "\n",
    "In the next Module (Module 5), we will go over 'Computer Vision Models'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
