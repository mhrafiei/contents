{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b1ab66",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Transforms and Augment**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673fe7b",
   "metadata": {},
   "source": [
    ">Last update: 20260129.\n",
    "    \n",
    "By the end of this Lecture, you will be able to:\n",
    "- Apply common preprocessing transforms such as normalization, resizing, and tensor conversion to raw data. \n",
    "- Design and configure data augmentation pipelines that improve model robustness without corrupting labels. \n",
    "- Integrate transforms into Dataset and DataLoader workflows while monitoring their impact on training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad1b14",
   "metadata": {},
   "source": [
    "## **1. Core Preprocessing Transforms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57d96b",
   "metadata": {},
   "source": [
    "### **1.1. Tensor Conversion and Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d9887",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_01_01.jpg?v=1769673622\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Convert raw images, text, tables into tensors\n",
    ">* Normalize tensor values for stable, efficient training\n",
    "\n",
    ">* Convert varied images to float tensors, rescaled\n",
    ">* Normalize each color channel using mean and std\n",
    "\n",
    ">* Tensor conversion and normalization help across modalities\n",
    ">* They stabilize training by controlling feature scales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be667f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tensor Conversion and Normalization\n",
    "\n",
    "# This script shows tensor conversion basics.\n",
    "# It uses TensorFlow for simple image preprocessing.\n",
    "# Focus on conversion, scaling, and normalization steps.\n",
    "\n",
    "# Install TensorFlow only if missing in other environments.\n",
    "# !pip install tensorflow==2.20.0 --quiet.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset with small grayscale images.\n",
    "(x_train, y_train), _ = datasets.mnist.load_data()\n",
    "\n",
    "# Select a tiny subset for this demonstration.\n",
    "num_samples = 4\n",
    "x_small = x_train[:num_samples]\n",
    "y_small = y_train[:num_samples]\n",
    "\n",
    "# Confirm shapes before further processing.\n",
    "print(\"Subset shape:\", x_small.shape)\n",
    "\n",
    "# Convert uint8 images to float32 tensors.\n",
    "x_tensor = tf.convert_to_tensor(x_small, dtype=tf.float32)\n",
    "\n",
    "# Add channel dimension for grayscale images.\n",
    "x_tensor = tf.expand_dims(x_tensor, axis=-1)\n",
    "\n",
    "# Validate tensor shape after expansion.\n",
    "print(\"Tensor shape:\", x_tensor.shape)\n",
    "\n",
    "# Scale pixel values from 0-255 to 0-1.\n",
    "x_scaled = x_tensor / 255.0\n",
    "\n",
    "# Compute per channel mean and standard deviation.\n",
    "channel_mean = tf.reduce_mean(x_scaled, axis=(0, 1, 2))\n",
    "channel_std = tf.math.reduce_std(x_scaled, axis=(0, 1, 2))\n",
    "\n",
    "# Avoid division by zero using small epsilon.\n",
    "epsilon = 1e-7\n",
    "safe_std = tf.maximum(channel_std, epsilon)\n",
    "\n",
    "# Apply channel wise normalization transform.\n",
    "x_normalized = (x_scaled - channel_mean) / safe_std\n",
    "\n",
    "# Compute statistics before and after normalization.\n",
    "mean_before = tf.reduce_mean(x_scaled).numpy()\n",
    "std_before = tf.math.reduce_std(x_scaled).numpy()\n",
    "mean_after = tf.reduce_mean(x_normalized).numpy()\n",
    "std_after = tf.math.reduce_std(x_normalized).numpy()\n",
    "\n",
    "# Print summary of scaling and normalization.\n",
    "print(\"Mean before:\", round(float(mean_before), 4))\n",
    "print(\"Std before:\", round(float(std_before), 4))\n",
    "print(\"Mean after:\", round(float(mean_after), 4))\n",
    "print(\"Std after:\", round(float(std_after), 4))\n",
    "\n",
    "# Show one original and normalized pixel range.\n",
    "idx = 0\n",
    "orig_min = float(tf.reduce_min(x_scaled[idx]))\n",
    "orig_max = float(tf.reduce_max(x_scaled[idx]))\n",
    "norm_min = float(tf.reduce_min(x_normalized[idx]))\n",
    "norm_max = float(tf.reduce_max(x_normalized[idx]))\n",
    "\n",
    "# Print pixel ranges to illustrate transformations.\n",
    "print(\"Scaled range sample:\", round(orig_min, 3), round(orig_max, 3))\n",
    "print(\"Norm range sample:\", round(norm_min, 3), round(norm_max, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae61aaa",
   "metadata": {},
   "source": [
    "### **1.2. Spatial Resizing Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f57b41",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_01_02.jpg?v=1769673699\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Real images come in many different sizes\n",
    ">* Resizing standardizes dimensions so models process efficiently\n",
    "\n",
    ">* Direct scaling can distort image aspect ratios\n",
    ">* Preserve aspect ratio using resize, crop, or pad\n",
    "\n",
    ">* Interpolation computes new pixel values when resizing\n",
    ">* Choose methods that preserve task-relevant visual details\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0360a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Spatial Resizing Basics\n",
    "\n",
    "# This script shows basic spatial resizing concepts.\n",
    "# We use TensorFlow to resize small example images.\n",
    "# Focus on shapes and visual intuition not training.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Configure TensorFlow global random seed deterministically.\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one concise line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Create a tiny batch of random RGB images.\n",
    "num_images = 3\n",
    "height, width, channels = 40, 60, 3\n",
    "\n",
    "# Generate random pixel values between zero and one.\n",
    "images_np = np.random.rand(num_images, height, width, channels)\n",
    "\n",
    "# Convert NumPy images to TensorFlow tensor.\n",
    "images_tf = tf.convert_to_tensor(images_np, dtype=tf.float32)\n",
    "\n",
    "# Show original batch shape before resizing.\n",
    "print(\"Original batch shape:\", images_tf.shape)\n",
    "\n",
    "# Define a simple resizing layer to fixed size.\n",
    "resize_layer = layers.Resizing(height=64, width=64)\n",
    "\n",
    "# Apply direct scaling resize to the batch.\n",
    "resized_direct = resize_layer(images_tf)\n",
    "\n",
    "# Show new shape after direct scaling resize.\n",
    "print(\"Direct scaled shape:\", resized_direct.shape)\n",
    "\n",
    "# Define a resizing layer that preserves aspect ratio.\n",
    "resize_keep = layers.Resizing(height=64, width=64, crop_to_aspect_ratio=True)\n",
    "\n",
    "# Apply aspect ratio preserving resize to batch.\n",
    "resized_keep = resize_keep(images_tf)\n",
    "\n",
    "# Show shape after aspect ratio preserving resize.\n",
    "print(\"Aspect ratio shape:\", resized_keep.shape)\n",
    "\n",
    "# Define a nearest neighbor interpolation resizing layer.\n",
    "resize_nearest = layers.Resizing(\n",
    "    height=64,\n",
    "    width=64,\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "# Apply nearest neighbor interpolation to batch.\n",
    "resized_nearest = resize_nearest(images_tf)\n",
    "\n",
    "# Show shape after nearest neighbor interpolation.\n",
    "print(\"Nearest interpolation shape:\", resized_nearest.shape)\n",
    "\n",
    "# Define a bilinear interpolation resizing layer.\n",
    "resize_bilinear = layers.Resizing(\n",
    "    height=64,\n",
    "    width=64,\n",
    "    interpolation=\"bilinear\",\n",
    ")\n",
    "\n",
    "# Apply bilinear interpolation to the same batch.\n",
    "resized_bilinear = resize_bilinear(images_tf)\n",
    "\n",
    "# Show shape after bilinear interpolation resize.\n",
    "print(\"Bilinear interpolation shape:\", resized_bilinear.shape)\n",
    "\n",
    "# Compute mean absolute difference between methods.\n",
    "diff_direct_keep = tf.reduce_mean(\n",
    "    tf.abs(resized_direct - resized_keep)\n",
    ")\n",
    "\n",
    "# Compute difference between nearest and bilinear outputs.\n",
    "diff_near_bilin = tf.reduce_mean(\n",
    "    tf.abs(resized_nearest - resized_bilinear)\n",
    ")\n",
    "\n",
    "# Print concise numeric comparison of resize strategies.\n",
    "print(\"Mean difference direct vs keep:\", float(diff_direct_keep))\n",
    "\n",
    "# Print difference between interpolation strategies for intuition.\n",
    "print(\"Mean difference nearest vs bilinear:\", float(diff_near_bilin))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803836b",
   "metadata": {},
   "source": [
    "### **1.3. Channel and Dtype Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb346d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_01_03.jpg?v=1769673773\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Know channel count, meaning, and ordering first\n",
    ">* Mismatch in channels breaks preprocessing across domains\n",
    "\n",
    ">* Dtype controls value range, storage, and math\n",
    ">* Consistent float dtypes prevent subtle training bugs\n",
    "\n",
    ">* Standardize channels and dtypes early in pipelines\n",
    ">* This prevents inconsistent transforms and unstable training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14796aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Channel and Dtype Basics\n",
    "\n",
    "# This script explains channels and dtypes simply.\n",
    "# We use TensorFlow to inspect small image tensors.\n",
    "# Focus is on shapes, channels, and type conversions.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic random seeds everywhere.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load a small subset of CIFAR10 images.\n",
    "(x_train, y_train), _ = datasets.cifar10.load_data()\n",
    "\n",
    "# Select first four images for quick demo.\n",
    "num_samples = 4\n",
    "x_small = x_train[:num_samples]\n",
    "y_small = y_train[:num_samples]\n",
    "\n",
    "# Confirm original shape and dtype information.\n",
    "print(\"Original shape:\", x_small.shape)\n",
    "print(\"Original dtype:\", x_small.dtype)\n",
    "\n",
    "# Show one label to confirm dataset loaded.\n",
    "print(\"Example label:\", int(y_small[0, 0]))\n",
    "\n",
    "# Convert numpy batch to TensorFlow tensor.\n",
    "images_uint8 = tf.convert_to_tensor(x_small)\n",
    "print(\"Tensor dtype before cast:\", images_uint8.dtype)\n",
    "\n",
    "# Check that channels are in last dimension.\n",
    "print(\"Tensor shape:\", images_uint8.shape)\n",
    "\n",
    "# Extract one image and inspect channel values.\n",
    "one_image = images_uint8[0]\n",
    "print(\"One image shape:\", one_image.shape)\n",
    "\n",
    "# Convert from uint8 to float32 safely.\n",
    "images_float = tf.image.convert_image_dtype(images_uint8, tf.float32)\n",
    "print(\"Tensor dtype after cast:\", images_float.dtype)\n",
    "\n",
    "# Confirm value range after conversion.\n",
    "min_val = tf.reduce_min(images_float).numpy()\n",
    "max_val = tf.reduce_max(images_float).numpy()\n",
    "print(\"Value range after cast:\", float(min_val), float(max_val))\n",
    "\n",
    "# Simulate grayscale by averaging color channels.\n",
    "image_gray = tf.reduce_mean(images_float[0], axis=-1, keepdims=True)\n",
    "print(\"Grayscale shape:\", image_gray.shape)\n",
    "\n",
    "# Repeat grayscale channel three times.\n",
    "image_gray_three = tf.repeat(image_gray, repeats=3, axis=-1)\n",
    "print(\"Repeated grayscale shape:\", image_gray_three.shape)\n",
    "\n",
    "# Stack original and grayscale for simple comparison.\n",
    "stacked = tf.stack([images_float[0], image_gray_three], axis=0)\n",
    "print(\"Stacked batch shape:\", stacked.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6e997",
   "metadata": {},
   "source": [
    "## **2. Label Safe Augmentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e8b5b",
   "metadata": {},
   "source": [
    "### **2.1. Spatial Augmentation Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd617c80",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_02_01.jpg?v=1769673815\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Change image geometry while keeping label meaning\n",
    ">* Simulate real-world viewpoint changes to improve robustness\n",
    "\n",
    ">* Common spatial augments: crop, pad, flip, rotate\n",
    ">* Simulate natural viewpoint changes, expand limited datasets\n",
    "\n",
    ">* Balance useful variation against possible label changes\n",
    ">* Match augmentation ranges to domainâ€™s natural geometry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4111c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Spatial Augmentation Basics\n",
    "\n",
    "# This script shows basic spatial augmentations.\n",
    "# We use TensorFlow image utilities for transformations.\n",
    "# Focus is on label safe geometric changes.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic random seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set TensorFlow random seed for reproducible results.\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset with small grayscale images.\n",
    "(x_train, y_train), _ = datasets.mnist.load_data()\n",
    "\n",
    "# Select a tiny subset for quick demonstration.\n",
    "num_samples = 4\n",
    "x_subset = x_train[:num_samples]\n",
    "\n",
    "y_subset = y_train[:num_samples]\n",
    "\n",
    "# Normalize images to range [0,1] as float32.\n",
    "x_subset = x_subset.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension to match expected shape.\n",
    "x_subset = np.expand_dims(x_subset, axis=-1)\n",
    "\n",
    "# Confirm shapes are as expected before transforms.\n",
    "print(\"Subset shape:\", x_subset.shape)\n",
    "\n",
    "# Define a function for random horizontal flip.\n",
    "def random_flip(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "# Define a function for small random rotation.\n",
    "def random_rotate(image, max_degrees=15.0):\n",
    "    radians = max_degrees * np.pi / 180.0\n",
    "    angle = tf.random.uniform((), -radians, radians)\n",
    "    image = tfa_image_rotate(image, angle)\n",
    "    return image\n",
    "\n",
    "# Define a helper using dense image warp for rotation.\n",
    "def tfa_image_rotate(image, angle):\n",
    "    c = tf.math.cos(angle)\n",
    "    s = tf.math.sin(angle)\n",
    "    transform = [c, -s, 0.0, s, c, 0.0, 0.0, 0.0]\n",
    "    transform = tf.convert_to_tensor(transform)\n",
    "    transform = tf.reshape(transform, (8,))\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=image,\n",
    "        transforms=tf.expand_dims(transform, axis=0),\n",
    "        output_shape=tf.shape(image)[1:3],\n",
    "        interpolation=\"BILINEAR\",\n",
    "        fill_mode=\"REFLECT\",\n",
    "        fill_value=0.0,\n",
    "    )\n",
    "    image = tf.squeeze(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Define a function for random translation using padding.\n",
    "def random_translate(image, max_pixels=3):\n",
    "    dx = tf.random.uniform((), -max_pixels, max_pixels + 1, tf.int32)\n",
    "    dy = tf.random.uniform((), -max_pixels, max_pixels + 1, tf.int32)\n",
    "    paddings = [[max_pixels, max_pixels], [max_pixels, max_pixels], [0, 0]]\n",
    "    padded = tf.pad(image, paddings, mode=\"REFLECT\")\n",
    "    h, w, _ = tf.unstack(tf.shape(image))\n",
    "    start_y = max_pixels + dy\n",
    "    start_x = max_pixels + dx\n",
    "    translated = padded[start_y:start_y + h, start_x:start_x + w, :]\n",
    "    return translated\n",
    "\n",
    "# Compose spatial augmentations into one function.\n",
    "def spatial_augment(image):\n",
    "    image = random_flip(image)\n",
    "    image = random_rotate(image)\n",
    "    image = random_translate(image)\n",
    "    return image\n",
    "\n",
    "# Apply augmentations and collect results.\n",
    "augmented_images = []\n",
    "for i in range(num_samples):\n",
    "    img = x_subset[i]\n",
    "    aug = spatial_augment(img)\n",
    "    augmented_images.append(aug)\n",
    "\n",
    "# Convert augmented list to tensor for inspection.\n",
    "augmented_images = tf.stack(augmented_images, axis=0)\n",
    "\n",
    "# Verify shapes match original subset shapes.\n",
    "print(\"Augmented shape:\", augmented_images.shape)\n",
    "\n",
    "# Show original and augmented labels to confirm safety.\n",
    "print(\"Original labels:\", y_subset.tolist())\n",
    "\n",
    "# Convert augmented images to numpy for simple stats.\n",
    "aug_np = augmented_images.numpy()\n",
    "\n",
    "# Print simple statistics to summarize augmentations.\n",
    "print(\"Original min, max:\", float(x_subset.min()), float(x_subset.max()))\n",
    "\n",
    "# Print augmented statistics to confirm valid ranges.\n",
    "print(\"Augmented min, max:\", float(aug_np.min()), float(aug_np.max()))\n",
    "\n",
    "# Print one example pair of label and pixel mean.\n",
    "idx = 0\n",
    "print(\"Example label:\", int(y_subset[idx]), \"orig mean:\", float(x_subset[idx].mean()))\n",
    "\n",
    "# Print augmented mean for the same example index.\n",
    "print(\"Augmented mean:\", float(aug_np[idx].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66570f76",
   "metadata": {},
   "source": [
    "### **2.2. Color Jitter and Noise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6913c0d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_02_02.jpg?v=1769673945\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Adjust brightness, contrast, saturation, and hue randomly\n",
    ">* Keep labels fixed while improving robustness to appearance\n",
    "\n",
    ">* Add small pixel noise to mimic imperfections\n",
    ">* Model learns robust features while labels stay valid\n",
    "\n",
    ">* Control strength and frequency to avoid label corruption\n",
    ">* Use realistic ranges, monitor effects on images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850de938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Color Jitter and Noise\n",
    "\n",
    "# This script shows label safe color jitter augmentations.\n",
    "# We use TensorFlow to add jitter and noise examples.\n",
    "# Focus is on appearance changes preserving image labels.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set deterministic random seeds everywhere.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Create a simple synthetic RGB image tensor.\n",
    "height, width, channels = 64, 64, 3\n",
    "base_image = tf.ones((height, width, channels), dtype=tf.float32)\n",
    "\n",
    "# Add a colored square to the center region.\n",
    "center_start, center_end = 16, 48\n",
    "square_color = tf.constant([1.0, 0.0, 0.0], dtype=tf.float32)\n",
    "\n",
    "# Use tensor operations to draw the square.\n",
    "center_region = tf.ones((center_end - center_start,\n",
    "                         center_end - center_start,\n",
    "                         channels), dtype=tf.float32)\n",
    "center_region = center_region * square_color\n",
    "\n",
    "# Insert the square into the base image.\n",
    "base_image_with_square = tf.tensor_scatter_nd_update(\n",
    "    base_image,\n",
    "    indices=tf.reshape(\n",
    "        tf.stack(\n",
    "            tf.meshgrid(\n",
    "                tf.range(center_start, center_end),\n",
    "                tf.range(center_start, center_end),\n",
    "                indexing=\"ij\"),\n",
    "            axis=-1),\n",
    "        (-1, 2)),\n",
    "    updates=tf.reshape(center_region, (-1, channels)))\n",
    "\n",
    "# Confirm image shape is as expected.\n",
    "print(\"Base image shape:\", base_image_with_square.shape)\n",
    "\n",
    "# Normalize image to [0,1] range safely.\n",
    "image = tf.clip_by_value(base_image_with_square, 0.0, 1.0)\n",
    "\n",
    "# Define a color jitter layer using Keras preprocessing.\n",
    "color_jitter_layer = tf.keras.Sequential([\n",
    "    layers.RandomBrightness(factor=0.2,\n",
    "                            value_range=(0.0, 1.0),\n",
    "                            seed=seed_value),\n",
    "    layers.RandomContrast(factor=0.2,\n",
    "                          seed=seed_value)\n",
    "])\n",
    "\n",
    "# Apply color jitter to the image batch.\n",
    "image_batch = tf.expand_dims(image, axis=0)\n",
    "color_jittered_batch = color_jitter_layer(image_batch,\n",
    "                                          training=True)\n",
    "color_jittered_image = tf.squeeze(color_jittered_batch,\n",
    "                                  axis=0)\n",
    "\n",
    "# Define a simple Gaussian noise function.\n",
    "def add_gaussian_noise(x, stddev=0.05):\n",
    "    noise = tf.random.normal(shape=tf.shape(x),\n",
    "                             mean=0.0,\n",
    "                             stddev=stddev,\n",
    "                             seed=seed_value)\n",
    "    noisy = x + noise\n",
    "    noisy = tf.clip_by_value(noisy, 0.0, 1.0)\n",
    "    return noisy\n",
    "\n",
    "# Apply Gaussian noise to the jittered image.\n",
    "noisy_image = add_gaussian_noise(color_jittered_image,\n",
    "                                 stddev=0.05)\n",
    "\n",
    "# Compute simple statistics for each version.\n",
    "def summarize_image(name, img_tensor):\n",
    "    img_min = tf.reduce_min(img_tensor).numpy()\n",
    "    img_max = tf.reduce_max(img_tensor).numpy()\n",
    "    img_mean = tf.reduce_mean(img_tensor).numpy()\n",
    "    print(f\"{name} min={img_min:.3f} max={img_max:.3f} mean={img_mean:.3f}\")\n",
    "\n",
    "# Show statistics for base, jittered, and noisy images.\n",
    "summarize_image(\"Base\", image)\n",
    "summarize_image(\"Color jittered\", color_jittered_image)\n",
    "summarize_image(\"Jittered plus noise\", noisy_image)\n",
    "\n",
    "# Build a small dataset pipeline with these transforms.\n",
    "def preprocess_with_augment(x):\n",
    "    x = tf.image.resize(x, (height, width))\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    x = color_jitter_layer(tf.expand_dims(x, 0),\n",
    "                           training=True)\n",
    "    x = tf.squeeze(x, axis=0)\n",
    "    x = add_gaussian_noise(x, stddev=0.05)\n",
    "    return x\n",
    "\n",
    "# Load a tiny subset of MNIST digits.\n",
    "(train_images, train_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images[:32]\n",
    "train_labels = train_labels[:32]\n",
    "\n",
    "# Expand grayscale images to RGB channels.\n",
    "train_images_rgb = np.repeat(train_images[..., np.newaxis],\n",
    "                             3, axis=-1)\n",
    "\n",
    "# Create a TensorFlow dataset from arrays.\n",
    "ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images_rgb, train_labels))\n",
    "\n",
    "# Map preprocessing with augmentation and batch.\n",
    "ds_aug = ds.map(lambda x, y: (preprocess_with_augment(x), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_aug = ds_aug.batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Take one batch and show label stability.\n",
    "for batch_images, batch_labels in ds_aug.take(1):\n",
    "    print(\"Augmented batch shape:\", batch_images.shape)\n",
    "    print(\"Batch labels:\", batch_labels.numpy())\n",
    "\n",
    "# Final line prints confirmation of script completion.\n",
    "print(\"Color jitter and noise augmentation demo complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b4ba7",
   "metadata": {},
   "source": [
    "### **2.3. Label Preserving Constraints**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449109e9",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_02_03.jpg?v=1769674030\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Augmentations must keep the original label meaning\n",
    ">* Decide safe transforms based on task semantics\n",
    "\n",
    ">* Structured tasks need geometry-consistent label transformations\n",
    ">* Augment inputs and labels together, avoiding meaning changes\n",
    "\n",
    ">* Match augmentations to task-specific invariances and limits\n",
    ">* Continuously inspect augmented data and training behavior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Label Preserving Constraints\n",
    "\n",
    "# This script illustrates label preserving constraints.\n",
    "# We compare safe and unsafe image augmentations.\n",
    "# Focus is on how transforms affect labels.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Configure TensorFlow random seed deterministically.\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load MNIST dataset with train and test splits.\n",
    "(train_images, train_labels), _ = datasets.mnist.load_data()\n",
    "\n",
    "# Confirm expected image and label shapes.\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "\n",
    "# Select a tiny subset for quick demonstration.\n",
    "subset_size = 8\n",
    "images_subset = train_images[:subset_size]\n",
    "\n",
    "# Slice corresponding labels for the subset.\n",
    "labels_subset = train_labels[:subset_size]\n",
    "\n",
    "# Normalize images to range zero to one.\n",
    "images_subset = images_subset.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension to match image format.\n",
    "images_subset = np.expand_dims(images_subset, axis=-1)\n",
    "\n",
    "# Define a safe augmentation that preserves labels.\n",
    "safe_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.05,\n",
    "        fill_mode=\"nearest\"\n",
    "    ),\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.05,\n",
    "        width_factor=0.05\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define an unsafe augmentation for digit orientation.\n",
    "unsafe_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\n",
    "        mode=\"horizontal\"\n",
    "    ),\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.5\n",
    "    )\n",
    "])\n",
    "\n",
    "# Apply safe augmentation once to the subset.\n",
    "safe_augmented = safe_augment(images_subset, training=True)\n",
    "\n",
    "# Apply unsafe augmentation once to the subset.\n",
    "unsafe_augmented = unsafe_augment(images_subset, training=True)\n",
    "\n",
    "# Ensure augmented shapes still match original.\n",
    "print(\"Safe augmented shape:\", safe_augmented.shape)\n",
    "\n",
    "# Confirm unsafe augmented shape also matches.\n",
    "print(\"Unsafe augmented shape:\", unsafe_augmented.shape)\n",
    "\n",
    "# Helper function to summarize one example pair.\n",
    "def describe_example(index, original, safe_img, unsafe_img, label):\n",
    "    # Compute simple mean intensity statistics.\n",
    "    orig_mean = float(np.mean(original))\n",
    "    safe_mean = float(np.mean(safe_img))\n",
    "\n",
    "    # Compute mean for unsafe augmented image.\n",
    "    unsafe_mean = float(np.mean(unsafe_img))\n",
    "\n",
    "    # Print a compact description line.\n",
    "    print(\n",
    "        f\"Idx {index} label {label} | \"\n",
    "        f\"orig_mean {orig_mean:.3f} \"\n",
    "        f\"safe_mean {safe_mean:.3f} \"\n",
    "        f\"unsafe_mean {unsafe_mean:.3f}\"\n",
    "    )\n",
    "\n",
    "# Loop over a few examples and describe them.\n",
    "max_examples = 5\n",
    "for i in range(min(max_examples, subset_size)):\n",
    "    describe_example(\n",
    "        i,\n",
    "        images_subset[i],\n",
    "        safe_augmented[i],\n",
    "        unsafe_augmented[i],\n",
    "        int(labels_subset[i])\n",
    "    )\n",
    "\n",
    "# Final message linking back to label constraints.\n",
    "print(\"Safe transforms keep digit identity, unsafe may flip digits.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d66ebe",
   "metadata": {},
   "source": [
    "## **3. Transform Integration Patterns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fbc6a",
   "metadata": {},
   "source": [
    "### **3.1. Transforms in Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b676591",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_03_01.jpg?v=1769674112\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Dataset applies transforms when samples are loaded\n",
    ">* Ensures consistent, model-ready data without altering originals\n",
    "\n",
    ">* Dataset transforms hide preprocessing from training loop\n",
    ">* Easily swap datasets and test preprocessing strategies\n",
    "\n",
    ">* Different datasets use role-specific transform pipelines\n",
    ">* Ensures fair, stable evaluation and robust training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fecb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Transforms in Dataset\n",
    "\n",
    "# This script shows transforms inside datasets.\n",
    "# We use TensorFlow image dataset utilities.\n",
    "# Focus on integrating preprocessing into dataset.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and image utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set TensorFlow random seed.\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version once.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load small subset of MNIST data.\n",
    "(x_train, y_train), _ = datasets.mnist.load_data()\n",
    "\n",
    "# Select a tiny slice for speed.\n",
    "num_samples = 512\n",
    "x_train = x_train[:num_samples]\n",
    "\n",
    "# Slice labels to match images.\n",
    "y_train = y_train[:num_samples]\n",
    "\n",
    "# Validate shapes before building dataset.\n",
    "assert x_train.shape[0] == y_train.shape[0]\n",
    "\n",
    "# Print basic dataset information.\n",
    "print(\"Train subset shape:\", x_train.shape)\n",
    "\n",
    "# Define a preprocessing transform function.\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    # Convert image to float32 tensor.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Add channel dimension for grayscale.\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    # Normalize pixel values to zero mean.\n",
    "    image = (image / 255.0) - 0.5\n",
    "    # Return transformed image and original label.\n",
    "    return image, label\n",
    "\n",
    "# Create base dataset from NumPy arrays.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "# Apply preprocessing transform inside dataset.\n",
    "train_ds = base_ds.map(preprocess_image, num_parallel_calls=1)\n",
    "\n",
    "# Shuffle and batch the transformed dataset.\n",
    "train_ds = train_ds.shuffle(buffer_size=num_samples).batch(32)\n",
    "\n",
    "# Take one batch to inspect shapes.\n",
    "images_batch, labels_batch = next(iter(train_ds))\n",
    "\n",
    "# Print batch shapes after transforms.\n",
    "print(\"Batch images shape:\", images_batch.shape)\n",
    "\n",
    "# Print batch labels shape for confirmation.\n",
    "print(\"Batch labels shape:\", labels_batch.shape)\n",
    "\n",
    "# Compute simple statistics of transformed batch.\n",
    "batch_mean = tf.reduce_mean(images_batch).numpy()\n",
    "\n",
    "# Compute standard deviation of transformed batch.\n",
    "batch_std = tf.math.reduce_std(images_batch).numpy()\n",
    "\n",
    "# Print summary of transform effects.\n",
    "print(\"Batch pixel mean:\", float(batch_mean))\n",
    "\n",
    "# Print standard deviation to show normalization.\n",
    "print(\"Batch pixel std:\", float(batch_std))\n",
    "\n",
    "# Show first label to confirm label integrity.\n",
    "print(\"First label in batch:\", int(labels_batch[0].numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5105a",
   "metadata": {},
   "source": [
    "### **3.2. Composing Transform Calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eebe03",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_03_02.jpg?v=1769674177\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Transforms run in a strict, ordered pipeline\n",
    ">* Each step expects specific input; wrong order breaks\n",
    "\n",
    ">* Mix always-on and random transforms thoughtfully\n",
    ">* Preserve meaning while increasing variation for generalization\n",
    "\n",
    ">* Choose which transforms run pre- and post-batch\n",
    ">* Structure stages to reduce work and ease changes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Composing Transform Calls\n",
    "\n",
    "# This script shows composing simple image transforms.\n",
    "# We use TensorFlow to simulate transform pipelines.\n",
    "# Focus on per sample and per batch transforms.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set deterministic random seeds.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Configure NumPy and TensorFlow seeds.\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version briefly.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load a small subset of MNIST digits.\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select a tiny subset for quick demonstration.\n",
    "num_samples = 256\n",
    "x_small = x_train[:num_samples]\n",
    "\n",
    "y_small = y_train[:num_samples]\n",
    "\n",
    "# Validate shapes before building datasets.\n",
    "assert x_small.ndim == 3\n",
    "assert y_small.shape[0] == num_samples\n",
    "\n",
    "# Define a per sample deterministic transform function.\n",
    "def per_sample_transform(image, label):\n",
    "    # Convert image to float32 tensor.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Add channel dimension for convolutional models.\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "\n",
    "    # Apply a random horizontal flip augmentation.\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed_value)\n",
    "\n",
    "    # Return transformed image and original label.\n",
    "    return image, label\n",
    "\n",
    "# Define a simple per batch transform function.\n",
    "def per_batch_transform(images, labels):\n",
    "    # Confirm batch rank and image rank.\n",
    "    tf.debugging.assert_rank(images, 4)\n",
    "\n",
    "    # Normalize batch to zero mean unit variance.\n",
    "    mean, variance = tf.nn.moments(images, axes=[0, 1, 2])\n",
    "    images = (images - mean) / tf.sqrt(variance + 1e-6)\n",
    "\n",
    "    # Return batch ready for the model.\n",
    "    return images, labels\n",
    "\n",
    "# Build a base dataset from NumPy arrays.\n",
    "base_ds = tf.data.Dataset.from_tensor_slices((x_small, y_small))\n",
    "\n",
    "# Apply per sample transform inside the dataset.\n",
    "train_ds = base_ds.map(per_sample_transform, num_parallel_calls=1)\n",
    "\n",
    "# Shuffle and batch the dataset for training.\n",
    "train_ds = train_ds.shuffle(buffer_size=num_samples, seed=seed_value)\n",
    "train_ds = train_ds.batch(32)\n",
    "\n",
    "# Apply per batch transform after batching.\n",
    "train_ds = train_ds.map(per_batch_transform, num_parallel_calls=1)\n",
    "\n",
    "# Prefetch to improve pipeline performance.\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Inspect one batch to see composed effects.\n",
    "for batch_images, batch_labels in train_ds.take(1):\n",
    "    # Print batch shapes and basic statistics.\n",
    "    print(\"Batch images shape:\", batch_images.shape)\n",
    "    print(\"Batch labels shape:\", batch_labels.shape)\n",
    "\n",
    "    # Compute mean and std of the batch.\n",
    "    batch_mean = tf.reduce_mean(batch_images).numpy()\n",
    "    batch_std = tf.math.reduce_std(batch_images).numpy()\n",
    "\n",
    "    # Print summary statistics for monitoring.\n",
    "    print(\"Batch mean after transforms:\", float(batch_mean))\n",
    "    print(\"Batch std after transforms:\", float(batch_std))\n",
    "\n",
    "# Build a tiny model to consume transformed batches.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(8, (3, 3), activation=\"relu\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile the model with simple settings.\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train briefly to ensure pipeline integration.\n",
    "history = model.fit(train_ds, epochs=1, verbose=0)\n",
    "\n",
    "# Print final training accuracy for confirmation.\n",
    "print(\"Training accuracy with composed transforms:\", float(history.history[\"accuracy\"][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78e209",
   "metadata": {},
   "source": [
    "### **3.3. Tracking Training Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05b85d",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.jsdelivr.net/gh/mhrafiei/contents@main/LFF/Master PyTorch 2.10.0/Module_04/Lecture_B/image_03_03.jpg?v=1769674273\" width=\"250\">\n",
    "\n",
    "\n",
    "\n",
    ">* Track how transforms change training and validation metrics\n",
    ">* Compare metric curves before and after transform tweaks\n",
    "\n",
    ">* Track detailed metrics like per-class accuracy\n",
    ">* Log metrics and transform settings to explain changes\n",
    "\n",
    ">* Pair metric trends with visual data checks\n",
    ">* Use this feedback loop to refine transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Python Code - Tracking Training Metrics\n",
    "\n",
    "# This script shows tracking metrics with transforms.\n",
    "# We use TensorFlow image data and simple augmentations.\n",
    "# Focus on how transforms affect training curves.\n",
    "\n",
    "# !pip install tensorflow.\n",
    "\n",
    "# Import required standard libraries.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras utilities.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set deterministic seeds for reproducibility.\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Set NumPy and TensorFlow seeds deterministically.\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Print TensorFlow version in one short line.\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Choose device based on GPU availability.\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if physical_gpus:\n",
    "    device_name = \"GPU\"\n",
    "else:\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "# Print which device type will be mainly used.\n",
    "print(\"Using device type:\", device_name)\n",
    "\n",
    "# Load MNIST dataset from Keras datasets.\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = (\n",
    "    keras.datasets.mnist.load_data()\n",
    ")\n",
    "\n",
    "# Select a small subset for quick demonstration.\n",
    "train_subset_size = 4000\n",
    "test_subset_size = 1000\n",
    "\n",
    "# Slice the arrays to obtain smaller subsets.\n",
    "x_train = mnist_x_train[:train_subset_size]\n",
    "y_train = mnist_y_train[:train_subset_size]\n",
    "\n",
    "# Slice test arrays similarly for evaluation.\n",
    "x_test = mnist_x_test[:test_subset_size]\n",
    "y_test = mnist_y_test[:test_subset_size]\n",
    "\n",
    "# Validate shapes to avoid unexpected broadcasting.\n",
    "assert x_train.shape[0] == train_subset_size\n",
    "assert x_test.shape[0] == test_subset_size\n",
    "\n",
    "# Expand channel dimension and normalize to floats.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension required for Conv2D layers.\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Confirm final shapes are as expected.\n",
    "print(\"Train shape:\", x_train.shape)\n",
    "print(\"Test shape:\", x_test.shape)\n",
    "\n",
    "# Define a simple convolutional model builder.\n",
    "def build_simple_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Input(shape=(28, 28, 1)),\n",
    "            keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(32, activation=\"relu\"),\n",
    "            keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create a tf.data.Dataset without augmentation.\n",
    "base_train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "base_train_ds = base_train_ds.shuffle(1000, seed=seed_value)\n",
    "\n",
    "# Batch and prefetch for performance.\n",
    "base_train_ds = base_train_ds.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Create a simple normalization only pipeline.\n",
    "def normalize_only(image, label):\n",
    "    return image, label\n",
    "\n",
    "# Map normalization transform to dataset.\n",
    "train_ds_no_aug = base_train_ds.map(normalize_only)\n",
    "\n",
    "# Define an augmentation function using tf.image.\n",
    "def augment_image(image, label):\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed_value)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    return image, label\n",
    "\n",
    "# Apply augmentation transform to create new dataset.\n",
    "train_ds_aug = base_train_ds.map(augment_image)\n",
    "\n",
    "# Prepare validation dataset without augmentation.\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_ds = val_ds.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Build two identical models for fair comparison.\n",
    "model_no_aug = build_simple_model()\n",
    "model_aug = build_simple_model()\n",
    "\n",
    "# Train model without augmentation silently.\n",
    "history_no_aug = model_no_aug.fit(\n",
    "    train_ds_no_aug,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Train model with augmentation silently.\n",
    "history_aug = model_aug.fit(\n",
    "    train_ds_aug,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Extract final epoch metrics for both runs.\n",
    "final_no_aug = (\n",
    "    history_no_aug.history[\"loss\"][-1],\n",
    "    history_no_aug.history[\"val_loss\"][-1],\n",
    "    history_no_aug.history[\"accuracy\"][-1],\n",
    "    history_no_aug.history[\"val_accuracy\"][-1],\n",
    ")\n",
    "\n",
    "# Extract augmented run metrics similarly.\n",
    "final_aug = (\n",
    "    history_aug.history[\"loss\"][-1],\n",
    "    history_aug.history[\"val_loss\"][-1],\n",
    "    history_aug.history[\"accuracy\"][-1],\n",
    "    history_aug.history[\"val_accuracy\"][-1],\n",
    ")\n",
    "\n",
    "# Print a short header explaining the comparison.\n",
    "print(\"\\nFinal metrics after 3 epochs (no augmentation):\")\n",
    "\n",
    "# Print rounded metrics for the baseline model.\n",
    "print(\n",
    "    \"train_loss=\", round(final_no_aug[0], 3),\n",
    "    \"val_loss=\", round(final_no_aug[1], 3),\n",
    "    \"train_acc=\", round(final_no_aug[2], 3),\n",
    "    \"val_acc=\", round(final_no_aug[3], 3),\n",
    ")\n",
    "\n",
    "# Print header for augmented training metrics.\n",
    "print(\"\\nFinal metrics after 3 epochs (with augmentation):\")\n",
    "\n",
    "# Print rounded metrics for the augmented model.\n",
    "print(\n",
    "    \"train_loss=\", round(final_aug[0], 3),\n",
    "    \"val_loss=\", round(final_aug[1], 3),\n",
    "    \"train_acc=\", round(final_aug[2], 3),\n",
    "    \"val_acc=\", round(final_aug[3], 3),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefe305",
   "metadata": {},
   "source": [
    "# <font color=\"#418FDE\" size=\"6.5\" uppercase>**Transforms and Augment**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df052c",
   "metadata": {},
   "source": [
    "\n",
    "In this lecture, you learned to:\n",
    "- Apply common preprocessing transforms such as normalization, resizing, and tensor conversion to raw data. \n",
    "- Design and configure data augmentation pipelines that improve model robustness without corrupting labels. \n",
    "- Integrate transforms into Dataset and DataLoader workflows while monitoring their impact on training. \n",
    "\n",
    "In the next Module (Module 5), we will go over 'Computer Vision Models'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
